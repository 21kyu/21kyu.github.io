[ { "title": "Linux OOM Killer", "url": "/posts/out-of-memory-kiiler/", "categories": "linux", "tags": "os", "date": "2022-08-20 20:00:00 +0900", "snippet": "OOM Killer?linux OOM Killerminikubesystemd / cgroup v2QoSGuaranteeduid: 3da16733_7851_49a0_a806_dd8a38f38ad3containerID: 9e20d88aa83a55eacdeeb366424c7b0c5c7734213d4d9aeb4ac5e6cd4c8facfedocker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-pod3da16733_7851_49a0_a806_dd8a38f38ad3.slice/docker-9e20d88aa83a55eacdeeb366424c7b0c5c7734213d4d9aeb4ac5e6cd4c8facfe.scope$ grep \"\" memory.*memory.current:196608memory.high:maxmemory.low:0memory.max:209715200memory.min:0docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-pod3da16733_7851_49a0_a806_dd8a38f38ad3.slice/docker-9e20d88aa83a55eacdeeb366424c7b0c5c7734213d4d9aeb4ac5e6cd4c8facfe.scope$ cat cgroup.procs44318docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-pod3da16733_7851_49a0_a806_dd8a38f38ad3.slice/docker-9e20d88aa83a55eacdeeb366424c7b0c5c7734213d4d9aeb4ac5e6cd4c8facfe.scope$ grep \"\" /proc/44318/oom_*/proc/44318/oom_adj:-16/proc/44318/oom_score:2/proc/44318/oom_score_adj:-997BestEffortuid: fd217f17-4ffa-41e6-882c-ced81693e3f4containerID: //5226c0c3615eb8a4de58d7f12dbb64cd68708457b06925d635bf4d84e7bdb679docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-podfd217f17_4ffa_41e6_882c_ced81693e3f4.slice/docker-5226c0c3615eb8a4de58d7f12dbb64cd68708457b06925d635bf4d84e7bdb679.scope$ grep \"\" memory.*memory.current:204800memory.high:maxmemory.low:0memory.max:maxmemory.min:0docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-podfd217f17_4ffa_41e6_882c_ced81693e3f4.slice/docker-5226c0c3615eb8a4de58d7f12dbb64cd68708457b06925d635bf4d84e7bdb679.scope$ cat cgroup.procs42981docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-podfd217f17_4ffa_41e6_882c_ced81693e3f4.slice/docker-5226c0c3615eb8a4de58d7f12dbb64cd68708457b06925d635bf4d84e7bdb679.scope$ grep \"\" /proc/42981/oom_*/proc/42981/oom_adj:15/proc/42981/oom_score:1332/proc/42981/oom_score_adj:1000Burstableuid: 87431cda-dfb8-4686-a593-4bee7a2596fccontainerID: docker://737d43b63cc68d5b8206adbde941f933f8d374092e5801bb5a875d942fced51fdocker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod87431cda_dfb8_4686_a593_4bee7a2596fc.slice/docker-737d43b63cc68d5b8206adbde941f933f8d374092e5801bb5a875d942fced51f.scope$ grep \"\" memory.*memory.current:208896memory.high:maxmemory.low:0memory.max:209715200memory.min:0docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod87431cda_dfb8_4686_a593_4bee7a2596fc.slice/docker-737d43b63cc68d5b8206adbde941f933f8d374092e5801bb5a875d942fced51f.scope$ cat cgroup.procs43918docker@minikube:/sys/fs/cgroup/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod87431cda_dfb8_4686_a593_4bee7a2596fc.slice/docker-737d43b63cc68d5b8206adbde941f933f8d374092e5801bb5a875d942fced51f.scope$ grep \"\" /proc/43918/oom_*/proc/43918/oom_adj:15/proc/43918/oom_score:1328/proc/43918/oom_score_adj:994 QoS Memory Request Memory Limit memory.min memory.max memory.low memory.high oom_adj oom_score oom_score_adj BestEffort - - 0 max 0 max 15 1332 1000 Burstable 100Mi 200Mi 0 209715200 0 max 15 1328 994 Guaranteed 200Mi 200Mi 0 209715200 0 max -16 2 -997 memory request의 값 자체는 cgorp의 memory 설정과는 관계가 없다. QoS가 bustable일 경우 oom_score_adj를 결정할 때 사용된다. memory limit의 값이 memory.max에 반영된다.oom_scorekubelet에서의 oom_score_adjGetContainerOOMScoreAdjustkubelet은 pod의 QoS를 기반으로 각 컨테이너에 대한 oom_score_adj를 설정한다. QoS oom_score_adj BestEffort 1000 Burstable min(max(3, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) Guaranteed -997 Kubelet -999 linux에서의 oom_scoreoom_kill.cAnother OOM killerout_of_memory -&gt; select_bad_process -&gt; oom_evaluate_task -&gt; oom_badness 순으로 호출되며 죽일 후보를 결정하기 위한 점수를 계산한다.목표는 후속 oom 실패를 방지하기 위해 가장 많은 메모리를 사용 중인 프로세스에게 가장 높은 점수를 부여하는 것이다.badness score(point)의 기준은 각 프로세스의 RSS, pagetable 및 swap 공간이 사용하는 RAM의 비율이다.이 계산은 결과적으로 퍼센트*10의 숫자를 반환한다.즉, 사용 가능한 메모리의 모든 바이트를 사용하는 프로세스의 점수는 1,000이고 메모리를 전혀 사용하지 않는 프로세스의 점수는 0이 된다.만약 root 소유의 프로세스라면 user 소유의 프로세스보다 조금 더 가치가 있다는 개념에 따라 30을 뺀다.이러한 결과에 -1,000 ~ 1,000의 범위를 가진 oom_score_adj를 더한 값이 최종 점수가 된다.-1,000으로 설정하면 oom kill이 완전히 비활성화되는 반면 1,000으로 설정하면 oom killer에 의해 선택될 확률이 매우 높아진다.oom_adj 값은 사용되지 않는다.cgroup out of memorycgroup의 메모리 사용량이 memory.max를 초과하면 oom kill이 동작하게 된다.// 내용 추가 필요한가node pressure eviction (kubelet)Node-pressure-eviction// 링크로 대체 가능node out of memory (oom_killer)kubelet의 메모리 회수가 가능하기 이전에 노드에 메모리 부족(out of memory, OOM) 이벤트가 발생하면,노드는 oom_killer에 의존한다.// 내용 추가할까.." }, { "title": "Control groups & Kubernetes", "url": "/posts/cgroups-and-kubernetes/", "categories": "linux", "tags": "os", "date": "2022-08-20 20:00:00 +0900", "snippet": "Control groups?보통 cgroups라고 불리는 control gorups는 프로세스가 사용하는 다양한 유형의 리소스를 제한하고 모니터링할 수 있는,계층적 그룹으로 구성된 Linux kernel 기능이다.커널의 cgroup interface는 cgroupfs라는 pseudo-filesystem을 통해 제공된다.Terminology cgorup cgorup은 cgroup filesystem을 통해 정의된 제한 또는 매개변수 집합에 바인딩된 프로세스들을 말한다. subsystem subsystem은 group에서 프로세스의 동작을 제어하는 커널의 구성 요소이다.cgorup에 허용될 CPU 및 메모리 양에 대한 제한, cgroup에서 사용하는 CPU 시간에 대한 측정, 프로세스 실행 중지 및 재개와 같은 작업을 수행할 수 있는 다양한 하위 시스템이 구현되어 있다.subsystem은 리소스 컨트롤러(또는 간단히 컨트롤러)라고도 한다. hierarchy controller의 cgorups는 계층 구조로 정렬된다.이 계층 구조는 cgroup filesystem 내에서 하위 디렉토리를 생성, 제거 작업을 통해 정의된다.계층의 각 수준에서 속성(e.g., 제한)을 정의할 수 있다.cgorup에서 제공하는 제한, 제어 및 측정은 보통 속성이 정의된 cgorup 아래의 하위 계층 전체에 영향을 미친다.따라서 계층의 더 높은 수준에서 cgorup에 설정된 제한값은 하위 cgorups가 초과할 수 없게 된다.CGROUPS VERSION 1cgroups v1에서의 각 controller는 시스템 내 프로세스에 대한 자체 계층 구조를 제공하는 별도의 cgorup filesystem으로 마운트될 수 있다.동일한 cgorup filesystem에 대해 여러(또는 모든) cgorup v1 controllers를 같이 마운트하는 것도 가능하다.즉, 같이 마운트된 controllers는 동일한 계층적 프로세스 조직을 관리하게 된다.마운트된 각 계층에 대해 디렉토리 트리는 control group 계층을 미러링한다.각 control group은 디렉토리로 표시되며 각 하위 cgroups는 하위 디렉토리로 표시된다.예를 들어서, /user/joe/1.session은 /user의 자식인 cgorup joe의 자식인 control group 1.session을 나타낸다.각 cgorup 디렉토리 아래에는 리소스 제한과 몇 가지 일반적인 cgroup 속성을 반영하여 읽거나 쓸 수 있는 파일들이 있다.Tasks (threads) versus processescgorups v1에서는 프로세스와 태스크를 구분한다.프로세스는 여러 (사용자 공간 관점에서 대개 스레드로 불리우는) 태스크로 구성될 수 있다.cgroups v1에서는 프로세스에 있는 스레드의 cgroup 구성원을 독립적으로 조작할 수 있다.cgroups v1이 스레드를 여러 cgroup으로 분할하는 기능으로 인해 상황에 따라 문제가 발생되곤 했는데,프로세스의 모든 스레드가 단일 주소 공간을 공유하기 때문에 memory 컨트롤러는 큰 의미가 없다.이러한 문제로 인해 프로세스에서 스레드의 cgorup 구성원을 독립적으로 조작하는 기능은 초기 cgorups v2 구현에서 제거되었으며추후 더 제한된 형태로 복원되긴 했다.Mounting v1 controllerscgroups를 사용하려면 CONFIG_CGROUP 옵션으로 빌드된 커널이 필요하다.또한 각 v1 컨트롤러에는 해당 컨트롤러를 사용하기 위해 설정해야하는 관련된 구성 옵션이 존재한다.v1 컨트롤러 사용을 위해 cgroup filesystem을 마운트하자.보통 sys/fs/cgroup에 마운트된 tmpfs filesystem 아래에 위치한다.따라서 다음과 같이 cpu 컨트롤러를 마운트할 수 있다.mount -t cgroup -o cpu none /sys/fs/cgroup/cpu동일한 계층 구조에 대해 여러 컨트롤러를 공동으로 마운트할 수도 있다.다음의 명령어를 사용하면 cpu 및 cpuacct 컨트롤러는 단일 계층 구조에 함께 마운트된다.mount -t cgroup -o cpu,cpuacct none /sys/fs/cgroup/cpu,cpuacct컨트롤러를 함께 마운트하면 프로세스가 같이 마운트된 모든 컨트롤러에 대해 동일한 cgroup에 있다는 효과를 볼 수 있다.또한 동일한 계층 구조에 대해 모든 v1 컨트롤러를 함께 마운트할 수 있다.mount -t cgroup -o all cgroup /sys/fs/cgroup여러 cgroup 계층에 대해 동일한 컨트롤러를 마운트할 수 없다.한 계층에서 cpu 및 cpuacct 컨트롤러를 모두 마운트하고 다른 계층에 대해 cpu 컨트롤러만 따로 마운트할 수 없다.lssubsys를 사용해 각 subsystem이 마운트된 경로를 확인할 수 있다.➜ ~ lssubsys -am cpu,cpuset,memory /cgroup/cpu_and_memcpuacctblkiodevicesfreezernet_clsperf_eventnet_priohugetlbpidsrdmamiscUnmounting v1 controllers마운트된 cgroup filesystem은 umount 커맨드를 사용해 마운트 해제할 수 있다.umount /sys/fs/cgroup/pidscgroup filesystem은 사용 중이 아닌 경우, 즉 자식 cgroup이 없는 경우에만 마운트 해제된다.그렇지 않은 경우의 umount 커맨드의 효과는 해당 마운트를 보이지 않게만 만든다.따라서 마운트가 실제로 해제되었는지 확인하려면 먼저 모든 하위 cgroup을 제거해야만 한다.cgroups v1 controllers cpu cgorups는 시스템이 사용 중일 때 최소 “CPU 공유” 수를 보장할 수 있다.CPU가 사용 중이 아닌 경우 cgorups의 CPU 사용량을 제한하지 않는다.Linux 3.2에서 이 컨트롤러는 CPU “대역폭” 제어를 제공하도록 확장되었다.커널이 CONFIG_CFS_BANDWITDH로 구성된 경우 각 스케줄링 기간(cgorup 디렉토리의 파일을 통해 정의됨) 내에서cgroup의 프로세스에 할당된 CPU 시간의 상한을 정의할 수 있다.이 상한은 CPU에 대한 다른 경쟁이 없는 경우에도 적용된다. cpuacct 프로세스 그룹에 의해 사용되고 있는 CPU 사용량에 대한 관측 정보를 제공한다. cpuset cgroup의 프로세스를 지정된 CPU 및 NUMA 노드 집합에 바인딩하도록 사용할 수 있다. memory cgroup에서 사용하는 프로세스 메모리, 커널 메모리 및 swap의 보고 및 제한을 지원한다. device 특정 프로세스가 (mknod) 장치를 생성하고 읽기 또는 쓰기를 위해 열 수 있는지에 대한 제어를 할 수 있도록 한다.정책은 허용 및 거부 목록으로 지정할 수 있다.계층 구조로 적용되므로 새로운 규칙은 대상 또는 상위 cgorup에 대한 기존 규칙을 위반해서는 안된다. freezer cgorup의 모든 프로세스를 일시 중단하고 복원(재개)할 수 있다.cgorup /A를 프리징하면 하위 프로세스(/A/B) 또한 프리징된다. net_cls cgorup에 의해 생성된 네트워크 패킷에 cgorup에 대해 지정된 classid를 배치한다.이렇게 배치된 classid들은 방화벽 규칙 및 tc를 사용해 트래픽을 형성하는데 사용할 수 있다.이것은 cgroup에 도착하는 트래픽이 아니라 cgroup을 나가는 패킷에만 적용된다. blkio 스토리지 계층의 리프(leaf) 노드 및 중간(intermediate) 노드에 대한 스로틀링 및 상한(upper limits)의 형태로IO 제어를 적용해 지정된 block devices에 대한 접근을 제어하고 제한한다.CFQ를 사용하는 리프 노드에 적용되는 디스크의 비례 가중치(proportional-weight) 시간 기반 분할(time-based division)과device의 상위 I/O 속도 제한을 조절하는 두 가지의 정책을 사용할 수 있다. perf_event cgroup으로 그룹화된 프로세스들을 모니터링할 수 있다. net_prio cgroups에 대해 네트워크 인터페이스별로 우선 순위를 지정해줄 수 있다. hugetlb cgroups에 의한 huge page 사용 제한을 지원한다. pids cgroup(및 그 하위 자식들)에서 생성될 수 있는 프로세스의 수를 제한한다. rdma cgroup당 RDMA/IB 특정 리소스의 사용을 제한할 수 있다.Creating cgroups and moving processes새로운 cgroup은 cgroup filesystem에 디렉토리를 만들면 생성된다.cgroup filesystem은 /sys/fs/cgroup에 위치해있다.➜ ~ cd /sys/fs/cgroup ➜ cgroup lscgroup.controllers cgroup.subtree_control cpu.stat io.cost.qos memory.pressure sys-kernel-config.mountcgroup.max.depth cgroup.threads dev-hugepages.mount io.pressure memory.stat sys-kernel-debug.mountcgroup.max.descendants cpu.pressure dev-mqueue.mount io.prio.class misc.capacity sys-kernel-tracing.mountcgroup.procs cpuset.cpus.effective init.scope io.stat proc-sys-fs-binfmt_misc.mount system.slicecgroup.stat cpuset.mems.effective io.cost.model memory.numa_stat sys-fs-fuse-connections.mount user.slice이 호스트는 cgroup.controllers와 같은 파일이 있는걸로 봐선 cgroups v2 파일시스템을 지원한다.참고로 현재 사용 중인 Linux system이 지원하는 cgroup 버전은 아래 커맨드로 쉽게 확인할 수 있다.➜ cpu grep cgroup /proc/filesystemsnodev\tcgroupnodev\tcgroup2새 cgroup을 만들어보자.➜ cgroup sudo mkdir -p cpu/cg1➜ cgroup cd cpu ➜ cpu lscg1 cgroup.procs cpu.max.burst cpu.stat io.prio.class memory.low memory.swap.currentcgroup.controllers cgroup.stat cpu.pressure cpu.uclamp.max io.stat memory.max memory.swap.eventscgroup.events cgroup.subtree_control cpuset.cpus cpu.uclamp.min io.weight memory.min memory.swap.highcgroup.freeze cgroup.threads cpuset.cpus.effective cpu.weight memory.current memory.numa_stat memory.swap.maxcgroup.kill cgroup.type cpuset.cpus.partition cpu.weight.nice memory.events memory.oom.group pids.currentcgroup.max.depth cpu.idle cpuset.mems io.max memory.events.local memory.pressure pids.eventscgroup.max.descendants cpu.max cpuset.mems.effective io.pressure memory.high memory.stat pids.max➜ cpu cd cg1 ➜ cg1 lscgroup.controllers cgroup.freeze cgroup.max.depth cgroup.procs cgroup.subtree_control cgroup.type cpu.stat memory.pressurecgroup.events cgroup.kill cgroup.max.descendants cgroup.stat cgroup.threads cpu.pressure io.pressure현재 사용 중인 shell 프로세스의 PID를 cgroup의 cgroup.procs 파일에 기록하여 해당 cgroup으로 이동할 수 있다.➜ echo $$ &gt; cgroup.procs➜ cat cgroup.procs 15451671545240➜ ps aux | grep 1545167root 1545167 0.0 0.0 11544 4304 pts/1 S 23:04 0:00 bash➜ tty/dev/pts/1이 파일에는 한 번에 하나의 PID만 기록해야 하며PID를 cgroup.procs에 쓸 때 프로세스의 모든 스레드는 한 번에 새 cgroup으로 이동한다.계층 내에서 프로세스는 정확히 하나의 cgroup의 구성원일 수 있다.프로세스의 PID를 cgroup.procs 파일에 쓰면 이전에 구성원이었던 cgroup에서 자동으로 제거된다.cgroup.procs 파일을 읽어 cgroup의 구성원이 프로세스 리스트를 얻을 수 있다.반환된 PID 리스트는 순서가 보장되지 않으며 또한 중복이 없다는 보장도 없다.(리스트에서 읽는 동안 PID가 재활용될 수 있다.)cgroups v1에서 개별 스레드는 cgroup 디렉토리의 tasks 파일에스레드 ID(i.e., clone 및 gettid에 의해 반환된 커널 스레드 ID)를 기록하여 다른 cgroup으로 이동할 수 있다.이 파일을 읽어 cgroup의 구성원인 스레드 집합을 검색할 수 있다.Removing cgroupscgroup을 제거하려면 먼저 자식 cgroups가 없고 (nonzombie) 프로세스가 없어야 한다.이런 경우라면 해당 디렉토리 경로 이름을 간단하게 제거할 수 있다.cgroup 디렉토리의 파일은 제거할 수 없으며 제거할 필요도 없다.CGROUPS VERSION 2cgroups v2에서 마운트된 모든 컨트롤러는 단일 통합 계층 구조(single unified hierarchy)이다.(다른) 컨트롤러가 v1 및 v2 계층 아래에 동시에 마운트될 수 있지만 v1 및 v2 계층 모두에서 동일한 컨트롤러를 동시에 마운트할 수는 없다.cgroups v2의 새로운 동작은 다음과 같이 요약된다. Cgroups v2는 모든 컨트롤러가 마운트되는 통합 계층 구조를 제공한다. “내부(Internal)” 프로세스는 허용되지 않는다. 루트 cgroup을 제외하고 프로세스는 리프 노드(하위 cgroup을 포함하지 않는 cgroup)에만 상주할 수 있다. active? cgroups는 cgroup.controllers 및 cgroup.subtree_control 파일을 통해 지정해야 한다. tasks 파일이 제거되었다. 또한 cpuset 컨트롤러에서 사용하는 cgroup.clone_children 파일도 제거되었다. cgroup.events 파일에서 빈 cgroup 알림을 위한 개선된 매커니즘을 제공한다.Cgroups v2 unified hierarchycgroups v1에서 서로 다른 계층에 대해 각기 다른 컨트롤러를 마운트하는 기능은 애플리케이션 설계에 있어서 큰 유연성을 허용하기 위함이었다.그러나 실제로 유연성은 예상보다 덜 유용했고 경우에 따라 복잡성이 추가되었다.따라서 cgroups v2에서는 사용 가능한 모든 컨트롤러는 단일 계층 구조에 마운트된다.다음과 같은 명령 사용을 통해 cgorups v2 filesystem을 마운트 할 때 컨트롤러를 지정할 필요가 없다(또는 가능하지 않다):mount -t cgroup2 none /mnt/cgroup2cgroups v2 컨트롤러는 cgroups v1 계층 구조에서 마운트되지 않은 경우에만 사용할 수 있다.다르게 말하면 v1 계층 구조와 v2 계층 구조 모두에서 동일한 컨트롤러를 사용할 수 없다.즉, v1 컨트롤러를 먼저 마운트 해제해야 v2에서 해당 컨트롤러를 사용할 수 있다.systemd는 기본적으로 일부 v1 컨트롤러를 많이 사용하기 때문에 어떤 경우에서든선택한 v1 컨트롤러가 비활성화된 상태에서 시스템을 부팅하는 것이 더 간단할 수 있다.커널 부팅 명령줄에서 cgroup_no_v1=list 옵션을 지정하면 된다.여기에서 list는 비활성화할 컨트롤러 이름을 쉼표로 구분한 리스트이며 모든 v1 컨트롤러를 비활성화하려면 all을 사용하면 된다.최근 많은 시스템에서 systemd는부팅 프로세스 동안 /sys/fs/cgroup/unified에 cgroup2 filesystem을 자동으로 마운트한다.Cgroups v2 mount optionscgroups v2 filesystem을 마운트할 때 다음 옵션(mount -o)을 지정할 수 있다. nsdelegate cgroup namespaces를 위임 경계?(delegation boundaries)로 취급한다. memory_localevents memory.events는 cgroup 자체에 대한 통계만 표시해야 하며 하위 cgroups에 대해서는 표시하지 않아야 한다(Linux 5.2 이전 동작).Linux 5.2부터는 memory.events에 하위 cgroups에 대한 통계를 포함하는 것이며 이 마운트 옵션을 사용해 레거시 동작으로 되돌릴 수 있다.이 옵션은 시슽메 전체에 적용되며 마운트 시 설정하거나 초기 마운트 네임스페이스에서만 다시 마운트를 해 수정할 수 있다.Cgroups v2 controllers다음 컨트롤러들이 cgroups v2에서 지원된다. cpu cgroups v1에서의 cpu와 cpuacct 컨트롤러의 후속 컨트롤러 cpuset cgroups v1과 동일 freezer cgroups v1과 동일 hugetlb cgroups v1과 동일 io cgroups v1에서의 blkio 컨트롤러의 후속 컨트롤러 memory cgroups v1과 동일 perf_event cgroups v1과 동일 pids cgroups v1과 동일 rdma cgroups v1과 동일cgroups v1의 net_cls 및 net_prio 컨트롤러에 직접적으로 대응되는 컨트롤러는 없다.대신 iptables에 지원이 추가되어 cgroups v2 경로 이름에 연결하는 eBPF 필터가 cgroup 기준으로 네트워크 트래픽에 대한 결정을 내릴 수 있다.v2 devices 컨트롤러는 인터페이스 파일을 제공하지 않는다.대신 eBPF(BPF_CGROUP_DEVICE) 프로그램을 cgroup v2에 연결해 디바이스를 제어한다.Cgroups v2 subtree controlv2 계층 구조의 각 cgroup에는 다음 두 파일이 포함된다. cgroup.controllers 이 읽기 전용 파일은 해당 cgorup에서 사용 가능한 컨트롤러의 리스트를 보여준다.이 파일의 내용은 상위 cgorup이 있는 cgroup.subtree_control 파일의 내용과 일치한다. cgroup.subtree_control cgroup에서 활성화된 컨트롤러의 리스트이다.이 파일의 컨트롤러 집합은 해당 cgroup의 cgroup.controllers에 있는 집합의 하위 집합이다.활성? 컨트롤러 세트는 다음 예와 같이 공백으로 구분된 컨트롤러 이름을 포함하는 문자열의각 이름 앞에 ‘+’(컨트롤러 활성화) 또는 ‘-‘(컨트롤러 비활성화)을 이 파일에 작성한다. echo '+pids -memory' &gt; x/y/cgroup.subtree_control cgroup.controllers에 없는 컨트롤러를 활성화하려고 하면 cgroup.subtree_control 파일에 쓸 때 ENOENT 에러가 발생한다. cgroup.subtree_control의 컨틀롤러 리스트는 해당 cgroup.controller의 하위 집합이기 때문에계층 구조의 한 cgroup에서 비활성화된 컨트롤러는 해당 cgroup 아래의 하위 트리에서 다시 활성화할 수 없다.cgroup의 cgroup.subtree_control 파일은 하위 cgroup에서 실행되는 컨트롤러 세트를 결정한다.컨트롤러(e.g., pids)가 상위 cgroup의 cgroup.subtree_control 파일에 있으면 해당 컨트롤러 인터페이스 파일(e.g., pids.max)이해당 cgroup의 하위에 자동으로 생성되고 이를 사용하여 하위 cgroup의 리소스를 제어할 수 있다.Cgroups v2 “no internal processes” rulecgroups v2는 “내부 프로세스 없음(no internal processes)”이라 불리는 규칙을 시행한다.대략 말해보자면 루트 cgroup을 제외하고 프로세스들은 리프 노드(하위 cgroups를 포함하지 않는 cgroup)에만 상주할 수 있음을 의미한다.이렇게 하면 cgroup A의 구성원인 프로세스와 A의 하위 cgroup에 있는 프로세스 간에 리소스를 분할하는 방법을 결정할 필요가 없다.Kubernetes cgroups쿠버네티스에서는 cgroup을 어떻게 사용할까Runkubernetes 역시 /sys/fs/cgroup을 cgroup의 path로 사용한다.➜ ~ ls /sys/fs/cgroup cgroup.controllers cgroup.stat cpuset.cpus.effective dev-mqueue.mount io.pressure memory.numa_stat proc-sys-fs-binfmt_misc.mount sys-kernel-tracing.mountcgroup.max.depth cgroup.subtree_control cpuset.mems.effective init.scope io.prio.class memory.pressure sys-fs-fuse-connections.mount system.slicecgroup.max.descendants cgroup.threads cpu.stat io.cost.model io.stat memory.stat sys-kernel-config.mount user.slicecgroup.procs cpu.pressure dev-hugepages.mount io.cost.qos kubepods misc.capacity sys-kernel-debug.mount➜ ~ cd /sys/fs/cgroup/kubepods➜ kubepods lsbesteffort cgroup.max.descendants cpu.max cpuset.mems.effective hugetlb.2MB.events io.prio.class memory.low memory.swap.current pids.eventsburstable cgroup.procs cpu.max.burst cpu.stat hugetlb.2MB.events.local io.stat memory.max memory.swap.events pids.maxcgroup.controllers cgroup.stat cpu.pressure cpu.uclamp.max hugetlb.2MB.max io.weight memory.min memory.swap.high rdma.currentcgroup.events cgroup.subtree_control cpuset.cpus cpu.uclamp.min hugetlb.2MB.rsvd.current memory.current memory.numa_stat memory.swap.max rdma.maxcgroup.freeze cgroup.threads cpuset.cpus.effective cpu.weight hugetlb.2MB.rsvd.max memory.events memory.oom.group misc.currentcgroup.kill cgroup.type cpuset.cpus.partition cpu.weight.nice io.max memory.events.local memory.pressure misc.maxcgroup.max.depth cpu.idle cpuset.mems hugetlb.2MB.current io.pressure memory.high memory.stat pids.current/sys/fs/cgroup 바로 아래에 /kubepods 폴더가 존재한다. cgroups v2를 사용하는 시스템이라?실제로 현재 사용 중인 Linux system은 cgroup2fs type을 사용하는 걸로 나온다.➜ kubepods stat /sys/fs/cgroup -f File: \"/sys/fs/cgroup\" ID: 0 Namelen: 255 Type: cgroup2fsBlock size: 4096 Fundamental block size: 4096Blocks: Total: 0 Free: 0 Available: 0Inodes: Total: 0 Free: 0BestEffort새 busybox 파드를 배포해보자.apiVersion: v1kind: Podmetadata: name: busyboxspec: containers: - image: busybox command: - sleep - \"3600\" imagePullPolicy: IfNotPresent name: busybox restartPolicy: Always파드는 다음과 같이 잘 배포되었다.해당 파드의 uid가 8fea8dd7-a6d2-4319-936f-d81bf4942cc2이고busybox 컨테이너의 id가 4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e인 것을 확인할 수 있다.➜ Workspace k apply -f busybox.yamlpod/busybox created➜ Workspace k get po NAME READY STATUS RESTARTS AGEbusybox 1/1 Running 0 8s➜ Workspace k get po -o yaml | grep uid uid: 8fea8dd7-a6d2-4319-936f-d81bf4942cc2➜ Workspace k get po -o yaml | grep containerID - containerID: containerd://4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e지금 해당 값들을 확인하는 이유는 kubernetes가 이 값들을 사용해 하위 cgroup을 구성하기 때문이다.cgroups path를 확인해보자.busybox 파드에 아무런 resources 설정을 하지 않았기 때문에 QoS는 BestEffort이므로 해당 폴더를 확인해보면 된다.➜ ~ ls /sys/fs/cgroup/kubepods/besteffort cgroup.controllers cgroup.subtree_control cpuset.cpus.effective cpu.weight.nice io.pressure memory.low memory.swap.events pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2cgroup.events cgroup.threads cpuset.cpus.partition hugetlb.2MB.current io.prio.class memory.max memory.swap.high rdma.currentcgroup.freeze cgroup.type cpuset.mems hugetlb.2MB.events io.stat memory.min memory.swap.max rdma.maxcgroup.kill cpu.idle cpuset.mems.effective hugetlb.2MB.events.local io.weight memory.numa_stat misc.currentcgroup.max.depth cpu.max cpu.stat hugetlb.2MB.max memory.current memory.oom.group misc.maxcgroup.max.descendants cpu.max.burst cpu.uclamp.max hugetlb.2MB.rsvd.current memory.events memory.pressure pids.currentcgroup.procs cpu.pressure cpu.uclamp.min hugetlb.2MB.rsvd.max memory.events.local memory.stat pids.eventscgroup.stat cpuset.cpus cpu.weight io.max memory.high memory.swap.current pids.max➜ ~ ls /sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc24b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e cgroup.stat cpuset.cpus.effective hugetlb.2MB.current io.stat memory.numa_stat misc.max862ac391170008426a5fb8ea84ebe78093fb78ed6a311eba9d1bce0e102e3752 cgroup.subtree_control cpuset.cpus.partition hugetlb.2MB.events io.weight memory.oom.group pids.currentcgroup.controllers cgroup.threads cpuset.mems hugetlb.2MB.events.local memory.current memory.pressure pids.eventscgroup.events cgroup.type cpuset.mems.effective hugetlb.2MB.max memory.events memory.stat pids.maxcgroup.freeze cpu.idle cpu.stat hugetlb.2MB.rsvd.current memory.events.local memory.swap.current rdma.currentcgroup.kill cpu.max cpu.uclamp.max hugetlb.2MB.rsvd.max memory.high memory.swap.events rdma.maxcgroup.max.depth cpu.max.burst cpu.uclamp.min io.max memory.low memory.swap.highcgroup.max.descendants cpu.pressure cpu.weight io.pressure memory.max memory.swap.maxcgroup.procs cpuset.cpus cpu.weight.nice io.prio.class memory.min misc.current➜ ~ ls /sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2/4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7ecgroup.controllers cgroup.stat cpu.pressure cpu.uclamp.max hugetlb.2MB.max io.weight memory.min memory.swap.high rdma.currentcgroup.events cgroup.subtree_control cpuset.cpus cpu.uclamp.min hugetlb.2MB.rsvd.current memory.current memory.numa_stat memory.swap.max rdma.maxcgroup.freeze cgroup.threads cpuset.cpus.effective cpu.weight hugetlb.2MB.rsvd.max memory.events memory.oom.group misc.currentcgroup.kill cgroup.type cpuset.cpus.partition cpu.weight.nice io.max memory.events.local memory.pressure misc.maxcgroup.max.depth cpu.idle cpuset.mems hugetlb.2MB.current io.pressure memory.high memory.stat pids.currentcgroup.max.descendants cpu.max cpuset.mems.effective hugetlb.2MB.events io.prio.class memory.low memory.swap.current pids.eventscgroup.procs cpu.max.burst cpu.stat hugetlb.2MB.events.local io.stat memory.max memory.swap.events pids.maxbusybox 파드의 uid, containerID와 일치하는 cgroup이 kubepods/besteffort/ 아래에 계층 구조로 만들어진걸 확인할 수 있다./sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2 cgroup 아래에 두 개의 cgroup이 있는 것을 볼 수 있는데,하나(4b96c3..)는 busybox 컨테이너이고 다른 하나(862ac3..)는 해당 파드의 pause 컨테이너이다. 이는 cgroup.procs 파일로 확인 가능하다.➜ ~ cat /sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2/862ac391170008426a5fb8ea84ebe78093fb78ed6a311eba9d1bce0e102e3752/cgroup.procs 616545➜ ~ ps aux | grep 616545 65535 616545 0.0 0.0 972 4 ? Ss 23:06 0:00 /pause➜ ~ cat /sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2/4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e/cgroup.procs 616691➜ ~ ps aux | grep 616691 root 616691 0.0 0.0 1320 4 ? Ss 23:07 0:00 sleep 3600cpu, memory 확인cgroups v1과는 다르게 생겼다..v1에서는 cpu.shares, cpu.cfs_period_us, cpu.cfs_quota_us로 확인이 됐었는디➜ ~ cd /sys/fs/cgroup/kubepods/besteffort/pod8fea8dd7-a6d2-4319-936f-d81bf4942cc2/4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e ➜ 4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e grep \"\" cpu.*cpu.idle:0cpu.max:max 100000cpu.max.burst:0cpu.pressure:some avg10=0.00 avg60=0.00 avg300=0.00 total=325cpu.pressure:full avg10=0.00 avg60=0.00 avg300=0.00 total=325cpu.stat:usage_usec 11315cpu.stat:user_usec 0cpu.stat:system_usec 11315cpu.stat:nr_periods 0cpu.stat:nr_throttled 0cpu.stat:throttled_usec 0cpu.uclamp.max:maxcpu.uclamp.min:0.00cpu.weight:1cpu.weight.nice:19파드 내 resources 스펙이 어떻게 매칭되는지ResourceConfigForPod 에서 확인해보자. 파드 내 컨테이너들의 리소스 requests, limits를 더한다. cpuRequests / cpuLimits / memoryLimits에 대입한다. cpuRequests &lt;- requests[cpu] cpuLimits &lt;- limits[cpu] memoryLimits &lt;- limits[memory] 2.에서 구한 값들을 CFS 값으로 변경한다. cpuShares(min: 2, max: 262144) &lt;- MilliCPUToShares(cpuRequests) cpuQuota &lt;- MulliCPUToQuota(cpuLimits) 결과적으로 해당 값들은 Resources 타입으로libcontainer의 Set 메서드의 인자로 전달된다.cgroups v1의 경우 호출되는 Set 에 의해다음과 같이 설정된다. cpuShares -&gt; cpu.shares cpuPeriod -&gt; cpu.cfs_period_us cpuQuota -&gt; cpu.cfs_quota_us cpu.shares cgroup의 작업에 사용 가능한 상대적인 cpu 시간을 지정할 수 있다.cpu.shares가 100으로 동일하게 설정된 두 cgroup의 작업은 동일한 비율의 cpu 시간을 사용할 수 있지만cpu.shares가 200으로 설정된 cgroup의 작업은 cpu.shares가 설정된 cgroup의 작업보다 2배의 cpu 시간이 허용된다. cpu.cfs_period_us cpu 리소스에 대한 cgroup의 접근이 이루어지는 주기를 나타낸다. 단위는 마이크로초이며 상한은 1초, 하한은 1000마이크로초이다. cpu.cfs_qouta_us cgroup의 작업이 한 주기(cpu.cfs_period_us) 동안 실행될 수 있는 총 시간을 나타낸다. 역시 마이크로초 단위이며 cgroup에 할당된 시간을 사용하는 즉시 나머지 시간 동안은 접근이 제한되고다음 주기가 올 때까지 실행이 허용되지 않는다. cgorup의 작업이 1초 중 0.2초 동안 단일 cpu에 접근할 수 있어야 하는 경우 cpu.cfs_quota_us를 200,000으로 설정하고cpu.cfs_period_us를 1,000,000으로 설정하면 된다. 또한 cgroup 내의 프로세스가 2개의 cpu를 사용할 수 있게 허용하려면 cpu.cfs_quota_us를 200,000으로,cpu.cfs_period_us를 100,000으로 설정하면 된다. 이 값이 -1(기본값)일 경우는 제한이 없다는 뜻이다.(https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu)cgrpus v2의 경우는 Set에 의해 다음과 같이 설정된다. cpuShares -&gt; cpuWeight -&gt; cpu.weight cpuQuota cpuPeriod -&gt; cpu.max cpu.weight 가중치 기반 cpu 시간 분포 모델 처리를 위한 값이다. 기본값은 100이며,cpu 시간을 하위 cgroup들에게 분배할 때 모든 cpu.weight 값을 합산하여 가중치 비례에 따른 상대적인 cpu 시간을 얻을 수 있도록 한다.즉, 모든 cpu.weight 파일의 값이 동일하면 모든 하위 cgroup들은 동일한 cpu 시간을 사용할 수 있게 된다.이 값은 서로 다른 경우에만 중요하다. cpu.max 최대 대역폭 제한이며, $MAX $PERIOD 형식으로 설정된다.각 cgroup이 period 기간 내에서 최대 max까지 cpu를 사용할 수 있음을 나타낸다.$MAX에 max를 기입하면 제한이 없음을 나타낸다.(https://docs.kernel.org/admin-guide/cgroup-v2.html)memory쪽은 일단 이정도만 보자.➜ 4b96c3c56e7a5b1596ff64c58cfa7fdad52de3017918071fcc3229091b4f0c7e grep \"\" memory.*memory.current:237568...memory.high:maxmemory.low:0memory.max:maxmemory.min:0... memory.high 메모리 사용량에 대한 throttle(soft) 제한이다.cgroup의 메모리 사용량이 여기에 지정된 상한선을 넘어가면 cgroup의 프로세스는 스로틀링이 걸리고 상당한 메모리 회수에 대한 압박을 받게 된다.여기에서 프로세스에 작용되는 스로틀링은 상한선을 넘어가는 순간 메모리를 스왑해 디스크로 옮기고 최대한 상한선을 유지하도록 한다.기본값은 max이며 제한이 없음을 의미한다. memory.low 이 값만큼의 메모리는 회수되지 않는다는 soft 보증을 위한 설정이다. memory.max 메모리 사용량에 대한 hard 제한이다.cgroup의 메모리 사용량이 이 제한에 도달하고 줄일 수 없게 되면 OOM Killer가 호출되어 매커니즘에 따라 프로세스를 죽이게 된다. memory.min cgroup이 확보해야하는 최소한의 메모리를 나타낸다.해당 값을 확보할 수 없는 경우에 OOM Killer가 호출된다.(https://facebookmicrosites.github.io/cgroup2/docs/memory-controller.html)oom_score도 보자.QoS가 BestEffort이므로 oom_score_adj는 1000으로 설정되어 있다.➜ ~ grep \"\" /proc/616691/oom_score*/proc/616691/oom_score:1332/proc/616691/oom_score_adj:1000시간 날 때 이어서 정리..BurstableGuaranteed" }, { "title": "Scheduling In Go II - Go Scheduler", "url": "/posts/scheduling-in-go-02/", "categories": "go", "tags": "go, scheduler, os", "date": "2022-04-19 22:00:00 +0900", "snippet": " Scheduling In Go : Part II - Go Scheduler를 옮긴 글PreludeGo의 스케줄러 내부가 돌아가는 메커니즘(mechanics)과 의미(semantics)에 대한 이해를 제공할 3부작 시리즈의 첫번째 게시물이다.첫번째 게시물은 운영체제 스케줄러에 중점을 둔다.3부작: Scheduling In Go : Part I - OS Scheduler Scheduling In Go : Part II - Go Scheduler Scheduling In Go : Part III - ConcurrencyIntroduction스케줄링 시리즈의 첫 파트에서 Go 스케줄러의 구조를 이해하고 인지하는데 중요하다고 생각되는 운영체제의 스케줄러 관점에서 설명했다.이번 게시글에서는 Go 스케줄러가 동작하는 방식을 의미론적 수준에서 설명하고, 고수준의 동작에 초점을 맞출 것이다.Go 스케줄러는 복잡한 시스템이며 아주 조그만 메카니컬한 세부사항은 보다는 그것이 어떻게 동작하고 행동하는지에 대한 좋은 시야를 가지는 것이 중요하다.이는 당신이 더 나은 엔지니어링 결정을 하도록 도와줄 것이다.Your Program StartsGo 프로그램이 시작될 때, 호스트 머신에서 식별되는 모든 가상 코어(virtual core)에 대해 논리 프로세서(Logical Processor) P가 제공된다.물리적 코어당 여러 개의 하드웨어 스레드(hardware thread)가 있는 프로세서(Hyper-Threading1)가 있는 경우,각 하드웨어 스레드는 Go 프로그램에서 가상 코어로 표시된다.더 나은 이해를 위해 한 맥북 프로 모델의 시스템 리포트를 살펴보자.그림 14개의 물리적 코어가 있는 단일 프로세서가 있음을 확인할 수 있다.이 리포트에서는 물리적 코어 당 하드웨어 스레드의 수를 보여주지 않지만 이 맥북 프로가 보유한Intel Core i7 프로세서에는 물리적 코어 당 2개의 하드웨어 스레드를 가지는 하이퍼 스레딩 기능이 있다.운영체제 스레드를 병렬로 실행하려 할 때, 8개의 가상 코어를 사용할 수 있다는것을 Go 프로그램이 알게 된다.이를 테스트하기 위한 아래의 프로그램을 보자:package mainimport (\t\"fmt\"\t\"runtime\")func main() { // NumCPU returns the number of logical // CPUs usable by the current process. fmt.Println(runtime.NumCPU())}그림 1.의 머신에서 이 프로그램을 실행하면 NumCPU() 함수 호출의 결과는 8이 될 것이다.해당 머신에서 실행되는 모든 Go 프로그램에는 8개의 P가 주어진다.모든 P에는 운영체제 스레드 M이 할당된다.이 스레드는 여전히 운영체제에 의해 관리되며 지난 게시글에서 설명한바와 같이 운영체제는 실행을 위해 코어에 스레드를 배치할 책임이 있다.즉, 위 머신에서 Go 프로그램을 실행할 때 작업을 수행하는데 사용가능한 8개의 스레드가 존재하며 각각 P에 개별적으로 연결된다.모든 Go 프로그램에는 Go 프로그램의 실행 경로인 초기 고루틴(initial Goroutine) G가 주어진다.고루틴은 본질적으로 Coroutine2이지만 여기는 Go 세상이므로, 문자 C를 G로 바꾼 고루틴이라 불리게 된다.고루틴은 애플리케이션 수준의 스레드로 생각할 수 있으며 여러 면에서 운영체제의 스레드와 유사하다.운영체제 스레드는 컨텍스트 전환을 각 코어에서 하지만, 고루틴은 운영체제 스레드 M에서 컨텍스트 전환이 이루어 진다.퍼즐의 마지막 조각은 실행 큐(run queue)이다.Go 스케줄러에는 전역 실행 큐(Global Run Queue, GRQ)와 로컬 실행 큐(Local Run Queue,LRQ)라는 두 가지의 실행 큐가 있다.각 P에는 P의 컨텍스트 내에서 실행되도록 할당된 고루틴을 관리하는 LRQ가 주어진다.LRQ 내 고루틴들은 해당 P에 할당된 M에서 컨텍스트 전환되며 각자의 작업을 위한 시간을 갖는다.GRQ는 아직 P에 할당되지 않은 고루틴들을 위한 것으로 GRQ에서 LRQ로 이동하는 고루틴들의 프로세스는 이후에 논의될 것이다.그림 2.는 이 모든 구성 요소의 대한 전체적인 이미지를 제공한다.그림 2Cooperating Scheduler앞선 게시글에서 의논했던 바와 같이 운영체제 스케줄러는 선점형 스케줄러이며 이는 스케줄러가 특정 주어진 시간에 무엇을 할지 예상할 수 없다는 것을 의미한다.커널이 내리는 결정은 모두 비결정적이다.운영제체에서 실행되는 애플리케이션들은 원자적(atomic3) 명령어 및 뮤텍스(mutex4) 호출과 같은 동기화 요소들을 활용하지 않는 한스케줄링을 통해 커널에서 내부에서 일어날 일들을 제어할 수 없다.Go 스케줄러는 Go 런타임의 일부이며, Go 런타임은 애플리케이션에 내장되어 있다.이는 Go 스케줄러가 커널 위의 사용자 영역5에서 실행된다는 것을 의미한다.현재 Go 스케줄러의 구현은 선점형 스케줄러가 아니라 협조적(cooperating6) 스케줄러이며,이러한 협조적 스케줄러는 스케줄링 결정을 내리기 위해 코드의 안전한 지점에서 발생하는 잘 정의된 사용자 영역의 이벤트가 필요하다.Go 협조적 스케줄러의 놀라운 점은 선점형처럼 동작한다는 것인데, 사용자는 Go 스케줄러가 무엇을 할 지 예측하기가 어렵다.이 협력형 스케줄러에 대한 의사 결정은 개발자가 아니라 Go 런타임이 하기 때문이다.이렇듯 Go 스케줄러를 선점형 스케줄러로 생각하는 것이 중요하며 스케줄러는 비결정적이기 때문에 크게 확장되지 않는다.Goroutine States고루틴은 스레드와 동일한 3가지 형태의 고수준 상태를 가진다.고루틴이 수행하게될 역할을 Go 스케줄러가 지시하게 되며, 고루틴은 다음 3개의 상태 중 하나가 될 수 있다: Waiting 고루틴은 중지되었으며 작업이 계속되기 위한 무언가를 기다리고 있음을 의미한다.이는 운영체제 시스템 콜이나 atomic 및 mutex 연산과 같은 동기화 호출을 기다리는 것과 같은 이유로 발생될 수 있다.이러한 유형의 대기 시간은 성능 저하의 근본 원인이 된다. Runnable 고루틴이 할당된 명령어들을 실행할 수 있도록 M에 배치되기를 원하는 상태이다.배치되기를 원하는 고루틴들이 많이 있으면, 더 오랜 시간을 기다려야 한다.또한 각 고루틴에게 주어질 시간의 양은 더 많은 고루틴들이 경쟁을 할수록 짧아진다.이 유형의 대기 시간 또한 성능 저하의 원인이 된다. Executing 고루틴이 M에 배치됐고 명령어를 실행하고 있음을 의미한다.애플리케이션과 관련된 작업이 수행되며 모두가 원하는 것 이다.Context SwitchingGo 스케줄러는 컨텍스트 전환을 위한 코드 내 안전한 지점에서 발생할 잘 정의된 사용자 영역의 이벤트가 필요하다.이러한 이벤트와 안전한 지점은 함수 호출 내에서 나타난다.함수 호출은 Go 스케줄러의 상태에 매우 중요한 요인으로, 오늘날 (1.11 버전 이하의 Go)함수 호출을 하지 않는 tight loop7를 실행하면 스케줄러 및 가비지 컬렉션 내에서의 지연 시간이 발생된다.따라서 함수 호출이 합리적인 주기 내에서 발생되는 것이 매우 중요하다. Node: tight loop의 선점을 허용하기 위한 Go 스케줄러 내부의 비협조적 선점 기술을 적용하기 위해 승인된 1.12 버전에 대한 제안 이 있다.Go 프로그램에는 스케줄러의 스케줄링 결정이 발생하도록 하는 4가지 이벤트가 존재한다. The use of the keyword go go 키워드는 고루틴을 생성하는 방법이다.새로운 고루틴이 생성되면 스케줄러에게 스케줄링 결정을 내릴 수 있는 기회를 제공한다. Garbage collection GC는 자체 고루틴 세트를 사용해 실행되기 때문에, 이러한 고루틴들은 M에 배치된 후 실행되어야 한다.이로 인해 GC는 스케줄링의 많은 혼란을 야기하지만 스케줄러는 고루틴이 하는 작업에 대한 해박한 지식이 있으며 현명한 스케줄링 결정을 내리기 위해 해당 지식을 십분 활용할 것이다.이러한 현명한 스케줄링 결정 중 하나는 GC가 발생되는 동안 힙을 건드리지 않는 고루틴과 힙을 건드리려는 고루틴의 컨텍스트 전환이다.GC가 실행될 때에는 수많은 스케줄링 결정이 이루어지게 된다. System calls 고루틴이 M이 차단되도록 만드는 시스템 콜을 발생시키게 되면스케줄러는 해당 고루틴을 M에서 내리고 동일한 M으로 새로운 고루틴을 배치할 수 있다.그러나, P에서 대기 중인 고루틴을 실행하기 위한 새로운 M이 필요한 경우도 있다.이것이 어떻게 작동하는지에 대해 다음 섹션에서 더 자세히 설명하겠다. Synchronization and Orchestration 아토믹, 뮤텍스 또는 채널 작업의 호출로 인해 고루틴이 차단되면 스케줄러는 새로운 고루틴이 실행되도록 컨텍스트 전환 할 수 있다.추후에 차단된 고루틴이 실행될 수 있을 때 큐에 다시 들어가 결과적으로는 컨텍스트 전환을 통해 다시 M에 배치될 것이다.Asynchronous System Calls비동기 시스템 콜을 처리할 수 있는 능력을 가진 운영체제에서는 네트워크 폴러 라 불리는 것을 사용해 시스템 호출을 보다 효율적으로 처리할 수 있다.이는 해당 운영체제 내에서 kqueue(MacOS), epoll(Linux) 또는 iocp(Windows)를 사용하여 수행된다.네트워킹 기반 시스템 콜은 오늘날 우리가 사용하고 있는 많은 운영체제에서 비동기적으로 처리될 수 있다.네트워크 폴러는 네트워킹 작업을 처리하는 것이 주 용도라서 그런 이름을 가지게 되었다.네트워크 폴러를 통해 네트워킹 시스템 호출을 사용하게 되면 스케줄러는 해당 시스템 호출로 인해 고루틴이 M이 차단되도록 하는 것을 방지할 수 있다.이 동작은 새로운 M을 생성할 필요 없이 P의 LRQ에 있는 다른 고루틴이 실행 가능하도록 M을 유지하며 이는 운영체제의 스케줄링 부하를 줄이는 데 도움이 된다.예제를 살펴보자.그림 3그림 3은 기본 스케줄링 다이어그램을 보여준다.G1은 M에서 실행되고 있으며 3개 이상의 고루틴들이 M에 배치되기 위해 LRQ에서 대기하고 있다.Net Poller는 아무런 작업도 수행하지 않는 유휴(idle) 상태이다.그림 4그림 4에서 G1은 네트워크 시스템 콜을 수행하길 원하여 Net Poller로 옮겨졌으며 비동기 네트워크 시스템 호출이 처리되고 있다.G1이 Net Poller로 옮겨질 때, M은 LRQ의 다른 고루틴을 실행할 수 있게 된다.이 경우에서는 G2가 컨텍스트 전환되어 M에 배치되었다.그림 5그림 5에서는 비동기 네트워크 시스템 콜이 Net Poller에서 처리 완료됐으며 G1은 P의 LRQ로 다시 옮겨졌다.이후에 G1이 컨텍스트 전환돼 M에 다시 배치되면 G1이 담당하는 Go 관련 코드가 다시 실행될 것이다.여기에서의 가장 큰 이점이라고 한다면 네트워크 시스템 호출이 실행될 때 추가적인 M이 필요하지 않다는 점이다.Net Poller는 하나의 운영체제 스레드를 가졌으며 효율적으로 돌아가는 이벤트 루프를 처리하고 있다.Synchronous System Calls고루틴이 비동기적으로 동작할 수 없는 시스템 콜을 호출하길 원하면 어떻게 될까?이 경우 네트워크 폴러는 사용될 수 없으며 시스템 콜을 호출하는 고루틴은 M이 차단되게 한다.불행히도 이 동직이 발생되지 않도록 막을 방법은 없다.비동기적으로 호출될 수 없는 시스템 콜의 한 예는 파일 기반 시스템 콜이다.CGO를 사용 중이라면, C 함수를 호출할 때 M 또한 차단되는 상황이 있을 수도 있다. Note: Windows 운영체제는 파일 기반 시스템 콜을 비동기적으로 호출할 수 있다.기술적으로 Windows에서 실행할 때에는 네트워크 폴러를 사용할 수 있다.M이 차단되게 만드는 file I/O와 같은 동기적으로 동작하는 시스템 호출에서는 어떠한 일이 발생되는지 살펴보자.그림 6그림 6은 그림 3에 이어 한번 더 기본 스케줄링 다이어그램을 보여주지만 이번에는 G1이 M1이 차단될 동기적 시스템 콜을 호출할 것이다.그림 7그림 7에서 스케줄러는 G1에 의해 M1이 차단됐음을 식별할 수 있다.이 시점에서 스케줄러는 M1을 G1이 여전히 연결된 채로 P에서 분리한다.그러면 스케줄러는 P가 계속 작업을 할 수 있도록 새로운 M2를 가져온다.LRQ에서 G2가 컨텍스트 전한되어 M2에 배치된다.만약 이전에 발생됐던 위와 같은 스왑으로 인해 다른 M이 이미 존재하는 경우, 이 전환 작업은 새로운 M을 생성하는 것보다 빠를 것이다.그림 8그림 8에서는 G1에 의해 발생된 blocking 시스템 콜이 종료된다.이 시점에서는 G1은 다시 LRQ에 들어가며 P에서 다시 작업을 이어할 수 있게 된다.M1은 해당 시나리오가 다시 발생될 때 사용할 수 있도록 사이드에 배치된다.Work Stealing스케줄러의 또 다른 측면은 작업을 훔치는 스케줄러라는 것이다.이는 스케줄링을 효율적으로 유지하는 데 몇 가지 영역에서 도움이 된다.예를 들어, M이 waiting 상태로 전환되면 운영체제가 M을 코어에서 컨텍스트 전환하기 때문에 M이 waiting 상태로 전환되는 것은 바람직하지 않다.즉, runnable 상태의 고루틴이 있더라도 M이 코어에서 컨텍스트 전환될 때까지 P는 어떠한 작업도 완료할 수 없음을 의미한다.작업 훔치기는 모든 P에 걸쳐 고루틴의 균형을 유지하여 작업이 더 잘 분산되고 더 효율적으로 수행되도록 도와준다.예제를 살펴보자.그림 9그림 9는 각각 4개의 고루틴을 포함하는 2개의 P와 GRQ에 있는 하나의 고루틴을 가진 멀티스레드 Go 프로그램을 나타낸다.2개의 P 중 하나가 모든 고루틴을 빠르게 처리하면 어떤 일이 발생될까?그림 10그림 10에서 P1에는 더 이상 실행할 고루틴이 없다.하지만 P2의 LRQ에도, 외부의 GRQ에도 runnable 상태의 고루틴들이 기다리고 있다.여유가 생긴 P1이 작업을 훔칠 필요가 있는 순간이라고 할 수 있겠다.작업 훔치기(stealing work8)의 규칙은 다음과 같다.runtime.schedule() { // only 1/61 of the time, check the global runnable queue for a G. // if not found, check the local queue. // if not found, // try to steal from other Ps. // if not, check the global runnable queue. // if not found, poll network.} wq: 위의 stealing work 규칙과는 실제 코드 구현이 조금 달라보여서 추가로 정리해보고자 한다. 공정성을 보장하기 위해 스케줄러는 가끔(schedtick%61 == 0일 때 마다) GRQ를 확인한다. 그렇지 않으면 두 고루틴이 서로를 지속적으로 재호출하여 LRQ를 완전히 차지하게 된다. GRQ에서 찾은게 없다면 LRQ에서 고루틴을 가져온다. LRQ에서도 찾은게 없다면, 싫행 가능한 고루틴을 찾을 때까지 이후 작업은 차단된다. LRQ를 확인한다. GRQ를 확인한다. 네트워크를 폴링한다. 네트워크 폴러로부터 실행 가능한 고루틴을 가져온다. 다른 P에서 작업을 훔쳐온다. 예를 들어 P2의 LRQ에 있는 고루틴의 절반을 가져와서 P1의 LRQ에 넣는다. 아직까지도 고루틴을 찾지 못한거면 할 일이 없는거다. 그럼에도 P를 그냥 포기하는 것은 아쉬우니 GC 마크 단계에 있다면 유휴 시간 마킹이라도 한다. wasm일 경우, 콜백이 반환되었지만 다른 고루틴이 깨어 있지 않다면 콜백이 트리거될 때까지 실행을 일시 중지하는 이벤트 핸들러 고루틴을 깨운다. 위의 룰에 따라, P1은 P2의 LRQ에서 고루틴을 확인하고 찾은 것의 절반을 가져와야 한다. wq: 이 부분에서 설명해주는 동작이 최신 코드 구현과는 다르므로 감안해서 보도록 하자.그림 11P1은 P2의 LRQ로부터 절반의 고루틴을 가져와서 실행한다.만약 P2가 모든 고루틴의 실행을 마치고 P1의 LRQ에도 고루틴이 없다면 어떻게 될까?그림 12그림 12에서 P2는 모든 작업을 마쳤으며 고루틴 몇개를 훔칠 필요성이 생겼다.우선 P1의 LRQ를 살펴보지만 가져올 고루틴은 보이지 않는다.다음 순으로 GRQ를 확인한다. 여기에서 고루틴 G9을 찾을 수 있다.그림 13그림 13에서는 P2는 GRQ의 G9을 훔쳐오고 해당 고루틴의 작업을 실행한다.이러한 작업 훔치기의 장점은 M 모두가 바쁘게 지내며 유휴 상태가 되지 않도록 해준다는 것이다.작업 훔치기는 내부적으로는 M을 회전(spinning)시키는 것으로 간주된다.이 회전에서는 JBD가 작성한 블로그 게시물에서 또 다른 이점에 대해 잘 설명해주고 있다.Practical Example메커니즘과 의미에 대한 이해를 갖춘 상태에서 이 모든 것이 결합되어 Go 스케줄러가 시간이 지남에 따라더 많은 작업을 수행할 수 있도록 하는 방법을 보여주고자 한다.두 개의 운영체제 스레드를 사용하여 프로그램이 서로 메시지를 주고 받도록 하는 C로 작성된 멀티스레드 애플리케이션을 떠올려보자.그림 14그림 14에는 메시지를 앞뒤로 전달하는 2개의 스레드가 있다.Thread 1이 Code 1에서 컨텍스트 전환되어 실행 중이므로 Thread 1이 Thread 2로 메시지를 보낼 수 있다. Node: 메시지가 전달되는 방식은 중요하지 않다. 중요한 것은 이 작업들이 진행되는 동안의 스레드들의 상태이다.그림 15그림 15에서 Thread 1이 메시지 전송을 마치면 이제 응답을 기다려야 한다.이렇게 되면 Thread 1은 컨텍스트 전환되어 Core 1에서 내려간 후 waiting 상태가 된다.Thread 2가 메시지를 전달받으면 runnable 상태가 되고, 운영체제는 컨텍스트 전환을 수행해 Core 2에서 Thread 2를 실행할 수 있다.그런 다음 Thread 2는 메시지를 처리하고 새로운 메시지를 Thread 1에게 다시 보낸다.그림 16그림 16에서 Thread 2의 메시지가 Thread 1에 수신됨에 따라 스레드는 컨텍스트 전환을 다시 한 번 수행한다.이제 Thread 2는 executing 상태에서 waiting로, Thread 1은 waiting 상태에서 runnable 상태로 컨텍스트 전환되고최종적으로는 executing 상태로 다시 전환되어서 새 메시지를 처리하고 보낼 수 있게 된다.이러한 모든 컨텍스트 전환과 상태 변경에는 작업을 빠르게 완료하기 위한 제한된 수행 시간이 필요하다.각 컨텍스트 전환은 최대 1000 나노초의 지연 시간이 발생될 수 있으며 하드웨어가 나노초 당 12개의 명령어를 수행하기를 기대하는 상황에서는대략 1,200개의 명령어가 컨텍스트 전환 중에는 실행되지 못한다.이러한 스레드들도 서로 다른 코어에 배치되기 때문에 캐시 라인 누락으로 인한 추가 지연 시간이 발생될 가능성도 높다.이제 고루틴과 Go 스케줄러를 사용하는 동일한 예제를 살펴보자.그림 17그림 17엔 서로 오케스트레이션되어 메시지를 주고 받는 두 개의 고루틴이 있다.G1은 자신의 작업을 수행하기 위해 Core 1에 배치되어 있는 M1에서 컨텍스트 전환되며 G2로 메시지를 전달한다.그림 18그림 18에서의 G1 또한 메시지 전송을 마치면 이제 응답을 기다려야 한다.G1은 컨텍스트 전환되어 M1에서 내려가고 waiting 상태가 된다.G2가 G1이 보낸 메시지를 전달받으면 runnable 상태가 된다.이제 Go 스케줄러는 컨텍스트 전환을 수행해 G2가 Core 1에 여전히 배치되어 있는 M1에서 실행되게 한다.그런 다음 G2는 메시지를 처리하고 새로운 메시지를 G1으로 전달한다.그림 19그림 19에서는 G2에서 보낸 메시지가 G1에 전달됨에 따라 다시 한번 컨텍스트 전환된다.이제 G2는 executing 상태에서 waiting 상태로, G1은 waiting 상태에서 runnable 상태로 전환된 후최종적으로는 전달받은 메시지를 처리하고 보낼 executing 상태로 컨텍스트 전환된다.표면적으로는 별반 달라진게 없다.스레드를 사용하든 고루틴을 사용하든 컨텍스트 전환과 상태 변경은 발생될 수 밖에 없다.그러나 스레드와 고루틴의 사용 간에는 언뜻 보기엔 명백하지 않은 큰 차이가 존재한다.고루틴을 사용하는 경우에 모든 처리에 동일한 운영체제 스레드와 코어를 사용한다.이는 운영체제 관점에서 운영체제 스레드는 한 순간이라도 waiting 상태가 되지 않는다는 것을 의미한다.그 결과 스레드를 사용했더라면 컨텍스트 전환으로 인해 손실될 모든 명령어들은 고루틴을 사용할 때는 손실되지 않는다.본질적으로 Go는 IO/Blocking 작업을 운영체제 수준에서 CPU-bound 작업으로 전환한다.모든 컨텍스트 전환이 애플리케이션 수준에서 발생되기 때문에, 스레드를 사용할 때 손실됐던 컨텍스트 전환 시의 최대 12,000개의 명령어는 더이상 손실되지 않는다.Go에서는 이런 동일한 컨텍스트 전환의 비용으로 최대 200 나노초 혹은 2,400개의 명령가 소요된다.스케줄러 또한 효율적인 캐시 라인 효율성과 NUMA를 향상시키는 데도 도움이 된다.이것이 우리가 가상 코어보다 더 많은 스레드를 필요로 하지 않는 이유다.Go 스케줄러가 더 적은 스레드를 사용하고 각 스레드에서 더 많은 작업을 수행하고자 시도하므로 시간이 지남에 따라더 많은 작업을 완료할 수 있으며, 이는 운영체제와 하드웨어의 부하를 줄인다.ConclusionGo 스케줄러는 운영체제와 하드웨어의 작동 방식의 복잡함을 고려하여 설계되었다는 점에서 진심으로 놀라울 따음이다.운영체제 수준에서 IO/Blocking 작업을 CPU-bound 작업으로 전환하는 기능은 시간이 지남에 따라 더 높은 CPU 처리량을 활용하는 데 큰 도움이 된다.다시 한번 말하지만, 가상 코어보다 더 많은 스레드가 필요하지 않는 이유이며가상 코어당 단 하나의 운영체제 스레드만으로 모든 작업(CPU 및 IO/Blocking bound)을 수행할 수 있다.운영체제 스레드를 차단하는 시스템 호출을 필요로 하지 않는 네트워킹 앱 및 기다 앱의 경우 이러한 작업이 가능해진다.개발자는 처리 중인 작업의 종류와 관련해 앱이 수행하는 작업을 이해해야 한다.무한정 많은 고루틴을 만들어서는 놀라운 성능을 기대할 수 없을 것이다.Less is always more, 이러한 Go 스케줄러의 의미를 이해한다면 더 나은 엔지니어링 결정을 내릴 수 있다.다음 게시물에서는 코드에 추가해야 하는 복잡성의 균형을 유지하면서, 더 나은 성능을 얻기 위해 보수적인 방식으로 동시성을 활용하는 아이디어를 살펴보도록 하겠다. Hyper-threading: wikipedia &#8617; Coroutine: wikipedia &#8617; Linearizability: wikipedia &#8617; Lock: wikipedia &#8617; User space: wikipedia &#8617; Cooperative multitasking: wikipedia &#8617; tight loop: wikipedia &#8617; Source file src/runtime/proc.go &#8617; " }, { "title": "Scheduling In Go I - OS Scheduler", "url": "/posts/scheduling-in-go-01/", "categories": "go", "tags": "go, scheduler, os", "date": "2022-04-01 23:00:00 +0900", "snippet": " Scheduling In Go : Part I - OS Scheduler를 옮긴 글PreludeGo의 스케줄러 내부가 돌아가는 메커니즘(mechanics)과 의미(semantics)에 대한 이해를 제공할 3부작 시리즈의 첫번째 게시물이다.첫번째 게시물은 운영체제 스케줄러에 중점을 둔다.3부작: Scheduling In Go : Part I - OS Scheduler Scheduling In Go : Part II - Go Scheduler Scheduling In Go : Part III - ConcurrencyIntroductionGo 스케줄러에 적용된 설계와 동작은 멀티스레드 기반 Go 프로그램이 더육 효율적면서 좋은 성능을 발휘할 수 있게 한다.이는 운영체제(OS) 스케줄러에 대한 Go 스케줄러의 mechanical sympathy1 덕분이며,멀티스레드 애플리케이션을 바르게 설계하기 위해서는 운영체제와 Go 스케줄러가 작동하는 방식에 대한 범용적이고 핵심적인 이해를 갖는 것이 중요하다.앞으로의 게시글에서는 스케줄러에 대한 높은 수준의 메커니즘과 의미론에 초점을 맞추고자 한다.더 나은 엔지니어링 결정을 하기 위해 이러한 것들의 작동 방식에 대한 시각화가 가능하도록 충분한 설명을 제공할 것이다.멀티스레드 애플리케이션 개발에 있어서 엔지니어가 선택해야하는 엔지니어링 결정에는 많은 것들이 있지만,당연하게도 메커니즘과 의미론은 이러한 결정에 필요한 기본 지식의 중요한 부분을 형성해 줄 것이다.OS Scheduler운영체제 스케줄러는 복잡한 소프트웨어 조각이다.스케줄러는 그들이 실행하는 하드웨어의 레이아웃(layout)과 설정(setup)을 고려해야하며고려해야할 사항에는 멀티프로세서와 코어, CPU 캐시 그리고 NUMA가 포함되지만 딱히 이에 국한되진 않는다.이런 지식이 없는 상태에서의 스케줄러 동작에 대한 이해는 효율적일 수 없을 것이다.다행스러운 점이라면 앞서 말한 토픽들에 대해 깊이 들어가지 않고도 운영체제 스케줄러가 작동하는 방식에 대한 훌륭한 Mental model2을 깨닳을 수 있다.프로그램은 순차적으로 실행되어야하는 일련의 기계 명령어이며 이를 위해 운영체제는 스레드라는 개념를 사용한다.할당된 명령어 집합에 대한 책임을 지고 순차적으로 실행하는 것은 스레드가 해야할 일이다.스레드는 더이상 실행할 명령어가 없을 때까지 실행은 계속되며, 이러한 특성때문에 스레드를 “실행 경로”라고 부르기도 한다.실행되는 모든 프로그램은 프로세스를 생성하며 각 프로세스에는 초기 스레드가 제공되고, 각 스레드는 더 많은 스레드를 생성할 수 있다.이러한 스레드들은 서로 독립적으로 실행되며 스케줄링 결정은 프로세스 수준이 아닌 스레드 수준에서 이루어진다.스레드들은 동시(동일 코어에서 빠르게 순차적으로 실행)에 또는 병렬(같은 시간에 다른 코어에서 실행)로 실행될 수 있다.스레드는 자신의 명령어를 안전하고 지역적이며 독립적으로 실행할 수 있도록 자체 상태를 유지한다.운영체제 스케줄러는 실행되어야할 스레드가 있는 경우 코어가 유휴 상태가 아닌지 확인하며또한 실행할 수 있는 모든 스레드가 동시에 실행되고 있다는 착각을 만들어야 한다.이 착각 속에서 스케줄러는 우선 순위가 낮은 스레드보다 높은 우선 순위의 스레드를 실행해야 한다.하지만 우선 순위가 낮은 스레드의 실행 시간이 부족하면 안되기 때문에 스케줄러는 빠르고 현명한 결정을 통해 스케줄링 지연을 가능한 한 최소화해야 한다.이것을 가능케 하기 위해 매우 많은 알고리즘이 사용되고 있지만, 운이 좋게도 이해를 도와줄 수십년의 작업과 경험이 존재해왔다.이 모든 것들을 더 잘 이해하기 위해 중요한 몇가지 개념을 설명하고 정의하는 것이 좋겠다.Executing Instructions명령어 포인터 (IP)라고도 하는 프로그램 카운터3 (PC)는 스레드가 실행할 다음 명령어를 추적할 수 있도록 한다.대부분의 프로세서에서 PC는 현재 명령어가 아닌 다음 명령어를 가리킨다는 것을 명심하자.그림 1https://www.slideshare.net/JohnCutajar/assembly-language-8086-intermediateGo 프로그램에서 스택 추적을 본 적이 있다면, 각 라인의 끝에 있는 작은 16진수 숫자를 봤을 것이다.아래에서 +0x39 와 +0x72 를 확인해보자.goroutine 1 [running]: main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa) stack_trace/example1/example1.go:13 +0x39 main.main() stack_trace/example1/example1.go:8 +0x72해당 숫자들은 각 함수 상단으로부터의 PC 값 오프셋을 나타낸다.+0x39 PC 오프셋은 프로그램이 패닉에 빠지지 않았다면 스레드가 example 함수 내부에서 실행했을 다음 명령어를 나타내고+0x72 PC 오프셋은 제어가 main 함수로 되돌아간 경우의 내부의 다음 명령어이다.더 중요한 것은 그 포인터 이전에 어떤 명령어가 실행되고 있었는지 알려준다는 것이다.위의 스택 추적을 만들어낸 프로그램은 아래와 생겼다.// https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go07 func main() {08 example(make([]string, 2, 4), \"hello\", 10)09 }12 func example(slice []string, str string, i int) {13 panic(\"Want stack trace\")14 }16진수 +0x39 는 함수의 시작 명령어보다 57 (10진수) 바이트 아래에 있는 example 함수 내부의 명령어를 위한 PC 오프셋이다.아래에서처럼 바이너리로부터 example 함수의 objdump를 볼 수 있다.아래 나열된 12번째 명령어의 위 코드 행은 패닉에 대한 호출이다.$ go tool objdump -S -s \"main.example\" ./example1TEXT main.example(SB) stack_trace/example1/example1.gofunc example(slice []string, str string, i int) { 0x104dfa0\t\t65488b0c2530000000\tMOVQ GS:0x30, CX 0x104dfa9\t\t483b6110\t\tCMPQ 0x10(CX), SP 0x104dfad\t\t762c\t\t\tJBE 0x104dfdb 0x104dfaf\t\t4883ec18\t\tSUBQ $0x18, SP 0x104dfb3\t\t48896c2410\t\tMOVQ BP, 0x10(SP) 0x104dfb8\t\t488d6c2410\t\tLEAQ 0x10(SP), BP\tpanic(\"Want stack trace\") 0x104dfbd\t\t488d059ca20000\tLEAQ runtime.types+41504(SB), AX 0x104dfc4\t\t48890424\t\tMOVQ AX, 0(SP) 0x104dfc8\t\t488d05a1870200\tLEAQ main.statictmp_0(SB), AX 0x104dfcf\t\t4889442408\t\tMOVQ AX, 0x8(SP) 0x104dfd4\t\te8c735fdff\t\tCALL runtime.gopanic(SB) 0x104dfd9\t\t0f0b\t\t\tUD2 &lt;--- LOOK HERE PC(+0x39)앞서 말했듯 PC는 현재 명령어가 아니라 다음 명령어이다.우리는 위의 예제를 통해 Go 프로그램의 스레드가 순차적으로 실행을 담당하는 amd64 기반 명령어의 좋은 예를 보았다.Thread States또 다른 중요한 개념은 스케줄러가 스레드와 함께 수행할 역할을 지시하는 스레드 상태이다.스레드는 3가지 상태 중 하나가 될 수 있다. Waiting 스레드가 중지됐으며 작업을 계속하기 위해 무언가를 기다리고 있음을 의미한다.하드웨어(disk, network), 운영체제(system call) 또는 동기화 이벤트(atomic, mutex)를 기다리는 것과 같은 이유 때문일 수 있다.이러한 유형의 지연4은 성능 저하의 근본적인 원인이 된다. Runnable 스레드가 할당된 기계 명령어를 실행할 수 있도록 코어에 배치되기를 원한다는 것을 의미한다.작업 시간을 원하는 스레드가 많으면 많을수록 스레드는 시간을 확보하기 위해 더 오래 기다려야 한다.또한 더 많은 스레드가 시간을 두고 경쟁함에 따라 각 스레드가 얻는 개별적인 작업 시간이 단축된다.이 유형의 스케줄링 지연 또한 성능 저하의 원인이 될 수 있다. Executing 스레드가 코어에 배치되어 기계 명령어를 실행하고 있음을 의미한다.애플리케이션과 연관된 작업이 완료된다.Types Of Work스레드가 할 수 있는 작업엔 두 가지의 유형이 있다. CPU-Bound 스레드가 Waiting 상태에 놓일 수 있는 상황을 만들지 않는 작업니다.끊임없이 계산을 하는 작업이며 예를 들어 Pi를 N번째 자리까지 계산하는 스레드는 CPU 바운드 유형이다. IO-Bound 스레드가 Waiting 상태에 진입하도록 만드는 작업이다.네트워크를 통해 리소스에 대한 접근을 요청하거나 운영체제에 시스템 호출을 하는 작업이다.데이터베이스에 접근해야하는 스레드도 IO 바운드 유형이다.스레드가 이 범주의 일부로 대기하도록 하는 동기화 이벤트(atomic, mutex)를 포함한다.Context SwitchingLinux, Mac 또는 Windows에는 선점형 스케줄러가 존재한다.이는 중요한 것들을 의미하는데, 첫번째로 스케줄러는 주어진 시간에 어떤 스레드가 실행되도록 선택되는지에 관해서 예측할 수 없음을 의미한다.네트워크에서의 데이터 수신과 같은 이벤트와 함께하는 스레드 우선 순위는 스케줄러가 언제 무엇을 할 지 결정하는 것을 불가능하게 만든다.두번째로, 항상 동일하게 발생될 것이라고 보장할 수 없는 운 좋게 경험했던 일부 인지된 동작을 기반으로 코드를 작성하면 안된다는 것을 의미한다.같은 동작이 동일한 방식으로 1000번 발생하는 것을 보았다면 이것은 보장된 동작이라고 생각할 수 있다.애플리케이션에서 결정성이 필요한 경우에는 스레드의 동기화(synchronization) 및 조정, 조율(orchestration)을 잘 제어해야만 한다.하나의 코어에서 스레드를 교환하는 물리적 동작을 컨텍스트 스위치라고 한다.컨텍스트 스위치는 스케줄러가 코어에 배치된 Executing 스레드를 내리고 그 자리에 Runnable 스레드를 배치할 때 발생된다.실행 큐(run queue)에서 선택된 스레드는 Executing 상태로 변경된다.코어에서 내려온 스레드는 다시 Runnable 상태(여전히 실행할 수 있는 경우) 혹은 Waiting 상태(IO 바운드 유형의 요청으로 인해 교체된 경우)가 된다.컨텍스트 스위치는 코어에서 스레드를 배치하고 내리는데 시간이 걸리기 때문에 비용이 많이 드는 것으로 간주된다.컨텍스트 스위치가 발생하는 동안의 지연 시간은 다양한 요인에 따라 달라지지만 ~1,000, ~1,500 나노초가 소요5된다고 볼 수 있다.하드웨어가 각 코어 당, 1 나노초에 평균적으로 12개의 명령어를 실행할 수 있어야 한다는 점을 고려해보면,컨텍스트 스위치에는 ~12k에서 ~18k개의 명령어에 해당하는 지연 시간이 발생할 수 있는 것이다.본질적으로 프로그램은 컨텍스트 스위치를 하는 동안 많은 수의 명령어를 실행하는 기회를 상실하게 된다.IO 바운드 작업에 초점을 맞춘 프로그램에서의 컨텍스트 스위치는 이점이 있다.코어를 점유 중인 스레드가 Waiting 상태가 될 때, Runnable 상태의 다른 스레드가 그 자리를 차지하게 된다.이를 통해 코어가 항상 작업을 수행할 수 있게 되는데 이것은 스케줄링의 가장 중요한 측면 중 하나로, 스케줄러는 수행할 작업(Runnable 상태의 스레드)이 있는 경우 코어가 유휴 상태가 되는 것을 허용해선 안된다.Less Is More프로세서가 단지 하나의 코어만을 가졌던 초기에는 스케줄링이 그닥 복잡하지 않았다.단일 코어가 있는 단일 프로세서이기 때문에 주어진 시간에 하나의 스레드만을 실행할 수 있었다.스케줄러 기간6을 정의하고 해당 기간 내에 모든 Runnable 상태의 스레드를 실행하는 것을 시도하는 것이 아이디어였고,정의된 스케줄러 기간을 실행되어야 하는 스레드의 수로 나누면 되기에 이것은 전혀 문제가 없었다.예를 들어 스케줄러 기간이 1,000ms(1초)이고 10개의 스레드가 존재한다면, 각 스레드는 각각 100ms의 실행 시간을 가진다.만약 100개의 스레드가 있다면, 각 스레드는 각각 10ms의 실행 시간을 얻게 될 것이다.그러나 100개의 스레드가 있다면? 각 스레드에 1ms의 작은 시간 조각을 제공하는 것은 컨텍스트 스위칭에서 소비되는 시간은 애플리케이션 작업이 소비할 시간의 양과 관련이 있기 때문에 제대로 작동할 수 없다.주어진 시간 조각이 얼마나 작을 수 있는지에 대한 제한을 설정하는 것이 필요하다.마지막 시나리오에서, 최소 시간 조각 제한이 10ms인 상태에서 1,000개의 스레드가 있다면 스케줄러 기간은 10,000ms(10초)로 늘려야 한다.10,000개의 스레드가 있는 경우엔 100,000ms(100초)의 스케줄러 기간을 보게 된다.10,000개의 스레드가 10ms의 최소 시간 조각으로 각 스레드가 전체 시간 조각을 사용하는 경우,이 간단한 예제에서 모든 스레드가 한 번씩만 실행되는데 100초가 걸린다.이것은 세상을 보는 아주 단순한 관점이라는 것을 알아두자.스케줄링에 대한 결정을 내릴 때에 스케줄러가 고려하고 처리해야할 많은 사항들이 있다.애플리케이션에서는 자신이 사용하는 스레드 수를 제어할 수 있다.고려해야 할 스레드가 더 많고 IO 바운드 작업이 발생하면 더 많은 혼돈과 비결정적 동작이 발생한다.스케줄링을 하고 실행하는데 더 많은 시간을 필요로하게 된다.이것이 게임의 규칙이 “Less is More”인 이유이다.Runnable 상태의 스레드가 적다는건 스케줄링에 대한 오버헤드가 적고 시간이 지남에 따라 각 스레드엔 더 많은 시간이 할당된다는 것을 의미한다.Runnable 상태의 스레드가 많을수록 시간이 지남에 따라 각 스레드가 얻는 시간도 줄어든다.즉, 시간이 지남에 따라 한 스레드가 수행할 수 있는 작업도 줄어들게 된다는 것이다.Find The Balance보유하고 있는 코어의 수와 애플리케이션에 대한 최상의 처리량을 얻는데 필요한 스레드의 수 간에 균형을 찾아야 한다.이러한 균형을 관리하는 것과 관련해 스레드 풀은 좋은 답변이 된다.Go에서는 이것이 더 이상 필요하지 않다는 것은 다음 게시글에서 보여줄건데,개인적으로 이를 통해 Go에서 멀티스레드 애플리케이션 개발이 쉬워졌다고 생각한다.나는 Go로 코딩하기 전에 NT에서 C와 C#으로 코드를 작성했다.해당 운영체제에서 멀티스레드 소프트웨어를 만들 때 IOCP(IO Completion Ports) 스레드 풀을 사용해야만 했고,엔지니어는 주어진 코어 수에 대한 처리량을 최대화하기 위해 필요한 스레드 풀의 수와 주어진 풀에 대한 최대 스레드 수를 파악해야 했다.데이터베이스와 통신하는 웹 서비스를 작성할 때 코어당 3개의 스레드라는 마법같은 숫자는 항상 NT에서 최고의 처리량을 제공하는 것처럼 보였다.즉, 코아당 3개의 스레드는 컨텍스트 스위치의 대기 시간 비용을 최소화하면서 코어의 실행 시간을 최대화해주었다.IOCP 스레드 풀을 생성할 때 호스트 시스템에서 식별한 모든 코어에 대해 최소 1개의 스레드와 최대 3개의 스레드로 시작해야 하는 것으로 알고 있었다.코어당 2개의 스레드를 사용하면 작업을 완료할 수 있는 유휴 시간이 있었기 때문에 모든 작업을 완료하는데 시간이 더 오래 걸렸다.코어당 4개의 스레드를 사용한 경우 컨텍스트 스위치에서 더 많은 대기 시간을 필요로 했기 때문에 더 오랜 시간이 걸렸다.어떠한 이유로든 코어당 3개의 스레드 사용은 항상 NT에서 마법의 숫자처럼 느껴진 것이다.당신의 서비스가 다양한 종류의 작업을 수행하는 경우에는 어떻게 할 것인가?이는 서로 다르며 일관성이 없는 지연 시간을 생성할 수 있으며, 또한 처리해야 하는 다양한 시스템 수준의 이벤트를 생성할 수도 있다.서로 다른 모든 워크로드에 대해 항상 최상으로 작동하는 마법의 숫자를 찾는 것은 불가능에 가까울 수 있다.스레드 풀을 사용하여 서비스 성능을 조정하는 경우 바르게 일관된 구성을 찾는 것이 매우 복잡해질 수 있다.Cache Lines주 메모리의 데이터에 접근하는 것은 프로세서와 코어가 해당 데이터를 필요로 하는 하드웨어 스레드에 보다 가깝게 유지하기 위해 별도의 로컬 캐시를 갖기 때문에지연 시간 비용이 매우 높다(~100 to ~300 clock cycles).캐시의 데이터에 접근하는 것은 액세스되는 캐시에 따라 훨씬 저렴한 비용(~3 to ~40 clock cycles)을 갖는다.오늘날 성능의 한 측면은 이러한 데이터 액세스 지연 시간을 줄이기 위해 데이터를 프록세서에 얼마나 효율적으로 가져올 수 있는지에 관한 것이다.상태를 변경하는 멀티스레드 애플리케이션을 작성하려면 캐싱 시스템의 매커니즘을 충분히 고려해야 한다.그림 2데이터는 캐시 라인7을 통해 프로세서와 주 메모리 간 교환이 이루어진다.캐시 라인은 주 메모리와 캐싱 시스템 간에 교환되는 64 바이트 크기의 메모리 청크이다.각 코어에는 필요한 캐시 라인의 자체 복사본이 제공되며, 이는 하드웨어가 value semantics8를 사용함을 의미한다.멀티스레드 애플리케이션에서 메모리에 대한 변경 사항은 성능에 악영향을 끼칠 수 있는 직격탄이다.병렬로 실행되는 여러 스레드가 동일한 데이터 또는 서로 가까운 데이터에 접근하려 할 때 동일한 캐시 라인의 데이터에 도달하게 된다.모든 코어에서 실행되는 모든 스레드는 동일한 캐시 라인의 자체 복사본을 얻는다.그림 3주어진 코어의 한 스레드가 캐시 라인의 복사본을 변경하게 되면 하드웨어의 마법을 통해 동일한 캐시 라인의 다른 모든 복사본이 dirty로 표시되어야 한다.스레드가 dirty 캐시 라인에 대한 읽기 또는 쓰기 접근을 시도하면 캐시 라인의 새 복사본을 얻기 위해 주 메모리 접근이 필요하게 된다.2개의 코어를 가진 프로세서에서는 이것이 큰 문제가 아닐 수 있지만,32개의 스레드를 병렬로 실행하는 32 코어 프로세서는 모두 동일한 캐시 라인에서 동일한 데이터에 액세스하고 데이터를 변경하게 될 것이다.각각 16개의 코어가 있는 2개의 물리적 프로세서로 돌아가는 시스템은 어떨까?프로세서 간 통신에 지연 시간이 발생되기 때문에 이는 더 나빠질 것이다.애플리케이션은 프로세서와 주 메모리 간의 반복되는 캐시 라인 적재로 인해 스래싱 될 것이고 성능은 끔찍할 것이며 대부분은 그 이유조차 이해하지 못할 것이다.이를 캐시 일관성 문제9라고 하며 잘못된 공유와 같은 문제도 발생된다.공유 상태를 변경하는 멀티스레드 애플리케이션을 작성할 때에는 캐싱 시스템도 충분히 고려해야만 한다. wq: 음.. 여기서부터 헷갈리기 시작했다. 캐시 라인에 대한 이해가 부족한 상태에서 보자니 쉽지 않았다. 추가로 정리해놓고자 한다.캐시 라인은 아래와 같은 흐름으로 동작한다: 캐시 라인이란 CPU가 주 메모리로부터 데이터를 가져올 때 바이트 단위로 가져오지 않고 캐시 라인을 가득 채울만큼의 데이터를 가져오는 것을 말한다. 캐시 라인은 CPU에 따라 32, 64, 128 바이트의 크기로 구성되며 캐시 메모리에 정렬돼 저장된다. 일반적인 캐시 라인 동작: CPU에서 1000번째 메모리를 읽으려고 한다. 주 메모리에 있는 데이터를 캐시 라인의 크기(여기서는 64 바이트로 가정)만큼 가져오므로 1000번에서 1064번 메모리의 데이터를 캐시 메모리에 채우게 된다. 이후 1000번에서 1064번 메모리에 접근 시 캐시 메모리에서 접근이 가능해진다. 멀티 프로세서 환경에서의 캐시 라인: CPU A가 1000번째 메모리에 접근한다. 이 때 캐시 라인의 크기만큼 CPU A의 캐시 메모리에 적재된다. (1000번 ~ 1064번) CPU B도 1000번째 메모리에 접근한다. 마찬가지로 캐시 라인의 크기만큼 CPU B의 캐시 메모리에 적대된다. CPU A가 1000번째 메모리의 데이터를 변경한다. 3.의 작업으로 인해 다른 CPU에 있던 동일한 캐시 라인을 무효화시키게 되므로 CPU B에 적재되어 있던 1000번 ~ 1064번 캐시 라인이 무효화된다. 이후 CPU B는 1000번째 메모리의 데이터에 접근하고자 한다면 다시 캐시 라인을 적재해야 한다. 여기에서 캐시 라인을 무효화 또는 동기화하는 작업이 바로 위에서 언급된 dirty이다. 이러한 동작때문에 False Sharing이 발생된다.한 애플리케이션에서 사용되는 두 개의 변수 n1, n2가 있고애플리케이션 내부에선 2개의 스레드 t1, t2를 통해 각각 n1과 n2를 다루는 어떠한 연산을 진행한다고 가정해보자.(n1과 n2는 주 메모리에 물리적으로 가까이에 순차적으로 있을 것이다.)이러한 상황에서 t1의 코어 1에 배치되고 t2는 코어 2에 배치된다고 한다면,코어 1의 캐시 라인은 n1부터 64 바이트를 읽어서 적재하게 되고 코어 2의 캐시 라인은 n2부터 64 바이트를 읽어서 적재하게 될 것이다.특히 코어 1의 캐시 라인은 n1부터 가져왔지만 64 바이트를 통째로 읽어서 적재했으므로 n2 데이터도 같이 있을 확률이 높다.연산이 시작됐을 때, 코어 2는 별다른 문제없이 연산하게 된다.하지만 코어 1은 약간의 문제가 생길 수 있다.CPU는 단지 계산만 처리하는 기계이며 캐시 일관성(cache coherence) 매커니즘으로 돌아가기 때문에 캐시 라인에 들어있던 두 변수 모두를 살펴봐야만 한다.따라서 코어 1은 코어 2에 의해 n2의 값이 변경되면 연산을 멈추고 n2의 값을 다시 받아와서 캐시 라인에 적재하게 된다.이런 작업이 계속 반복된다면 성능 저하를 일으킬 수 밖에 없다.이를 해결하는 방법은 패딩(padding)을 사용해 데이터를 캐시 라인의 크기인 64 바이트로 채워주는 것이다.이제 가려운 부분이 어느정도 해소가 되었다. 다음으로 넘어가보자.Scheduling Decision Scenario내가 당신에게 알려준 높은 수준의 정보를 기반으로 운영체제 스케줄러를 작성하도록 요청했다고 상상해보라.스케줄러를 만들 때 고려해야할 당장 떠오르는 시나리오가 있는가?그것은 스케줄러가 스케줄링 결정을 내릴 때 고려해야하는 많은 흥미로운 것들 중 하나라는 것을 기억하자.애플리케이션을 시작하면 메인 스레드가 생성되고 코어 1에서 실행된다고 가정해보자.스레드가 명령을 실행하기 시작하면 데이터가 필요하기 때문에 캐시 라인이 검색된다.이후 스레드가 일부 동시 처리를 위해 새로운 스레드를 생성하기로 결정한다. 이 때,새로운 스레드가 생성되고 사용될 준비가 되면 스케줄러는 다음을 수행해야 한다: 코어 1의 메인 스레드를 컨텍스트 스위치할 것인가? 새로운 스레드가 이미 캐시된 동일한 데이터를 필요로할 가능성이 매우 높기 때문에 이렇게 하면 성능에 도움이 될 수 있다. 하지만 메인 스레드는 작업할 시간을 얻지 못하게 된다. 메인 스레드의 작업 시간이 완료될 때까지 새로운 스레드가 코어 1에 배치되기를 기다리게 할 것인가? 새로운 스레드는 실행되고 있지 않지만, 시작되면 데이터를 가져오는 작업에 대한 지연 시간이 제거될 것이다. 새로운 스레드가 다른 코어에 배치되기를 기다리게 할 것인가? 즉, 선택한 코어의 캐시 라인이 날아가고 검색 및 복제되는 지연 시간이 발생될 것이다. 그러나 스레드가 더 빨리 시작되고 메인 스레드는 작업 시간을 충분히 가질 수 있게 된다.즐겁지 아니한가?이것은 운영체제 스케줄러가 스케줄링 결정을 내릴 때 고려해야하는 아주 흥미로운 질문이다.운 좋게도 나는 스케줄러는 만드는 사람이 아니다.내가 말할 수 있는 것은 유휴 코어가 있으면 사용된다는 것 뿐, 우리는 스레드가 실행될 수 있을 때 실행되기를 원한다.Conclusion이 게시물의 첫 번째 부분은 멀티스레드 애플리케이션을 만들 때의 스레드 및 운영체제 스케줄러와 관련해 고려해야 할 사항들에 대한 통찰력을 제공한다.이는 Go 스케줄러도 고려하는 사항이다.다음 게시물에서는 Go 스케줄러의 의미와 그것들이 이러한 정보들과 어떻게 연관되는지 설명할 것이다.그런 다음, 마지막으로 몇 가지 프로그램을 실행해 이 모든 것이 실제로 작동하는지 확인해 볼 것이다. Mechanical Sympathy 란 간단히 말해서 도구나 시스템이 가장 잘 작동하는 방식을 이해하고 사용하는 상태를 말한다. &#8617; Mental model 은 실제 세상에서 그것이 어떻게 작동하는지에 관해 어떤 누군가가 사고한 과정에 대한 설명이다. &#8617; Program counter &#8617; Latency &#8617; Measuring context switching and memory overheads for Linux threads &#8617; Improving scheduler latency &#8617; code::dive conference 2014 - Scott Meyers: Cpu Caches and Why You Care &#8617; Design Philosophy On Data And Semantics &#8617; Youtube, 캐시 일관성이란 공유 메모리 시스템에서 각 클라이언트 혹은 프로세서가 가진 로컬 캐시 간의 일관성을 의미한다. &#8617; " }, { "title": "eBFP example", "url": "/posts/linux-ebpf-example/", "categories": "ebpf", "tags": "kernel, tracepoint", "date": "2022-03-24 23:00:00 +0900", "snippet": "eBPF 프로그램을 만드는 가장 흔한 방법은 C 언어로 소스 코드를 작성하고 그것을 LLVM 으로 컴파일하는 것이다.LLVM은 다양한 종류의 바이트코드를 산출할 수 있는 범용 컴파일러이며, Clang은 LLVM의 메인 프론트엔드이다.LLVM을 통해 BPF 프로그램을 컴파일해서 유효한 ELF 이진 파일(리눅스 커널이 적재할 수 있는 이진 실행 파일 형식)을 만들고 커널에 적재하는 일련의 과정을 진행하고 정리해보자.cilium/ebpf를 사용해 eBPF 프로그램을 작성하고 컴파일하고, 커널에 적재하고자 한다.전체 예제 코드는 21kyu/bpf-example에 올려두었다.eBPF Programcilium/ebpf를 사용할 때 eBPF Program은 C 언어로 작성해도 되고, Go 언어 내부에서 BPF 어셈블리 코드를 사용해 프로그램을 작성해도 된다.여기에서는 가장 보편적인 방법인 C 언어로 Program을 작성하는 방법을 분석해 보고자 한다./src/bpf/execve.c에 정의된 코드이다.SEC(\"tracepoint/syscalls/sys_enter_execve\")int enter_execve(struct execve_entry *args){ struct event info = {}; u64 pid_tgid = bpf_get_current_pid_tgid(); info.pid = pid_tgid &amp; 0xFFFFFFFF; bpf_probe_read_user_str(info.fname, sizeof(info.fname), args-&gt;filename); bpf_get_current_comm(info.comm, sizeof(info.comm)); bpf_perf_event_output(args, &amp;events, BPF_F_CURRENT_CPU, &amp;info, sizeof(info)); bpf_printk(\"hello, world\\n\"); return 0;}이 코드를 통해 BPF VM이 해당 프로그램을 실행할 시점을 정의한다.구체적으로 보자면, 이 예제는 execve 시스템 호출의 추적점(tracepoint)이 검출되었을 때 BPF VM이 이 BPF 프로그램을 실행해야 함을 SEC 매크로로 지정한다.추적점은 커널의 이진 코드 안에 있는 정적 표식(mark)이다. BPF 프로그램 개발자는 실행 추적이나 디버깅을 위해 추적점에 임의의 코드를 주입할 수 있다.커널에 미리 정의해둔 추적점들에만 코드를 붙일 수 있다는 점에서 kprobe 프로그램보다 덜 유연하지만, 일단 정의되고 나면 변하지 않으므로 안정적이다.시스템의 모든 추적점은 /sys/kernel/debug/tracing/events 아래에 정의되어 있다.코드를 하나하나 살펴보자. bpf_get_current_pid_tgid() tgid 및 pid를 포함하는 64비트 정수(current_task-&gt;tgid &lt;&lt; 32 | current_task-&gt;pid)가 반환된다.현재로썬 pid만 필요하므로 last 32 bit만 가져와서 pid를 얻고 이를 info.pid에 채운다. bpf_probe_read_user_str(info.fname, sizeof(info.fname), args-&gt;filename); 안전하지 않은 사용자 주소인 unsafe_ptr(args-&gt;filename)에서 dst(info.comm)로 문자열을 복사한다.size에는 NUL 바이트가 포함되어 있어야 하며 성공하면 복사된 문자열의 길이가 반한된다. bpf_probe_read_user() helper를 사용하여 문자열을 읽을 수도 있지만, 컴파일 시간에 길이를 추정해야 하며 간혹 필요한 것보다 더 많은 메모리를 복사하게 될 수도 있다. bpf_get_current_comm(info.comm, sizeof(info.comm)); 현재 task의 comm 속성을 buf(info.comm)에 복사한다. comm 속성에는 현재 task의 실행 파일 이름(경로 제외)이 포함된다. bpf_perf_event_output(args, &amp;events, BPF_F_CURRENT_CPU, &amp;info, sizeof(info)); BPF_MAP_TYPE_PERF_EVENT_ARRAY 타입의 map(&amp;events)이 보유하는 BPF perf event에 raw data(&amp;info) blob을 쓴다.이 perf event는 PERF_SAMPLE_RAW를 sample_type으로, PERF_TYPE_SOFTWARE를 type으로, PERF_COUNT_SW_BPF_OUTPUT을 config로 지정해야 한다.flag는 값을 넣어야하는 map(&amp;events)의 인덱스를 나타내는데 사용되며 BPF_F_INDEX_MASK로 마스킹된다.flag를 BPF_F_CURRENT_CPU로 설정하여 현재 CPU 코어의 인덱스를 사용해야 함을 나타낼 수 있다. bpf_printk(\"hello, world\\n\"); 추적 파이프에 대한 간편한 측정을 위해 hello, world 출력한다.bpf_printk는 내부적으로 bpf_trace_printk helper를 호출하는데, 이는 디버깅을 위한 printk()-like 기능이다.사용 가능한 경우 DebugFS에서 /sys/kernel/debug/tracing/trace 파일에 정의된 메시지를 출력한다.만약 /sys/kernel/debug/tracing/trace가 열려 있는 동안엔 메시지는 삭제된다.이를 방지하려면 /sys/kernel/debug/tracing/trace_pipe를 사용하면 된다.Parameter이제 해당 함수의 파라미터로 사용 중인 execve_entry 구조체를 확인해보자.struct execve_entry { u64 _unused; u64 _unused2; const char* filename; const char* const* argv; const char* const* envp;};이 프로그램에서 사용할 커스텀한 추적 이벤트 객체를 만든다.아래에서 해당 추적 지점에 대해 얻을 수 있는 모든 정보가 표시된다.❯ sudo cat /sys/kernel/debug/tracing/events/syscalls/sys_enter_execve/formatname: sys_enter_execveID: 707format: field:unsigned short common_type; offset:0; size:2; signed:0; field:unsigned char common_flags; offset:2; size:1; signed:0; field:unsigned char common_preempt_count; offset:3; size:1; signed:0; field:int common_pid; offset:4; size:4; signed:1; field:int __syscall_nr; offset:8; size:4; signed:1; field:const char * filename; offset:16; size:8; signed:0; field:const char *const * argv; offset:24; size:8; signed:0; field:const char *const * envp; offset:32; size:8; signed:0;print fmt: \"filename: 0x%08lx, argv: 0x%08lx, envp: 0x%08lx\", ((unsigned long)(REC-&gt;filename)), ((unsigned long)(REC-&gt;argv)), ((unsigned long)(REC-&gt;envp))사용될 데이터는 filename 정보이다.filename 필드의 offset이 16 byte이므로 128 bit부터 유의미한 데이터가 되므로 u64 타입의 unused 필드를 사용해 구조를 맞춘다.BPF MapBPF 맵은 커널 안에 존재하는 Key-Value 저장소이며 그 위치를 아는 모든 BPF 프로그램이 접근할 수 있다.사용자 공간에서 실행되는 프로그램도 특정 파일 서술자를 이용해서 접근이 가능하다.BPF 맵에는 그 어떤 형식의 자료도 저장할 수 있다. 단, 저장 전에 자료의 크기를 명시할 수 있어야 한다.커널은 키와 값을 이진 blob으로 취급할 뿐, 그 안에 담긴 내용과 형식이 무엇인지는 신경 쓰지 않는다.struct bpf_map_def SEC(\"maps\") events = { .type = BPF_MAP_TYPE_PERF_EVENT_ARRAY, .key_size = sizeof(u32), .value_size = sizeof(u32),};프로그램에 필요한 맵의 유형을 미리 알고 있다면 위와 같이 맵을 사전에 정의해둘 수 있으며,SEC(\"maps\") 섹션 특성(section attribute)를 사용해 이 구조체가 하나의 BPF 맵임을 커널에 알릴 수 있게 된다.Event바로 위에서 언급한 BPF_MAP_TYPE_PERF_EVENT_ARRAY 타입의 map(&amp;events)이 보유하는 BPF perf event에 쓸 raw data를 정의한다.struct event { u32 pid; u8 fname[32]; u8 comm[32];};// Force emitting struct event into the ELF.const struct event *unused __attribute__((unused)); const struct event *unused __attribute__((unused)); 위 event 구조체는 이 BPF 프로그램을 컴파일하고 커널에 적재하고 이후의 작업을 처리할 .go 파일에서도 동일한 포맷으로 정의가 되고 사용이 되어야 한다.위 코드를 사용하게 되면 bpf2go를 통해 프로그램이 컴파일될 때 해당 event 구조체도 자동으로 알아서 bpfel.go 파일에 반영이 된다.이는 github.com/cilium/ebpf 의존성의 v0.8.2-0.20220217141816-62da0a730ab7 버전부터 지원되는 기능으로 확인이 되니 참고하여 사용하도록 하자.main.go//go:generate go run github.com/cilium/ebpf/cmd/bpf2go -target bpfel -cc clang -type event bpf ./bpf/execve.c -- -I/usr/include/bpf -I./headersgo:generate marker를 통해 bpf2go를 실행하도록 지시한다.bpf2go는 clang을 통해 ./bpf/execve.c에 작성된 BPF 프로그램을 컴파일하고 bpf_bpfel.o, bpf_bpfel.go 파일을 생성한다.여기에서 생성된 bpf_bpfel.go 파일은 main.go를 쉽게 작성할 수 있도록 도움을 준다.func main() { // Subscribe to signals for terminating the program. stopper := make(chan os.Signal, 1) signal.Notify(stopper, os.Interrupt, syscall.SIGTERM) // Allow the current process to lock memory for eBPF resources. if err := rlimit.RemoveMemlock(); err != nil { log.Fatal(err) } // Load pre-compiled programs and maps into the kernel. objs := bpfObjects{} if err := loadBpfObjects(&amp;objs, nil); err != nil { log.Fatalf(\"loading objects: %v\", err) } defer objs.Close() // Open a Tracepoint at the entry point of the kernel function and attach the pre-compiled program. tp, err := link.Tracepoint(\"syscalls\", \"sys_enter_execve\", objs.EnterExecve) if err != nil { log.Fatalf(\"opening tracepoint: %s\", err) } defer tp.Close() // Open a perf reader from userspace PERP map described in the eBPF C program. rd, err := perf.NewReader(objs.Events, os.Getpagesize()) if err != nil { log.Fatalf(\"opening perf reader: %s\", err) } defer rd.Close() // Close the reader when the process receives a signal, which will exit the read loop. go func() { &lt;-stopper if err := rd.Close(); err != nil { log.Fatalf(\"closing perf reader: %s\", err) } }() log.Println(\"waiting for events..\") // bpfEvent is generated by bpf2go. var event bpfEvent for { record, err := rd.Read() if err != nil { if errors.Is(err, perf.ErrClosed) { log.Println(\"received signal, exiting..\") return } log.Printf(\"reading from reader: %s\", err) continue } if record.LostSamples != 0 { log.Printf(\"perf event ring buffer full, dropped %d samples\", record.LostSamples) continue } // Parse the perf event entry into a bpfEvent structure. if err := binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &amp;event); err != nil { log.Printf(\"parsing perf event: %s\", err) continue } fmt.Printf(\"On cpu %02d %s ran : %d %s\\n\", record.CPU, event.Comm, event.Pid, event.Fname) }} signal.Notify(stopper, os.Interrupt, syscall.SIGTERM) 프로그램의 종료 신호를 구독한다. rlimit.RemoveMemlock() 현재 프로세스가 eBPF 리소스에 대한 메모리를 잠글 수 있도록(lock) 허용한다.RemoveMemlock은 필요한 경우 현재 프로세스가 RAM에 잠글 수 있는 메모리 양에 대한 제한을 제거한다.cgroup-based memory accounting의 도입으로 인해 커널 버전 5.11부터는 eBPF 리소스를 로드하는데 이 기능을 필요로 하지 않는다.이 기능은 편의상 존재하며 영구적으로 RLIMIT_MEMLOCK을 무한으로 올리는 것이 적절한 경우에만 사용해야 한다.원하는 경우 보다 합리적인 제한으로 prlimit(2)를 직접 호출하는 것을 고려하자. loadBpfObjects(&amp;objs, nil) pre-compiled program과 map을 커널에 로드한다. tp, err := link.Tracepoint(\"syscalls\", \"sys_enter_execve\", objs.EnterExecve) tracepoint를 열고 pre-compiled program을 연결한다.커널 함수가 입력될 때마다 프로그램은 perf buffer에 지정된 perf event를 기록한다.처음 두 arguments는 /sys/kernel/debug/tracing/events/syscalls/sys_enter_execve 경로에서 가져오면 된다. rd, err := perf.NewReader(objs.Events, os.Getpagesize()) eBPF C 프로그램에서 설명된 userspace PERF 맵으로부터 perf reader를 가져온다. go func() { 프로세스가 신호를 수신하게 되면 reader를 닫고 read loop도 종료하게 된다. var event bpfEvent bpfEvent 구조체는 bpf2go에 의해 생성된다. binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &amp;event) perf event entry를 bpfEvent 구조로 변환한다.x86은 little endian machine이므로 byte order를 그에 맞게 지정해주자.How to use➜ bpf-example git:(main) makego generate src/*.goCompiled /home/parallels/Workspace/bpf-example/src/bpf_bpfel.oStripped /home/parallels/Workspace/bpf-example/src/bpf_bpfel.oWrote /home/parallels/Workspace/bpf-example/src/bpf_bpfel.goCGO_ENABLED=0 go build -o exec_scrape src/*.goMakefile을 실행하면 exec_scrape 파일이 생성된다.이를 통해 작성했던 BPF 프로그램을 실제로 실행할 수 있게 된다.➜ bpf-example git:(main) sudo ./exec_scrape2022/03/25 00:59:26 waiting for events..On cpu 00 prlshprint ran : 118136 /bin/shOn cpu 00 sh ran : 118138 /usr/bin/sedOn cpu 01 sh ran : 118137 /usr/bin/lpstatOn cpu 00 prlshprint ran : 118139 /bin/shOn cpu 00 sh ran : 118141 /usr/bin/lpstatOn cpu 01 sh ran : 118142 /usr/bin/sedOn cpu 01 prlshprint ran : 118143 /bin/shOn cpu 00 sh ran : 118144 /usr/bin/lpstatOn cpu 01 sh ran : 118145 /usr/bin/sed2022/03/25 00:59:30 received signal, exiting..실행하면 위와 같이 execve 시스템 호출의 추적점을 통해 한 프로그램이 다른 프로그램을 실행하는 상황이 커널에 포착될 때의 이벤트가 출력되는 것을 확인할 수 있다. prlshprint-118136 [000] d... 16371.756553: bpf_trace_printk: hello, world lpstat-118137 [001] d... 16371.757808: bpf_trace_printk: hello, world sed-118138 [000] d... 16371.757899: bpf_trace_printk: hello, world prlshprint-118139 [000] d... 16372.824015: bpf_trace_printk: hello, world lpstat-118141 [000] d... 16372.825758: bpf_trace_printk: hello, world sed-118142 [001] d... 16372.826010: bpf_trace_printk: hello, world prlshprint-118143 [001] d... 16374.093667: bpf_trace_printk: hello, world lpstat-118144 [000] d... 16374.095143: bpf_trace_printk: hello, world sed-118145 [001] d... 16374.095145: bpf_trace_printk: hello, world/sys/kernel/debug/tracing/trace에서 /src/bpf/execve.c의 마지막 부분에 출력하도록 했던 hello, world 메시지도 볼 수 있다." }, { "title": "Network Device", "url": "/posts/linux-kernel-networking-02/", "categories": "linux", "tags": "kernel, network", "date": "2022-03-06 02:00:00 +0900", "snippet": "리눅스 커널 네트워킹 스택에서 처리하는 3계층 중 가장 낮은 계층인 L2는 데이터 링크 계층이다.네트워크 장치 드라이버는 이 계층에 속하며 이와 관련된 기본적인 사항에 익숙해지면 네트워크 스택을 이해하는데 큰 도움이 될 것이다.Network Interface네트워크 인터페이스는 네트워크 연결을 위한 운영체제의 끝점이다.인터페이스는 시스템 관리자가 설정하고 관리하는 추상적인 요소다.network interface네트워크 인터페이스는 설정 정보에 있는 물리적인 네트워크 포트와 매핑된다.포트는 네트워크에 연결되며, 보통 수신과 송신 채널을 따로 가지고 있다.Network ControllerNIC(Network Interface Card)는 시스템에 네트워크 포트를 하나 이상 제공하며, 네트워크 컨트롤러를 수용한다.컨트롤러는 포트와 시스템 I/O 트랜스포트 사이에 패킷을 전송하는 마이크로 프로세서다.network controller컨트롤러는 별도의 카드로 돼 있거나 시스템 보드에 내장돼 있다.Network Device Drivers네트워크 장치 드라이버(Network Device Drivers)에는 보통 커널 메모리와 NIC 사이에 데이터를 보내고 받기 위한 추가 버퍼(보통 링 버퍼)가 있다.Network Device의 NAPI(New API)오래된 네트워크 장치 드라이버는 인터럽트 구동 모드(interrupt-driven mode)로 동작하며 이는 패킷을 수신할 때마다 인터럽트가 발생한다는 의미다.이 방식은 트래픽 부하가 심할 때 성능 측면에서 비효율적인 것으로 증명됐다.그리하며 New API(NAPI)라고 하는 새로운 소프트웨어 기법이 개발됐고 현재 대부분의 리눅스 네트워크 장치 드라이버에서 지원한다.linux low level network stackNAPI를 이용하면 부하가 높은 상태에서 네트워크 장치 드라이버가 인터럽트 구동 방식이 아닌 폴링 방식(polling mode)으로 동작한다.각 패킷은 드라이버에 버퍼링되고, 커널이 이따금 패킷을 가져오기 위해 드라이버를 대상으로 폴링한다.NAPI를 사용하면 부하가 높은 상황일 때 성능이 향상된다.Network Device Driver의 주요 작업네트워크 장치 드라이버의 주요 작업은 다음과 같다. 로컬 호스트를 목적지로 하는 패킷을 수신하고, 네트워크 계층(L3)을 거쳐 전송 계층(L4)로 전달 로컬 호스트에서 생성되어 외부로 나가는 패킷을 전송하거나, 로컬 호스트에서 수신된 패킷을 포워딩Busy Polling on Socket소켓 큐가 고갈될 때 네트워킹 스택이 동작하는 전통적인 방법은 드라이버가 소켓 큐에 데이터를 넣을 수 있을 때까지 기다리며 잠들거나, 비차단 동작일 경우 반환하는 것이다.이는 인터럽트와 컨텍스트 전환으로 인해 추가적인 지연을 발생시킨다.지연 시간을 최대한 낮춰야 하지만 높은 CPU 사용률은 기꺼이 감수할 수 있는 소켓 애플리케이션에 대해 리눅스는 바쁜 폴링(busy polling) 기능을 추가했다.바쁜 폴링은 애플리케이션으로 데이터를 옮기는 방향으로 더욱 적극적인 접근법을 취한다.애플리케이션이 데이터를 더 요청하고 소켓 큐에 아무것도 없다면 네트워킹 스택은 장치 드라이버를 호출한다.드라이버는 새로 도착한 데이터를 검사하고 네트워크 계층(L3)을 통해 소켓에 데이터를 밀어 넣는다.바쁜 폴링은 하드웨어에 가까운 지연시간을 제공한다.대량의 소켓에 동시에 사용될 수 있지만 최상의 결과를 낼 수는 없는데, 일부 소켓에 대한 바쁜 폴링이 동일한 CPU 코어를 사용하는 다른 소켓을 느리게 하기 때문이다. 전통적인 수신 경로 흐름 애플리케이션이 수신 검사를 한다. 소켓 큐에 데이터가 없어서 즉시 받을 수 없으므로 차단된다. 패킷이 수신돼 NIC에 도착하고 장치 드라이버로 전달된다. 장치 드라이버는 프로토콜 계층에 패킷을 전달한다. 프로토콜/소켓이 애플리케이션을 깨운다. - Bypass context switch and interrupt. 애플리케이션은 소켓을 통해 데이터를 수신한다. 반복 바쁜 폴링이 적용된 소켓의 수신 흐름 애플리케이션이 수신 검사를 한다. 네트워킹 스택은 보류 패킷에 대해 장치 드라이버를 검사한다. (폴링 시작) 그 사이 NIC에 패킷이 수신되고 장치 드라이버로 전달된다. 장치 드라이버가 프로토콜 계층에 패킷을 전달한다. 애플리케이션은 소켓을 통해 데이터를 수신한다. 반복net_device 구조체net_device 구조체는 네트워크 장치를 나타내며, 이것은 이더넷 장치 같은 물리 장치, 브리지 장치 또는 VLAN 장치 같은 소프트웨어 장치가 될 수 있다.장치 매개변수는 패킷을 분할해야 하는지 결정한다. net_device는 매우 큰 구조체이고, 다음과 같은 장치 매개변수로 구성돼 있다. IRQ 번호 MTU MAC 주소 장치의 이름(e.g., eth0 또는 eth1) 플래그 값(e.g., 활성 또는 비활성) 연관된 멀티캐스트 주소 목록 promiscuity(무차별) 카운터 장치가 지원하는 기능(e.g., GSO 또는 GRO 오프로딩) 네트워크 장치 콜백 객체(net_device_ops 객체): 장치를 열거나 종료, 전송 시작, 네트워크 장치의 MTU 변경 등을 위한 함수 포인터로 구성돼 있다. ethtool 콜백 객체: 명령줄 ethtool 유틸리티를 실행해 장치에 관한 정보를 수집할 수 있게 지원한다. 멀티 큐를 지원하는 장치일 경우 Tx, Rx 큐의 개수 패킷의 마지막 송신/수신 타임스탬프net_device 구조체의 일부struct net_device { unsinged int irq; /* 장치 IRQ 번호 */ ... const strict net_device_ops *netdev_ops; ... unsigned int mtu; unsigned int promiscuity; unsigned char *dev_adr; ... 참고.1 리눅스 커널 네트워킹 참고.2 시스템 성능 분석과 최적화" }, { "title": "Socket Buffer", "url": "/posts/linux-kernel-networking-01/", "categories": "linux", "tags": "kernel, network", "date": "2022-03-04 20:00:00 +0900", "snippet": "SKB나 sk_buff라고도 부르는 소켓 버퍼(socker buffer) 구조체는 전송 또는 수신된 모든 패킷에 대해 커널이 생성해서 사용하는 구조체이다.여러 BPF 프로그램은 이 SKB를 읽어서 패킷 전달 여부를 결정하거나, 현재 소통량에 관한 통계치와 측정치를 BPF 맵에 추가한다.또한 eBPF는 SKB의 수정도 가능하다.최종 패킷의 대상 주소를 변경함으로써 패킷을 다른 곳으로 재지정할 수 있으며, 심지어 근본적인 구조도 바꿀 수 있다.이런 능력을 활용하면 IPv6 전용시스템이 받은 모든 패킷을 IPv4로 변환하는 것도 가능하다.커널 내부 구조를 이해하면 eBPF를 이해하는데 도움이 될 것이다.여기서 핵심은 패킷이 struct sk_buff(socket buffer) 구조체를 통해 커널 네트워크 스택을 통과한다는 것이다.(커널 영역) 소켓의 경우 struct sock 구조체에 정의되어 있는데, 이 구조체는 tcp_sock과 같은 소켓 프로토콜의 앞부분에 내장되어 있다.네트워크 프로토콜은 tcp_prot, udp_prot 등의 struct proto 구조체를 사용해서 소켓에 연결된다.우선 sk_buff를 조사해보자.리눅스 커널 네트워킹의 부록 A. 리눅스 API 중 sk_buff 구조체를 정리해두고자 한다.socket buffer?패킷의 이동을 더 잘 이해하려면 리눅스 커널에서 패킷이 어떻게 표현되는지 알면 알수록 좋다고 한다.리눅스 커널에서 소켓 버퍼(socket buffer)는 sk_buff 구조체로 표현되며 유입/유출 패킷을 나타낸다.패킷은 로컬 장비에서 로컬 소켓으로 생성될 수 있으며(로컬 호스트에서 생성된 패킷은 4계층 소켓:TCP 또는 UDP 소켓을 통해 만들어진다.),(소켓 API를 통해) 사용자 공간 애플리케이션에서 생성된다. 소켓에는 데이터그램(datagram) 소켓과 스트림(stream) 소켓이라는 두 가지 주된 유형이 있다.로컬에서 생성된 패킷은 네트워크 계층인 L3로 전달(여기서 단편화가 발생하기도 한다.)된 후 전송을 위해 네트워크 장치 드라이버(L2)로 전달된다.패킷은 외부 또는 같은 장비 내의 다른 소켓으로 보내질 수 있다.또한 패킷은 커널 소켓에 의해 생성될 수도 있다.네트워크 장치(L2)로부터 물리적 프레임을 수신하고 이를 sk_buff에 연결(netdev_alloc_skb() 함수를 호출하여 sk_buff 구조체를 할당한다)한 후 네트워크 계층(L3)에 전달할 수 있다.패킷 목적지가 로컬 장비이면 전송 계층(L4)으로 계속 이동할 것이고, 패킷 목적지가 로컬 장비가 아니라면 라우팅 테이블 규칙에 따라 포워딩될 것이다(로컬 장비가 포워딩을 지원할 경우).패킷은 이유가 어떻든 간에 손상되면 폐기된다.sk_buff 구조체sk_buff 구조체를 살펴보자.struct sk_buff { union { struct { /* These two members must be first to match sk_buff_head. */ struct sk_buff *next; struct sk_buff *prev; union { // dev는 SKB와 연관된 네트워크 인터페이스 장치를 나타내는 net_device 객체이다. // 간혹 그러한 네트워크 장치에 대한 NIC(network interface card)라는 용여를 접하게 될 것이다. // NIC는 패킷이 도착한 네트워크 장치나 패킷을 보낼 네트워크 장치가 될 수 있다. // 다음 포스팅에서 좀 더 자세히 정리해두자. struct net_device *dev; /* Some protocols might use this space to store information, * while device pointer would be NULL. * UDP receive path is one user. */ unsigned long dev_scratch; }; }; struct rb_node rbnode; /* used in netem, ip4 defrag, and tcp stack */ struct list_head list; struct llist_node ll_node; }; union { // SKB(로컬 생성 트래픽과 로컬 호스트를 목적지로 하는 트래픽에 대한)를 소유한 소켓이다. 포워딩될 패킷은 sk가 NULL이다. // 보통 소켓에 관해 이야기할 때는 사용자 공간에서 socket() 시스템 콜을 호출해 생성된 소켓을 기준으로 한다. // sock_create_kern() 함수를 호출해 생성되는 커널 소켓에 대해서도 알아둘 필요가 있다. struct sock *sk; int ip_defrag_offset; }; union { // 패킷의 도착 timestamp. SKB에서 기본 timestamp로 제공돼 저장된다. ktime_t tstamp; u64 skb_mstamp_ns; /* earliest departure time */ }; /* * This is the control buffer. It is free to use for every * layer. Please put your private variables there. If you * want to keep them across layers you have to do a skb_clone() * first. This is owned by whoever has the skb queued ATM. */ // 제어 버퍼로서 다른 계층에서 자유롭게 사용될 수 있다. // 이것은 비공개 정보를 저장하는데 사용되는 불투명 영역으로 TCP 프로토콜에서는 TCP 제어 버퍼를 다음과 같이 사용한다. // #define TCP_SKB_CB(__skb) ((struct tcp_skb_cb *)&amp;((__skb)-&gt;cb[0])) @include/net/tcp.h char cb[48] __aligned(8); union { struct { // 목적지 항목(dst_entry) 주소. dst_entry 구조체는 특정 목적지에 대한 라우팅 항목을 나타낸다. // 각 송수신 패킷의 경우 라우팅 테이블에서 탐색을 수행한다. // 간혹 이 탐색을 FIB(Forwarding Information Base) 탐색이라 하며 이 탐색의 결과에 따라 이 패킷을 어떻게 처리할 지 결정된다. // 포워딩돼야 하는지, 포워딩돼야 한다면 어떤 인터페이스를 사용해 전송될지, 또는 던져져야 하는지, ICMP 오류 메시지를 보내야 하는지 unsigned long _skb_refdst; // kfree_skb() 함수를 호출해 SKB를 해제할 때 호출되는 콜백 void (*destructor)(struct sk_buff *skb); }; struct list_head tcp_tsorted_anchor;#ifdef CONFIG_NET_SOCK_MSG unsigned long _sk_redir;#endif };#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE) unsigned long _nfct;#endif // 패킷 바이트의 전체 개수 unsigned int len, // 데이터 길이. 이 필드는 패킷이 비선형 데이터(페이지된 데이터)를 가질 때만 사용된다. data_len; // MAC(2계층) 헤더의 길이 __u16 mac_len, hdr_len; /* Following fields are _not_ copied in __copy_skb_header() * Note that queue_mapping is here mostly to fill a hole. */ __u16 queue_mapping;/* if you move cloned around you also must adapt those constants */#ifdef __BIG_ENDIAN_BITFIELD#define CLONED_MASK (1 &lt;&lt; 7)#else#define CLONED_MASK 1#endif#define CLONED_OFFSET offsetof(struct sk_buff, __cloned_offset) /* private: */ __u8 __cloned_offset[0]; /* public: */ // 패킷이 __skb_cloen() 함수로 복제되면 이 필드는 복제 패킷과 주 패킷 모두 1로 설정된다. // SKB 복제는 sk_buff struct의 사본을 생성하는 것을 의미한다. 데이터 영역은 복제본과 주 SKB 사이에 공유된다. __u8 cloned:1, nohdr:1, fclone:2, // 이 패킷은 이미 확인되어 이 패킷에 대한 통계 작업(?)이 이뤄졌다. 따라서 다시 통계 작업을 수행하지 않는다. peeked:1, head_frag:1, pfmemalloc:1, pp_recycle:1; /* page_pool recycle indicator */#ifdef CONFIG_SKB_EXTENSIONS __u8 active_extensions;#endif /* Fields enclosed in headers group are copied * using a single memcpy() in __copy_skb_header() */ struct_group(headers, /* private: */ __u8 __pkt_type_offset[0]; /* public: */ // 이더넷의 경우 패킷 타입은 이더넷 헤더의 목적지 MAC 주소에 좌우되며, eth_type_trans() 함수로 결정된다. // 브로드캐스트에 대한 PACKET_BROADCAST // 멀티캐스트에 대한 PACKET_MULTICAST // 목적지 MAC 주고가 매개변수로 전달된 장치의 MAC 주소면 PACKET_HOST // 이 조건이 일치하지 않으면 PACKET_OTHERHOST __u8 pkt_type:3; /* see PKT_TYPE_MAX */ __u8 ignore_df:1; // 넷필터 패킷 추적 플래그. 이 플래그는 패킷 흐름 추적 넷필터 모듈인 xt_TRACE 모듈로 설정되며, 추적할 패킷을 표시하는데 사용된다. __u8 nf_trace:1; __u8 ip_summed:2; __u8 ooo_okay:1; __u8 l4_hash:1; __u8 sw_hash:1; __u8 wifi_acked_valid:1; __u8 wifi_acked:1; __u8 no_fcs:1; /* Indicates the inner headers are valid in the skbuff. */ // 캡슐화 필드는 SKB가 캡슐화에 사용됨을 의미한다. // 예를 들면 VXLAN 드라이버에서 사용된다. VXLAN은 UDP 커널 소켓을 통해 2계층 이더넷 패킷을 전송하는 표준 프로토콜이다. // 이 프로토콜은 터널을 차단하고 TCP나 UDP 통신만 허용하는 방화벽이 있을 경우 솔루션으로 사용될 수 있다. // VXLAN 드라이버는 UDP 캡슐화를 사용하고 SKB 캡슐화를 vxlan_init_net() 함수에서 1로 설정한다. __u8 encapsulation:1; __u8 encap_hdr_csum:1; __u8 csum_valid:1; /* private: */ __u8 __pkt_vlan_present_offset[0]; /* public: */ __u8 vlan_present:1; /* See PKT_VLAN_PRESENT_BIT */ __u8 csum_complete_sw:1; __u8 csum_level:2; __u8 csum_not_inet:1; __u8 dst_pending_confirm:1;#ifdef CONFIG_IPV6_NDISC_NODETYPE __u8 ndisc_nodetype:2;#endif // 이 플래그는 SKB가 ipvs(IP 가상 서버)를 소유했는지를 나타낸다. // IPVS는 커널 기반 전송 계층 로드 밸런싱 솔루션이다. __u8 ipvs_property:1; __u8 inner_protocol_type:1; __u8 remcsum_offload:1;#ifdef CONFIG_NET_SWITCHDEV __u8 offload_fwd_mark:1; __u8 offload_l3_fwd_mark:1;#endif#ifdef CONFIG_NET_CLS_ACT __u8 tc_skip_classify:1; __u8 tc_at_ingress:1;#endif __u8 redirected:1;#ifdef CONFIG_NET_REDIRECT __u8 from_ingress:1;#endif#ifdef CONFIG_NETFILTER_SKIP_EGRESS __u8 nf_skip_egress:1;#endif#ifdef CONFIG_TLS_DEVICE __u8 decrypted:1;#endif __u8 slow_gro:1;#ifdef CONFIG_NET_SCHED __u16 tc_index; /* traffic control index */#endif union { // 체크섬 __wsum csum; struct { __u16 csum_start; __u16 csum_offset; }; }; // 패킷의 큐 우선순위. Tx 경로에서 SKB의 우선순위는 소켓 우선순위(소켓의 sk_priority 필드)에 따라 설정된다. // 소켓 우선순위는 SO_PRIORITY 소켓 옵션으로 setsocket() 시스템 콜을 호출해 설정될 수 있다. // net_prio cgroup 커널 모듈을 사용하면 SKB에 대한 우선순위를 설정할 규칙을 정의할 수 있다. // 포워딩 패킷에 대한 우선순위는 IP 허데에서 TOS(서비스 타입) 필드에 따라 설정된다. // 16개의 요소로 구성된 ip_tos2prio라고 하는 테이블이 있는데 TOS에서 우선순위로 변환하는 것은 rt_tos2priority() 함수로 이뤄지며, 이때 IP 헤더의 TOS 필드에 따른다. __u32 priority; int skb_iif; __u32 hash; // VLAN 프로토콜이 사용됨. 보통 이는 802.1q 프로토콜이다. __be16 vlan_proto; // VLAN 태그 제어 정보(2바이트). ID와 우선순위로 구성된다. (SPT의 Bridge id, priority는 아니겠지..?) __u16 vlan_tci;#if defined(CONFIG_NET_RX_BUSY_POLL) || defined(CONFIG_XPS) union { unsigned int napi_id; unsigned int sender_cpu; };#endif#ifdef CONFIG_NETWORK_SECMARK // 보안 표시 필드. secmark 필드는 iptables SECMARK 대상으로 설정되며, 이는 패킷을 유효한 보안 컨텍스트로 라벨링한다. // 예를 들면, // iptables -t mangle -A INPUT -p tcp --dport 80 -j SECMARK --selctx // system_u:object_r:httpd_packet_t:s0 // iptables -t mangle -A OUTPUT -p tcp --sport 80 -j SECMARK --selctx // system_u:object_r:httpd_packet_t:s0 // 위 규칙에서 80번 포트에서 송수신되는 패킷을 httpd_packet_t로 고정적으로 라벨링한다. __u32 secmark;#endif union { // 이 필드는 SKB를 표시해 식별할 수 있게 한다. // 예를 들면, SKB의 mark 필드를 설정할 수 있는데, 조각(mangle) 테이블의 iptables PREROUTING 규칙에서 iptalbes MARK 대상으로 설정할 수 있다. // iptables -A PREROUTING -t mangle -i eth1 -j MARK --set-mark 0x1234 // 이 규칙은 탐색을 수행하기 ㅈㅓsdp eth1의 수신 트래픽을 대상으로 모든 SKB mark 필드에 0x1234 값을 할당할 것이다. __u32 mark; __u32 reserved_tailroom; }; union { __be16 inner_protocol; __u8 inner_ipproto; }; // 전송 계층(L4) 헤더 __u16 inner_transport_header; // 네트워크 계층(L3) 헤더 __u16 inner_network_header; // 데이터 링크 계층(L2) 헤더 __u16 inner_mac_header; __be16 protocol; __u16 transport_header; __u16 network_header; __u16 mac_header;#ifdef CONFIG_KCOV u64 kcov_handle;#endif ); /* end headers group */ /* These elements must be at the end, see alloc_skb() for details. */ // 데이터의 꼬리(tail) sk_buff_data_t tail; // 버퍼가 끝나는 부분. tail은 end를 초과할 수 없다. sk_buff_data_t end; // 버퍼의 머리(head) unsigned char *head, // 데이터의 머리(head). 데이터 영역은 sk_buff 할당에서 분리되어 할당된다. *data; // SKB에 대해 할당된 전체 메모리(SKB 구조체 자체와 할당된 데이터 영역 크기를 포함) unsigned int truesize; refcount_t users;#ifdef CONFIG_SKB_EXTENSIONS /* only useable after checking -&gt;active_extensions != 0 */ struct skb_ext *extensions;#endif};Basic functions for sk_buffSKB의 headroom과 tailroom은 아래와 같다.SKB의 headroom과 tailroom참고: Basic functions for sk_buff{} void skb_reserve(struct sk_buff *skb, int len) tail을 감소시켜 빈 skb의 headroom을 증가시킨다.(headroom을 조정한다.) void *skb_push(struct sk_buff *skb, unsigned int len) skb의 데이터 포인터를 감소시키고 skb의 길이를 len만큼 증가시킨다.(headroom을 줄여서 데이터를 추가한다.) void *skb_pull(struct sk_buff *skb, unsigned int len) skb의 데이터 포인터를 증가시키고 len만큼 skb의 길이를 감소시킨다.(headroom을 늘려서 데이터를 제거한다.) void *skb_put(struct sk_buff *skb, unsigned int len) 버퍼에 데이터를 추가한다. 이 함수는 skb의 버퍼에 len 바이트를 추가해서 skb의 길이를 len만큼 증가시킨다.(tailroom을 줄이고 데이터를 추가한다.) void skb_trim(struct sk_buff *skb, unsigned int len) 버퍼의 데이터를 삭제한다.(tailroom을 늘려 데이터를 제거한다.)" }, { "title": "Event란건 어쩌면 어려운게 아닐까", "url": "/posts/what-is-a-kubernetes-watch-event-4rd/", "categories": "kubernetes", "tags": "kubernetes, watch, event", "date": "2022-01-29 20:00:00 +0900", "snippet": "Kubernetes ArchitectureKubernetes는 microservice 기반의 아키텍처가 적용되어 있다.Control Plane, Worker Node의 컴포넌트들은 개별 서비스로 구현된다.특히 Control Plane은 Event와 함께 느슨하게 결합된 구성 요소의 원칙을 많이 접목시켜 사용하고 있다.이러한 아키텍처의 주요 이점은 개발 및 배포의 유연성과 독립성, 수평 확장성 및 장애 허용이라고 할 수 있겠다.즉 etcd, scheduler, api server 등과 같은 중요한 프로세스를 두 개 이상의 인스턴스로 실행한다.이러한 개별 서비스들은 Control Loop(관찰 -&gt; 분석 -&gt; 행위)로 모델링되면서 오직 api server와 통신을 한다.즉, 서로 직접 통신을 하지 않는다.이러한 특성 탓에 Kubernetes는 Microservice 간의 흐름이 중앙 조정자없이 구성되는 event-driven architecture라고도 한다.What is an Event?이벤트란건 단순히 일어난 불변의 사실이다.Kubernetes control plane에서 여러 구성 요소들이 API server를 통해 Kubernetes의 개체들을 변경하며, 이러한 변경에 대한 작업은 결국 event로 이어진다.Producers and/or consumers모든 프로세스(또는 컨트롤러)는 이벤트의 생산하는 producer일 수도 있고, 이벤트를 소비하는 consumer일 수도 있다.소비자는 API server에서 이벤트를 수신하려는 개체를 지정한다.이를 Kubernetes에서는 listWatch라고 한다.소비자가 관찰을 시작할 때엔 관련된 리소스의 모든 리스트를 나열한 다음특정 리소스 버전 이후의 이벤트에 대해서만 watch 모드로 전환하여 API server의 부하를 줄이도록 설계가 되어 있다.소비자와 생산자는 대기열 등의 구조들에 의해 완전히 분리되어 있으며 서로에 대해 직접적으로 알 필요가 전혀 없다.이 구조는 전체 시스템을 아주 쉽게 확장 가능하도록 하는 가장 큰 요인이 될 것이다.따라서 이벤트가 생산자에서 소비자로 전파되는데 시간이 약간의 걸리기는 할테지만(거의 실시간), 설계 상 완전히 비동기적이고 궁극적으로는 일관된 플랫폼이다.Kubernetes core design conceptEvent의 상태 변경을 감지하는 2가지 원칙적인 옵션이 존재한다. Edge-driven triggers 상태 변경이 발생하는 시점(e.g., 존재하지 않던 Pod가 실행됨)에 handler가 트리거된다. Level-driven triggers 상태는 주기적으로 확인되며 특정 조건이 충족(e.g., Pod가 실행 중)되면 handler가 트리거 된다. Polling의 한 형태라고도 할 수 있다.Kubernetes 개체의 변경은 event로 이어진다고 했다.프로세스(또는 컨트롤러)의 맥락에서 보자면 발생되는 이벤트에 언제 어떻게 반응해야할지, 구현에 대한 고민이 생길 수 있다.Kubernetes에서는 이를 어떻게 해결했는지 크게 두 주제를 살펴보자.Level Triggering and Soft Reconciliation Edge-driven logic 네트워킹이 끊어지면 event가 손실될 수 있고, controller 자체에 버그가 존재하거나 일부 외부 cloud API가 다운되는 경우도 있어서 누락된 event에 대해 잘 대처하지 못한다. replicaSet controller가 pod 조욜 시에만 해당 pod를 교체한다고 가정했을 때, 누락된 event는 전체 상태를 조정하지 않기 때문에 항상 더 적은 수의 pod가 실행될 수 있게 된다. Edge-triggered, level-driven logic cluster의 최신 상태를 기반으로 로직을 구현하기 때문에 다른 이벤트가 수신될 때 1.에서 발생될 수 있는 문제를 복구한다. replicaSet controller의 경우 항상 지정된 replicas를 클러스터에서 실행 중인 pod와 비교하며 event가 손실되더라고 다음 pod update가 수신될 때 누락된 모든 pod를 교체한다. Reconciliation with resync 2.에 지속적인 동기화를 추가한다. 일반적인 edge-driven trigger의 문제를 감안할 때, kubernetes controller는 3.의 전략으로 돌아간다. 컨트롤러는 기본적으로 stateless하다.이벤트 기반 설계는 이벤트 소싱 개념과 유사하게 컨트롤러가 (재)시작될 때 모든 (적절한) 이벤트를 replay한다.Kubernetes의 컨트롤러는 Edge-Driven Triggers가 아닌 Level-Driven Triggers로 동작하도록 설계되었기 때문에네트워크 이슈나 컨트롤러 다운타임 동안 이벤트를 놓치게 되면 다음 동기화(Soft Reconciliation)가 있을 때 해당 개체애 대한 완전한 상태를 수신할 수 있게 된다.Optimistic ConcurrencyEtcd에 정보가 저장이 될 때 Kubernetes의 구조 상 동일 정보가 두 번 이상 전달될 수 있고컨트롤러가 서로 간에 직접 통신하지 않기 때문에 상태가 변경될 때 경쟁 조건이 발생할 가능성이 있다.낙관적 동시성을 통해 다른 컨트롤러에서도 동일한 개체에 쓰기 작업을 할 경우 충돌이 발생되며 각자 컨트롤러에서 충돌에 대한 후처리를 해야만 한다.Kubernetes는 낙관적 동시성을 단조적으로 증가하는 resourceVersion 기반으로 깔끔하게 구현해뒀다.Watch in ETCDetcd는 하나의 key에 대응되는 value 하나만을 저장하고 있는 것이 아니라, key의 모든 변경사항을 파일시스템에 기록하며 이것은 revision을 통해 이루어진다. Key Value Revision /registry/pods/default/test …test=1… 1 /registry/pods/default/test …test=5… 2 /registry/pods/default/test …test=2… 3 Etcd는 key에 대한 변경 사항을 비동기적으로 모니터링하기 위한 이벤트 기반 인터페이스는 watch feature를 통해 제공한다.API server 내의 etcd v3 client는 watchGrpcStream을 통해 etcd의 watch feature를 사용하고, etcd에 대한 session을 제공하고 관리한다.그림 1. Watch in etcdetcd의 Revision은 곧 Kubernetes에서의 Resource Version이다.etcd3storage의 versioner(APIObjectVersioner)는 etcd로부터 전달받은 객체의 revision 값을 통해 resource version을 설정한다.// UpdateObject implements Versionerfunc (a APIObjectVersioner) UpdateObject(obj runtime.Object, resourceVersion uint64) error { accessor, err := meta.Accessor(obj) if err != nil { return err } versionString := \"\" if resourceVersion != 0 { versionString = strconv.FormatUint(resourceVersion, 10) } accessor.SetResourceVersion(versionString) return nil}Watch Event in kubeAPIServerKubernetes에서의 Watch Event는 아래와 같은 흐름으로 전달이 된다. etcd watcher -&gt; watch cache -&gt; cacheWatcher(s) Get events from etcd Implement Store interface Serve events to clients Cacher와 Etcd storage는 API server가 시작될 때 지원해야할 리소스들의 정보에 따라 API가 셋업되면서 만들어진다.Cacher 내부에 포함된 Reflector에서 호출될 ListAndWatch 메서드에서의 watch 작업은 etcd watcher가 포함된 etcd storage의 watch 메서드를 호출한다.그림 2. Cacheretcd watcher는 etcd v3 client session을 제공하고 관리하는 Client의 Watch를 통해(여기에서 gRPC를 통해 etcd와 bidirection stream으로 이벤트를 전달받는다.)WatchResponse를 가져와 파싱하고, watchChan.incomingEventChan으로 전달한다.그림 3. Etcd storageprocessEvent를 통해 etcd watcher의 이벤트를 incomingEventChan으로 받아 처리하고 그 결과를 resultChan으로 보낸다.이 결과는 곧 Cacher 내부의 reflector가 수행하는 watch로 전달되어 watchCache가 받아 processEvent를 통해 이벤트를 전달하게 되고Cacher의 Watchers에 등록되어 있던 모든 cacheWatcher들에게 해당 이벤트를 최종적으로 전달해준다.Cacher의 구성요소들을 살펴보는 것을 끝으로 마무리하자. RawStorage Low level key/value storage이다.사실 이건 Cacher의 구성요소라기 보다는 리소스에 따라 기본적으로 생성되어야 하는 것이며 watchCache 기능이 필요없는 리소스인 경우에는UndecoratedStorage 를 통해 storage가 생성이 될텐데, 이 때에도 RawStorage는 만들어진다.생성될 때 주어진 구성을 기반으로 ETCD3Storage라는 storage backend가 만들어진다.ETCD3Storage 내부에는 etcd3를 위한 storage.Interface 구현체인 Store와 etcd v3 client의 session을 제공하고 관리하는 ETCD3Client가 존재하며API Server는 etcd에서 제공해주는 watch feature를 사용하기 위해 ETCD3Client를 통해 etcd와 gRPC bidirectional stream 연결을 맺고 key에 대한 변경 사항을 비동기적으로 모니터링한다. cacheListerWatcher ListerWatcher는 List() 및 Watch()를 포함하는 인터페이스 객체이다.먼저 모든 항목을 나열하고 호출 순간의 resource version을 가져온 다음 이를 사용해 watch를 시작한다. reflector ListerWatcher를 사용해 Store로부터 전달받은 event(transformer와 versioner를 거쳐옴)를 type에 따라 분류하고 watchCache에 전달한다.Object가 추가되거나 삭제될 때에는 Added/Deleted로 분류되며, Modified는 여러 변경 사항이 결합된 이벤트가 호출될 수 있으므로이것을 단일 변경 사항에 대한 이벤트라고 볼 순 없다. watchCache watchCache는 Store 인터페이스를 구현하며 API Server가 etcd에서 감시하는 객체를 저장하기 위해 사용되는 cache이다. watchers watchers(indexedWatchers)는 map이며 map의 value type은 cacheWatcher이다.kubelet, kube-scheduler와 같은 client가 특정 유형의 감시 리소스가 필요할 때 apiServer에 watch 요청을 시작하고,apiServer는 cacheWatcher를 생성한다.cacheWatcher는 watch.Interface의 구현체이며, thread-safe하지 않다. watch resource를 담당하여 http 통신을 통해 API Server에서 client로 전달한다. watchCacheEvent watchCache를 사용하는 client에게 보내는 단일 watch event이다.일반적인 watch.Event에 추가로 upper layers에서 적절한 필터링을 활성화하기 위한 객체의 이전 상태(prevObject)를 포함한다.끝." }, { "title": "Basic ETCD", "url": "/posts/basic-etcd/", "categories": "etcd", "tags": "kubernetes, watch, event, etcd", "date": "2022-01-19 23:00:00 +0900", "snippet": " Highly Available Fully Replicated Strong consistency model Scalable watch mechanism Concurrency control primitivesDistributed Key/Value storeDistributed consensus is a fancy way to express the idea of getting more than one party to agree on something We use tools like Kubernetes because we want to build a fault tolerance system, which requires redundancy and multiple resources Taking action on the system means that every manager entity in the system has to agree about the actionWhat is RaftIn a distributed model, that log entry can only “become truth” once the manager agree on the new value.Consensus Datastore: RAFT Consensus Algorithm Raft is an algorithm to manage consensus-based systems (like container orchestrators) It is designed to be easy to understand It also has a cute logoRaft implements consensus by a leader approach.The cluster has one and only one elected leader which is fully responsible for managing log replication on the other servers of the cluster.It means that the leader can decide on new entries’ placement and establishment of data flow between it and the other servers without consulting other servers.A leader leads until it fails or disconnects, in which case a new leader is elected.The Secret Lives of DataRaft is used in a lot of placesOrchestration systems typically use a key/value store backed by a consensus algorithm Kubernetes -&gt; etcd, and by extension, every system that uses etcd Docker (swarm mode) Nomad Zookeeper uses Zookeeper Atomic Broadcast (ZAB), which is similar to RaftRaft is responsible for Leader election Raft uses a randomized election timeout to ensure that split vote problems are resolved quickly.This should reduce the chance of a split vote because servers won’t become candidates at the same time: a single server will time out,win the election, then become leader and send heartbeat messages to other servers before any of the followers can become candidates.raftscope Log replication The leader is responsible for the log replication.It accepts client requests. Each client request consists of a command to be executed by the replicated state machines in the cluster.After being appended to the leader’s log as a new entry, each of the requests is forwarded to the followers as AppendEntries messages.In case of unavailability of the followers, the leader retries AppendEntries messages indefinitely, until the log entry is eventually stored by all of the followers.logging-post Safety Election safety (at most one leader can be elected in a given term.),Leader append-only (a leader can only append new entries to its logs (it can neither overwrite nor delete entries).),Log matching (if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index.),Leader completeness (if a log entry is committed in a given term then it will be present in the logs of the leaders since this term),State machine safety (if a server has applied a particular log entry to its state machine, then no other server may apply a different command for the same log.)Restore from a backupYou have a backup, right? : Some tools manage this for youGenerally speaking: The log snapshots live in /snap The WAL lives in /walQuorumThe minimum number of votes needed to perform an operation.Without quorum, your system can’t do work.Quorum is satisfied with over 50% of agreement.\\[(N/2) + 1\\] Managers Quorum Fault Tolerance 1 1 0 2 2 0 3 2 1 4 2 1 5 3 2 6 4 2 7 4 3 Key Space/prefix/K8S type/namespace/resource name/registry/pods/production/service1-xxxxxxxx/registry/replicasets/development/service1lexically orderedRequest/Response OperationsRANGE &lt;start_key&gt;..&lt;end_key&gt;PUT &lt;key&gt; &lt;value&gt;DELETE RANGE &lt;start_key&gt;..&lt;end_key&gt;TXN (if &lt;condition&gt; then &lt;op1, ..&gt; else &lt;op2, ..&gt;)Linearizable Consistency (a.k.a External Consistency)Streaming OperationsCREATE WATCH &lt;key1&gt;..&lt;key2&gt;client -------------------------------------------&gt; etcd gRPC bidirectional streamclient &lt;------------------------------------------- etcdWATCH CREATED &lt;watch-id&gt;EVENT &lt;watch-id&gt; PUT &lt;key1&gt; &lt;value1&gt;EVENT &lt;watch-id&gt; DELETE &lt;key2&gt;...Eventual Consistencyclient &lt;---- Watch stream &lt;---- Follower &lt;--RAFT Chatter--&gt; LeaderData StorageMulti-version concurrency control / Copy-on-write for all modificationsetcd - MVCC keyspace.Values may be accessed by key+version.This is used to implement the watch operation.Compaction applies to the etcd keyspace Removes all versions of objects older than a specific revision number. Kubernetes default policy: all data older than 5 minutes every 5 minutes Kube-apiserver requests compactions. etcd auto-compaction is disabled.BoltDB - MVCC internally enable 1 write + N reads to be executed concurrently.Defragmentation applies to the bolt db file Recovers all free space in the bolt db file. Only to shrink a db file as bolt does not automatically shrinks it`s file. Etcd will defrag and the file only if requested. This is a “stop-the-world” operation.How etcd Stores and Serves DataFor each write: Append write to WAL (Write Ahead Log (.wal files) Apply write to Keyspace (Persisted Keyspace (db file)Every “–snapshot-count” writes: Create a snapshot file Record revision snapshot was created to WAL Remove WAL file older than the snapshotRAFT ensures WAL log is the same on all members of an etcd cluster!References Debugging etcd - Joe Betz &amp; Jingyi Hu, Google - Youtube Understanding Distributed Consensus in etcd and Kubernetes - Laura Frank, CloudBees - Youtube The Raft Consensus Algorithm - Github Raft (algorithm) - Wikipedia" }, { "title": "Informer의 구조", "url": "/posts/what-is-a-kubernetes-watch-event-3rd/", "categories": "kubernetes", "tags": "kubernetes, watch, event, apiserver, gorestful, informer", "date": "2022-01-08 22:45:00 +0900", "snippet": "일전에 정리했던 내용과 같이 클라이언트가 API server에 Watch event를 요청할 때 streaming HTTP connection을 맺어해당 리소스의 변경에 대한 이벤트를 전달받곤 했다.이러한 변경 감지가 필요할 때마다 API server에 접근해야하는건 Kubernetes 시스템에 부하를 줄 수도 있다.게다가 여러 클라이언트, 컨트롤러에서 Watch event를 요청하게 되면 시스템에 더욱 높은 부하가 생성될 것이다.Informer는 In-memory 캐싱을 통해 이러한 문제를 해결하고자 했다. 이번 포스팅에서는 Informer에 대해 정리해보도록 하자.Prerequisites Go kubectl minikubeFirst, let’s use InformerInformer에 대해 자세히 파악하기 전에 간단히 사용해보고자 한다.먼저 minikube를 실행시켜주자.❯ minikube start😄 minikube v1.24.0 on Darwin 12.2✨ Automatically selected the docker driver. Other choices: hyperkit, parallels, ssh👍 Starting control plane node minikube in cluster minikube🚜 Pulling base image ...💾 Downloading Kubernetes v1.22.3 preload ... &gt; preloaded-images-k8s-v13-v1...: 501.73 MiB / 501.73 MiB 100.00% 55.37 Mi &gt; gcr.io/k8s-minikube/kicbase: 355.78 MiB / 355.78 MiB 100.00% 14.47 MiB p🔥 Creating docker container (CPUs=2, Memory=1985MB) ...🐳 Preparing Kubernetes v1.22.3 on Docker 20.10.8 ... ▪ Generating certificates and keys ... ▪ Booting up control plane ... ▪ Configuring RBAC rules ...🔎 Verifying Kubernetes components... ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5🌟 Enabled addons: storage-provisioner, default-storageclass🏄 Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by defaultInformer 예제를 작성하기 위한 Go 프로젝트를 하나 만들어준다.❯ go mod init example.com/informergo: creating new go.mod: module example.com/informer❯ touch main.gomain.go 파일 생성 후 아래 코드를 작성하도록 하자.package mainimport ( \"fmt\" \"os\" \"time\" v1 \"k8s.io/api/core/v1\" \"k8s.io/client-go/informers\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/tools/cache\" \"k8s.io/client-go/tools/clientcmd\")func main() { kubeconfigPath := \"location to your kubeconfig file path\" config, err := clientcmd.BuildConfigFromFlags(\"\", kubeconfigPath) if err != nil { fmt.Printf(\"The kubeconfig can't be loaded: %v\\n\", err.Error()) os.Exit(1) } clientset, err := kubernetes.NewForConfig(config) if err != nil { fmt.Printf(\"NewForConfig failed: %v\\n\", err.Error()) os.Exit(1) } stopCh := make(chan struct{}) defer close(stopCh) informerFactory := informers.NewSharedInformerFactory(clientset, time.Second*1) podInformer := informerFactory.Core().V1().Pods() podInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: func(obj interface{}) { pod := obj.(*v1.Pod) fmt.Println(\"Add: \" + pod.Name) }, UpdateFunc: func(oldObj, newObj interface{}) { pod := newObj.(*v1.Pod) fmt.Println(\"Update: \" + pod.Name) }, DeleteFunc: func(obj interface{}) { pod := obj.(*v1.Pod) fmt.Println(\"Delete: \" + pod.Name) }, }) informerFactory.Start(stopCh) fmt.Println(\"InformerFactory started\") &lt;-stopCh}InformerFactory로부터 PodInformer를 가져와서 변경 감지에 대한 처리를 할 수 있는 기본적이고 간단한 코드라고 할 수 있겠다.main() 함수를 하나하나 살펴보도록 하자.16-20 라인은 *rest.Config를 가져오는 부분이다.Kubernetes API server에 대한 접근하기 위한 여러 정보를 포함하고 있다.각자의 로컬에 있는 .kube/config 파일을 통해 빌드를 하는데 한가지 참고할 부분은 kubeconfigPath로~/.kube/config 등의 상대 경로가 아닌 절대 경로로 입력해 주어야 할 수도 있다.23-27 라인에서는 *rest.Config를 통해 *kubernetes.Clientset을 생성하고 있다.모든 기본 Kubernetes 리소스에 대한 많은 클라이언트가 여기에 포함되어 있기 때문에 Clientset라고 한다.32 라인에서 SharedInformerFactory 를 만든다.Shared informer factory는 informer들이 애플리케이션 내에서 동일한 리소스의 변경 사항을 공유할 수 있게 한다.즉, 서로 다른 제어 루프에서 Shared informer factory를 통해 API server에 대한 동일한 watch 커넥션을 사용할 수 있다는 말이다.이러한 특성으로 인해서 kube-controller-manager 내부에 있는 수많은 컨트롤러가 리소스에 대해 접근을 각자 하지만프로세스 내에 존재하는 단일 informer를 통해 리소스 변경에 대한 이벤트를 전달받게 된다.이 후 Pod informer를 가져와서 cache.ResourceEventHandlerFuncs를 사용해ResourceEventHandler 를 달아준다.ResourceEventHandler를 통해 해당 리소스에서 발생되는 이벤트에 대한 알림을 처리할 수 있다.한 가지 명심해야할 사안은 핸들러 내부에서 수신된 객체를 직접 수정해서는 안된다. OnAdd Object가 추가될 때 호출된다. OnUpdate Object가 수정될 때 호출된다. oldObj는 object의 변경에 따른 이벤트를 받기 전에 마지막으로 관찰된 상태이다.여러 변경 사항이 결합되어 이벤트가 호출될 수 있으므로 이것을 단일 변경 사항에 대한 이벤트라 볼 순 없다. OnDelete Object가 삭제되기 전의 상태를 가져올 수 있으면 가져오고 그렇지 못한다면 DeletedFinalStateUnknown 유형의 object를 가져오게 된다.후자의 경우는 watch event가 어떠한 문제로 인해 종료되어 삭제에 대한 이벤트를 놓쳤을 경우에 발생될 수 있다.위 이벤트에 대한 처리 로직을 작성하면 된다.여기에선 간단히 로깅만 하는 정도로 해두었다.마지막으로 53 라인에서 stop channel이 닫힐 때까지는 프로세스가 유지될 수 있도록 채널 수신을 받게 해두었다.이제 바로 실행해보자.❯ go mod tidy❯ go run main.goInformerFactory startedAdd: kube-apiserver-minikubeAdd: storage-provisionerAdd: coredns-78fcd69978-424p5Add: kube-proxy-crjsdAdd: etcd-minikubeAdd: kube-scheduler-minikubeAdd: kube-controller-manager-minikubeUpdate: kube-apiserver-minikubeUpdate: storage-provisionerUpdate: coredns-78fcd69978-424p5Update: kube-proxy-crjsdUpdate: etcd-minikube...Kubernetes 클러스터 위에 올라가 있는 모든 Pod들의 이벤트가 핸들링되고 있음을 확인할 수 있다.모든 namespace의 pod를 관찰할 필요는 없으므로 관찰 범위를 줄여보자.namespaceOption := informers.WithNamespace(\"default\")informerFactory := informers.NewSharedInformerFactoryWithOptions(clientset, time.Second*1, namespaceOption)32 라인의 informerFactory를 생성하는 부분을 위와 같이 변경하고 다시 실행하자.❯ go run main.goInformerFactory started# 한층 조용해졌다. 새로운 shell을 열어 nginx pod를 default namespace에 배포해보자.❯ kubectl run nginx --image=nginxpod/nginx created# 이제 다시 이전 shell로 돌아가보면Add: nginxUpdate: nginxUpdate: nginxUpdate: nginxUpdate: nginxUpdate: nginx...nginx pod에 대한 이벤트가 핸들링되고 있음을 확인할 수 있다.여기서 이상한 부분이 있다. OnUpdate 이벤트는 왜 계속 불려지고 있을까?func(obj interface{}) error { // from oldest to newest for _, d := range obj.(Deltas) { obj := d.Object if transformer != nil { var err error obj, err = transformer(obj) if err != nil { return err } } switch d.Type { case Sync, Replaced, Added, Updated: if old, exists, err := clientState.Get(obj); err == nil &amp;&amp; exists { if err := clientState.Update(obj); err != nil { return err } h.OnUpdate(old, obj) } else { if err := clientState.Add(obj); err != nil { return err } h.OnAdd(obj) } case Deleted: if err := clientState.Delete(obj); err != nil { return err } h.OnDelete(obj) } } return nil}Informer에서는 DeltaFIFO 에서 delta를 꺼내와 위와 같은 처리를 하게 된다.13 라인부터의 switch 문을 보게 되면 Updated 타입 뿐만 아니라 Sync, Replaced와 같은 다른 타입 또한 h.OnUpdate()로 호출될 수 있는 것을 볼 수 있다.Sync 타입은 informerFactory를 생성할 때 defaultResync 인자로 넘겨준 time.Duration과 밀접한 연관이 있다.주기적으로 재동기화가 되며 이 기간동안 합성된 이벤트가 핸들러로 전달되게 된다.위 작성된 코드에 따르면 1초마다 resync를 한다. 5초로 변경해보고 얼마나 자주 불리는지 확인해보자.Replaced 타입은 watch event의 오류로 인해 re-list 작업을 해야할 때 발생된다. 앞서 정리했던 ListAndWatch 작업에서의 List라고 보면 된다.이와 같은 다양한 변경 타입으로 인해 OnUpdate 이벤트는 지속적으로 호출되고 있는 것이다.진짜 변경이 일어났을 경우에만 처리를 하고 싶다면 어떻게 해야할까?우린 이미 resourceVersion이 무엇을 의미하는지 앞선 정리를 통해 알고 있는 상태이다.당장 사용해보자.UpdateFunc: func(oldObj, newObj interface{}) { old := oldObj.(*v1.Pod) cur := newObj.(*v1.Pod) fmt.Println(\"Update: \" + cur.Name + \", old RV: \" + old.ResourceVersion + \", new RV: \" + cur.ResourceVersion)},UpdateFunc을 이렇게 변경하고 다시 실행해보자.❯ go run main.goInformerFactory startedAdd: nginxUpdate: nginx, old RV: 2206, new RV: 2206Update: nginx, old RV: 2206, new RV: 2206Update: nginx, old RV: 2206, new RV: 2206...old/new resourceVersion을 확인할 수 있다.object에 대한 변경이 전혀 없는데도 OnUpdate의 동작으로 인해 꾸준히 핸들링되고 있다.이제 nginx pod에 변경을 가해보자.간단히 label을 추가하는 작업을 해보고자 한다.❯ kubectl label pods nginx foo=barpod/nginx labeled---Update: nginx, old RV: 2206, new RV: 2451 &lt;- pod/nginx labeledUpdate: nginx, old RV: 2451, new RV: 2451Update: nginx, old RV: 2451, new RV: 2451nginx pod에 label이 추가되고 resourceVersion 또한 변경되었다.이렇듯 object가 영속화되는 시점의 상태를 식별할 수 있는 resourceVersion을 사용하면 쉽게 변경 감지에 대한 이벤트를 처리할 수 있다.Informer’s Architecture이제 Informer가 어떤 형태로 구성되어 있는지 살펴보도록 하자.Kubernetes 소스 코드에 따른 Informer를 통한 watch event 전달 방식은 그림 1.과 같다.그림 1. Informer가 watch event를 전달하는 방식하나의 SharedInformer는 특정 API Group 및 kind/resource의 object에 대한 연결을 제공한다.object는 API Group, kind/resource, namespace 및 name으로 식별된다.SharedInformer를 기반으로 Indexer 추가 및 가져오기 기능을 제공하는 SharedIndexInformer를 살펴보자.(informers.NewSharedInformer()를 호출하면 NewSharedIndexInformer를 반환한다.)SharedIndexInformer는 주요 컴포넌트인 Indexer, Controller, SharedProcessor를 확인하고 넘어가는 것이 좋겠다. Indexer Indexer는 인덱싱된 로컬 캐시이다.object를 저장하고 처리하는 인터페이스인 Store를 여러 인덱스로 확장하며 DeltaFIFO에게는 KnownObjects 역할을 하며object를 조회할 때 사용되는 Key의 목록을 제공해준다.또한 클라이언트가 Lister를 통해 List/Get 요청을 하면 캐싱된 데이터를 전달해준다. Controller Controller는 실행될 때 지정된 리소스를 감시하고 모든 변경 사항이 지정된 Store에 저장되도록 하는 Reflector를 생성하면서 감시 작업에 ListerWatcher를 사용하도록 한다.ListerWatcher는 object/notification들을 가져오고 이를 DeltaFIFO로 push하는 동시에 해당 FIFO에서 pop하여HandleDeltas로 Delta를 처리하는 컨트롤러이며 각 Delta에 대해 Indexer를 업데이트하고 관련 알림을 sharedProcessor에 채운다. SharedProcessor Informer의 모든 클라이언트(Listener를 통해)에 해당 알림을 전달하는 역할을 한다.클라이언트에서 ResourceEventHandler를 추가하면 SharedProcessor의 Listener에 추가가 되어 알림을 지속적으로 받을 수 있게 된다.여기에서 DeltaFIFO는 주어진 객체의 변경 사항들에 대한 Delta를 항목으로 다루는 Queue이다.Informer가 실행될 때 생성되며 Pop(), Get(), GetByKey(), List()와 같은 method들을 제공한다.ConclusionInforemr는 특정 리소스에 대한 변경 감지가 필요한 수많은 클라이언트가 존재하더라도 하나의 watch connection으로 처리될 수 있도록 설계되었다.변경 감지가 필요한 클라이언트는 단지 ResourceEventHandler를 추가하기만 하면 된다.또한 Indexer에 캐싱된 데이터를 Lister를 통해서 접근해 사용할 수 있다.그리고 Informer는 watch connection이 끊어지면 WatchErrorHandler를 호출한 후 Backoff 한다.만약 중단된 기간이 길어져서 etcd가 event를 데이터베이스에서 삭제를 해 event가 손실되는 경우, Informer는 모든 object를 다시 나열(re-list)한다.func (r *Reflector) Run(stopCh &lt;-chan struct{}) { klog.V(3).Infof(\"Starting reflector %s (%s) from %s\", r.expectedTypeName, r.resyncPeriod, r.name) wait.BackoffUntil(func() { if err := r.ListAndWatch(stopCh); err != nil { r.watchErrorHandler(r, err) } }, r.backoffManager, true, stopCh) klog.V(3).Infof(\"Stopping reflector %s (%s) from %s\", r.expectedTypeName, r.resyncPeriod, r.name)}클라이언트가 Informer를 사용하지 않고 Watch() verb를 사용했다면 이러한 작업들을 직접해야만 하거나, 그렇지 않다면 event를 놓치게 될 것이다.이러한 이유들로 Informer의 사용이 권장되고 있다. 이제 마지막으로 Kubernetes의 Event에 대해 파악해보자.끝." }, { "title": "Watch Server에 요청이 도달하기까지의 과정", "url": "/posts/what-is-a-kubernetes-watch-event-2nd/", "categories": "kubernetes", "tags": "kubernetes, watch, event, apiserver, gorestful", "date": "2022-01-01 00:00:00 +0900", "snippet": "앞서 클라이언트와 API server가 어떤 방식으로 Watch event를 요청하고 응답하는지 확인해봤다.이번에는 좀 더 깊게 들어가서 API server가 Watch event에 대한 응답을 하기 위해 어떤 준비를 하는지, Watch Server 생성까지의 구현 부분을 알아볼 차례이다.분석하는 와중에 정말 많은 용어들이 등장했는데 내부적으로 왜 이러한 네이밍을 했는지 Ubiquitous Language를 선정할 때 오고 갔던 많은 내용들이 궁금해지기도 했다.이러한 용어들도 같이 정리해볼까 한다.Prerequisites Kubernetes Source CodeAPI Server analysisserver.go 를 보면여느 kubernetes component들과 마찬가지로 kube-apiserver는 cobra.Command 1 를 사용해 시작되는걸로 확인이 된다.func NewAPIServerCommand() *cobra.Command { s := options.NewServerRunOptions() cmd := &amp;cobra.Command{ Use: \"kube-apiserver\", // ... RunE: func(cmd *cobra.Command, args []string) error { // ... // set default options completedOptions, err := Complete(s) if err != nil { return err } // validate options if errs := completedOptions.Validate(); len(errs) != 0 { return utilerrors.NewAggregate(errs) } return Run(completedOptions, genericapiserver.SetupSignalHandler()) }, // ... return cmd}ServerChaincobra.Command의 RunE function에서 completedOptions를 설정하고 해당 옵션이 유효한지 확인한다.그리고 지정된 APIServer를 생성하고 실행하는 Run() method를 호출한다.Run() method 내부에서 호출되는 CreateServerChain() method를 살펴보자.func CreateServerChain(completedOptions completedServerRunOptions, stopCh &lt;-chan struct{}) (*aggregatorapiserver.APIAggregator, error) { kubeAPIServerConfig, serviceResolver, pluginInitializer, err := CreateKubeAPIServerConfig(completedOptions) // ... apiExtensionsConfig, err := createAPIExtensionsConfig(*kubeAPIServerConfig.GenericConfig, kubeAPIServerConfig.ExtraConfig.VersionedInformers, pluginInitializer, completedOptions.ServerRunOptions, completedOptions.MasterCount, serviceResolver, webhook.NewDefaultAuthenticationInfoResolverWrapper(kubeAPIServerConfig.ExtraConfig.ProxyTransport, kubeAPIServerConfig.GenericConfig.EgressSelector, kubeAPIServerConfig.GenericConfig.LoopbackClientConfig, kubeAPIServerConfig.GenericConfig.TracerProvider)) // ... apiExtensionsServer, err := createAPIExtensionsServer(apiExtensionsConfig, genericapiserver.NewEmptyDelegateWithCustomHandler(notFoundHandler)) // ... kubeAPIServer, err := CreateKubeAPIServer(kubeAPIServerConfig, apiExtensionsServer.GenericAPIServer) // ... aggregatorConfig, err := createAggregatorConfig(*kubeAPIServerConfig.GenericConfig, completedOptions.ServerRunOptions, kubeAPIServerConfig.ExtraConfig.VersionedInformers, serviceResolver, kubeAPIServerConfig.ExtraConfig.ProxyTransport, pluginInitializer) // ... aggregatorServer, err := createAggregatorServer(aggregatorConfig, kubeAPIServer.GenericAPIServer, apiExtensionsServer.Informers) // ... return aggregatorServer, nil}completedOptions의 설정에 따라 kubeAPIServerConfig와 Extension API server를 위한 apiExtensionsConfig를 통해 기본 API server와 Extended API server를 만들고생성된 두 API server의 access를 통합하는 Aggregator Server를 생성하여 반환한다.Extension API server는 customresourcedefinitions resource를 관리하게 되며 나머지 api-resources들은 kubeAPIServer가 관리하게 된다.Aggregation Architecture에 대한 지식이 있으면 매우 유용할 것이라는 이야기를 전해들었기에 AggregatorServer와 관련해서Aggregation layer 2 와 어떠한 연관이 있는지 추후에 확인해보도록 하자.이제 CreateKubeAPIServer method를 확인해보자.func CreateKubeAPIServer(kubeAPIServerConfig *controlplane.Config, delegateAPIServer genericapiserver.DelegationTarget) (*controlplane.Instance, error) { kubeAPIServer, err := kubeAPIServerConfig.Complete().New(delegateAPIServer) if err != nil { return nil, err } return kubeAPIServer, nil}Line:2의 kubeAPIServerConfig.Complete().New(delegateAPIServer) 코드가 보인다.Complete() method를 통해 유효한 데이터가 존재해야하는 모든 설정되지 않은 필드를 채우고 New() method를 통해 kube-apiserver의 구성을 생성한다.APIServerHandlersfunc (c completedConfig) New(delegationTarget genericapiserver.DelegationTarget) (*Instance, error) { // ... s, err := c.GenericConfig.New(\"kube-apiserver\", delegationTarget) if err != nil { return nil, err } if c.ExtraConfig.EnableLogsSupport { routes.Logs{}.Install(s.Handler.GoRestfulContainer) } // ... m := &amp;Instance{ GenericAPIServer: s, ClusterAuthenticationInfo: c.ExtraConfig.ClusterAuthenticationInfo, } if c.ExtraConfig.APIResourceConfigSource.VersionEnabled(apiv1.SchemeGroupVersion) { legacyRESTStorageProvider := corerest.LegacyRESTStorageProvider{ StorageFactory: c.ExtraConfig.StorageFactory, ProxyTransport: c.ExtraConfig.ProxyTransport, KubeletClientConfig: c.ExtraConfig.KubeletClientConfig, EventTTL: c.ExtraConfig.EventTTL, ServiceIPRange: c.ExtraConfig.ServiceIPRange, SecondaryServiceIPRange: c.ExtraConfig.SecondaryServiceIPRange, ServiceNodePortRange: c.ExtraConfig.ServiceNodePortRange, LoopbackClientConfig: c.GenericConfig.LoopbackClientConfig, ServiceAccountIssuer: c.ExtraConfig.ServiceAccountIssuer, ExtendExpiration: c.ExtraConfig.ExtendExpiration, ServiceAccountMaxExpiration: c.ExtraConfig.ServiceAccountMaxExpiration, APIAudiences: c.GenericConfig.Authentication.APIAudiences, } if err := m.InstallLegacyAPI(&amp;c, c.GenericConfig.RESTOptionsGetter, legacyRESTStorageProvider); err != nil { return nil, err } } restStorageProviders := []RESTStorageProvider{ apiserverinternalrest.StorageProvider{}, authenticationrest.RESTStorageProvider{Authenticator: c.GenericConfig.Authentication.Authenticator, APIAudiences: c.GenericConfig.Authentication.APIAudiences}, authorizationrest.RESTStorageProvider{Authorizer: c.GenericConfig.Authorization.Authorizer, RuleResolver: c.GenericConfig.RuleResolver}, autoscalingrest.RESTStorageProvider{}, batchrest.RESTStorageProvider{}, certificatesrest.RESTStorageProvider{}, coordinationrest.RESTStorageProvider{}, discoveryrest.StorageProvider{}, networkingrest.RESTStorageProvider{}, noderest.RESTStorageProvider{}, policyrest.RESTStorageProvider{}, rbacrest.RESTStorageProvider{Authorizer: c.GenericConfig.Authorization.Authorizer}, schedulingrest.RESTStorageProvider{}, storagerest.RESTStorageProvider{}, flowcontrolrest.RESTStorageProvider{}, appsrest.StorageProvider{}, admissionregistrationrest.RESTStorageProvider{}, eventsrest.RESTStorageProvider{TTL: c.ExtraConfig.EventTTL}, } if err := m.InstallAPIs(c.ExtraConfig.APIResourceConfigSource, c.GenericConfig.RESTOptionsGetter, restStorageProviders...); err != nil { return nil, err } // ... return m, nil}이 method는 먼저 Line:4의 New(\"kube-apiserver\", delegationTarget)에서 APIServerHandlers를 생성한다.여기에는 FullHandlerChain과 Director, 그리고 GoRestfulContainer와 NonGoRestfulMux가 포함된다. GoRestfulContainer 클라이언트에서 pods, deployments, services 등의 리소스들에 접근할 때 사용되는 /apis/*와 같은 API들이 등록되며go-restful design pattern을 준수하는*restful.Container 이다.즉, Container는 HTTP 요청을 다중화하기 위한 WebService collection을보유하며 WebService에는 root path가 지정되며 최종적으로 path와 method가 Route 에 의해 바인딩된다. NonGoRestfulMux chain에서 가장 마지막에 호출되는 HTTP handler이다. mux 객체를 래핑하고 exposedPaths를 기록하는 *mux.PathRecorderMux이며 모든 filter와 API가 처리된 후에 불리게 된다.여기를 통해 다른 서버들이 chain의 다양한 부분에 handler를 추가할 수 있다. Director 해당 path가 GoRestfulContainer에 의해 처리될 수 있는지를 확인하고 호출하며,만약 처리될 수 없는 요청이면 NonGoRestfulMux를 호출해 정상적으로 응답이 될 수 있도록 유도한다.이렇게 동작하는 Director에 의해 실패 및 프록시 케이스를 적절히 처리할 수 있게 된다.apis를 gorestful에 등록하면 /apis 또는 /apis/*가 아닌 모든 요청은 404 응답이 전달되며 다른 모든 것을 포함하는 패턴 등록 시도는 gorestful 제약에 의해 실패하게 된다.이에 mux가 필요한 것이다. Kubernetes에서는 요청이 gorestful에서 처리할 수 없는 path를 포함할 경우 mux로 위임해서 처리하도록 설계했다. FullHandlerChain HTTP 요청에 응답하는 http.Handler이다. 전체 filter chain가 포함된 상태에서 Director를 호출하게 된다.그림 1: HTTP 요청이 전달되었을 때의 호출 순서생성된 APIServerHandler를 통해 /, /debug/*, /metrics/, version을 포함한 여러 path를 GoRestfulContainer와 NonGoRestfulMux에 추가한다.또한 logs 관련 라우팅을 지원하는지 확인 후 /logs path를 추가한다.❯ kubectl get pods -A -v 6GET https://192.168.49.2:8443/api/v1/pods?limit=500 200 OK in 15 milliseconds❯ kubectl get deployments -A -v 6GET https://192.168.49.2:8443/apis/apps/v1/deployments?limit=500 200 OK in 12 milliseconds: pods와 deployments의 URL 확인Kubernetes는 처음 pods와 같은 리소스를 만들 때에는 /api이 root path로 붙도록 설계되었고 이후 추가되는 deployments와 같은 리소스들은 /apis를 root path로 시작하도록 설계하고 있어서이러한 리소스들을 Line:35, Line:60의 InstallLegacyAPI() &amp; InstallAPIs()에서 각각 바인딩해주고 있다.InstallLegacyAPI()와 InstallAPIs()는 RESTStorage 를 얻는 방식의 차이가 조금 있고 내부 동작은 거의 비슷하다.InstallAPIs()를 살펴보자.func (m *Instance) InstallAPIs(apiResourceConfigSource serverstorage.APIResourceConfigSource, restOptionsGetter generic.RESTOptionsGetter, restStorageProviders ...RESTStorageProvider) error { apiGroupsInfo := []*genericapiserver.APIGroupInfo{} // used later in the loop to filter the served resource by those that have expired. resourceExpirationEvaluator, err := genericapiserver.NewResourceExpirationEvaluator(*m.GenericAPIServer.Version) if err != nil { return err } for _, restStorageBuilder := range restStorageProviders { groupName := restStorageBuilder.GroupName() if !apiResourceConfigSource.AnyVersionForGroupEnabled(groupName) { klog.V(1).Infof(\"Skipping disabled API group %q.\", groupName) continue } apiGroupInfo, enabled, err := restStorageBuilder.NewRESTStorage(apiResourceConfigSource, restOptionsGetter) if err != nil { return fmt.Errorf(\"problem initializing API group %q : %v\", groupName, err) } if !enabled { klog.Warningf(\"API group %q is not enabled, skipping.\", groupName) continue } // ... apiGroupsInfo = append(apiGroupsInfo, &amp;apiGroupInfo) } if err := m.GenericAPIServer.InstallAPIGroups(apiGroupsInfo...); err != nil { return fmt.Errorf(\"error in registering group versions: %v\", err) } return nil}restStorageProviders에 포함돼 있는 RESTStorageProviders 를 통해해당 API Group에 대한 APIGroupInfo 를 빌드하고 모아Line:30의 InstallAPIGroups(apiGroupInfo...)를 호출하면서 인자로 전달한다. RESTStorage 특정 리소스나 컬렉션의 정보를 반환하는 동작에 대한 method를 구현할 수 있으며 생성과 변경 및 삭제 전략을 포함하는 인터페이스.API server에 RESTful API로 등록할 리소스들은 이 인터페이스를 구현해야 한다. RESTStorageProviders RESTStorage를 위한 Factory type이다.GroupName() method로 /apis/apps, /apis/cerificates.k8s.io와 같은 형태의 groupName을 가져올 수 있고,NewRESTStorage() method로 해당 API Group 내의 RESTStorage를 포함하고 있는 정보인 APIGroupInfo 가져올 수 있다. APIGroupInfo 해당 API Group에 대한 정보를 포함한다.Group 내의 리소스들에 대한 정보가 들어있는 VersionedResourcesStorageMap을 가지고 있다.Resource HandlerInstallAPIGroups -&gt; installAPIResources -&gt; InstallREST -&gt; registerResourceHandler까지 도달하면서apiGroupInfo에 포함된 RESTStorage를 통해 해당 리소스가 지원하는 작업들을 Action으로 저장하고 리소스 경로(e.g., /api/apiVersion/resource)에서 표준 REST 동사(GET, PUT, POST 및 DELETE)로 처리될 수 있도록 한다.예를 들어 create에 해당하는 Action operation은 POST, update에 해당하는 Action operation은 PUT이다.switch action.Verb {case \"GET\": // Get a resource. var handler restful.RouteFunction if isGetterWithOptions { handler = restfulGetResourceWithOptions(getterWithOptions, reqScope, isSubresource) } else { handler = restfulGetResource(getter, reqScope) } if needOverride { // need change the reported verb handler = metrics.InstrumentRouteFunc(verbOverrider.OverrideMetricsVerb(action.Verb), group, version, resource, subresource, requestScope, metrics.APIServerComponent, deprecated, removedRelease, handler) } else { handler = metrics.InstrumentRouteFunc(action.Verb, group, version, resource, subresource, requestScope, metrics.APIServerComponent, deprecated, removedRelease, handler) } handler = utilwarning.AddWarningsHandler(handler, warnings) doc := \"read the specified \" + kind if isSubresource { doc = \"read \" + subresource + \" of the specified \" + kind } route := ws.GET(action.Path).To(handler). Doc(doc). Param(ws.QueryParameter(\"pretty\", \"If 'true', then the output is pretty printed.\")). Operation(\"read\"+namespaced+kind+strings.Title(subresource)+operationSuffix). Produces(append(storageMeta.ProducesMIMETypes(action.Verb), mediaTypes...)...). Returns(http.StatusOK, \"OK\", producedObject). Writes(producedObject) if isGetterWithOptions { if err := AddObjectParams(ws, route, versionedGetOptions); err != nil { return nil, nil, err } } addParams(route, action.Params) routes = append(routes, route)마지막으로 Action 배열을 차례로 순회하여 각 operation에 handler method를 추가하여 Route에 등록하고, 생성된 Route를 WebService에 등록한다.모든 Route를 등록한 WebService는 최종적으로 GoRestfulContainer에 등록되어 라우팅된다.이 작업은 앞서 언급했던 go-restful design pattern과 완벽하게 일치한다. Container 여기서는 APIServerHandlers에 포함된 GoRestfulContainer를 말한다.HTTP 요청을 디스패치하기 위한 WebService 및 http.ServeMux 컬렉션을 가지고 있다.요청은 RouteSelector 를 사용해 WebServices의 경로에 추가로 디스패치된다. ServeMux HTTP 요청 Multiplexer이다.각 수신 요청의 URL을 등록된 패턴의 목록과 일치시켜 URL과 가장 근접한 패턴에 대한 Handler를 호출한다. RouteSelector HTTP 요청이 주어지면 가장 일치하는 최적의 path를 찾는다.선택적으로 PathProcessor 인터페이스를 구현하여 path가 선택된 후 path parameter도 추출할 수 있다. WebService Route 컬렉션을 가지고 있다. Route HTTP method + URL Path, Comsumers의 조합을 RouteFunction 에 바인딩한다. RouteFunction Route에 바인딩할 수 있는 function의 signature를 선언한다.Execution the final RUN method이렇게 server는 CreateServerChain() method를 통해 생성된다.이제 다시 처음으로 돌아가 NewAPIServerCommand() method 내부에서 실행되는 Run() method를 보자.func Run(completeOptions completedServerRunOptions, stopCh &lt;-chan struct{}) error { // ... server, err := CreateServerChain(completeOptions, stopCh) if err != nil { return err } prepared, err := server.PrepareRun() if err != nil { return err } return prepared.Run(stopCh)}Server를 시작하기 전에 PrepareRun() method에서 /healthz path 등록을 완료하고 Kubernetes API의 모든 세부 정보 및 사양을 포함한 OpenAPI 라우팅 등록 또한 완료한다.이후 preparedGenericAPIServer의 Run() method를 호출해 NonBlockingRun() method를 통해 secure HTTP server를 시작한다.Watch Server CreationWatch Server가 생성되는 과정을 정리하고 마무리해야겠다. registerResourceHandler에서 action.Verb가 “LIST”일 경우를 살펴보자.case \"LIST\": // List all resources of a kind. // ... handler := metrics.InstrumentRouteFunc(action.Verb, group, version, resource, subresource, requestScope, metrics.APIServerComponent, deprecated, removedRelease, restfulListResource(lister, watcher, reqScope, false, a.minRequestTimeout)) handler = utilwarning.AddWarningsHandler(handler, warnings) route := ws.GET(action.Path).To(handler). Doc(doc). Param(ws.QueryParameter(\"pretty\", \"If 'true', then the output is pretty printed.\")). Operation(\"list\"+namespaced+kind+strings.Title(subresource)+operationSuffix). Produces(append(storageMeta.ProducesMIMETypes(action.Verb), allMediaTypes...)...). Returns(http.StatusOK, \"OK\", versionedList). Writes(versionedList) // ... routes = append(routes, route)Handler를 생성할 때 restfulListResource() 함수를 호출하면서 watcher를 넘겨주는 것을 볼 수 있다.이 watcher는 watcher, isWatcher := storage.(rest.Watcher)에서 가져오는 것으로 해당 리소스의 RESTStorage에 이미 등록된 Watcher 구현체이다.RESTStorage는 곧 ETCDStorage이며 ETCDStorage 내부엔 Store가 존재한다.이 Store는 DryRunnableStorage 를 가지고 있으며,DryRunnableStorage 또한 wrapping하기 위한 storage.Interface를 가지고 있는데 여기엔RESTOptions 의Decorator에 등록된 함수가 사용돼UndecoratedStorage 또는Cacher 가 할당되게 된다.watchCache 기능이 필요한 리소스라면 Cacher가 할당되며 storage.(rest.Watcher)를 따라가다보면결국 위의 watcher는 Cacher의 Watch()에서 반환해주는 CacheWatcher가 된다.restfulListResource -&gt; ListResource -&gt; serveWatch 순으로 호출되면서 리소스에 알맞는 watch 응답을 성공적으로 제공할 수 있게 되는 것이다.func serveWatch(watcher watch.Interface, scope *RequestScope, mediaTypeOptions negotiation.MediaTypeOptions, req *http.Request, w http.ResponseWriter, timeout time.Duration) { defer watcher.Stop() // ... server := &amp;WatchServer{ Watching: watcher, Scope: scope, UseTextFraming: useTextFraming, MediaType: mediaType, Framer: framer, Encoder: encoder, EmbeddedEncoder: embeddedEncoder, Fixup: func(obj runtime.Object) runtime.Object { result, err := transformObject(ctx, obj, options, mediaTypeOptions, scope, req) if err != nil { utilruntime.HandleError(fmt.Errorf(\"failed to transform object %v: %v\", reflect.TypeOf(obj), err)) return obj } // When we are transformed to a table, use the table options as the state for whether we // should print headers - on watch, we only want to print table headers on the first object // and omit them on subsequent events. if tableOptions, ok := options.(*metav1.TableOptions); ok { tableOptions.NoHeaders = true } return result }, TimeoutFactory: &amp;realTimeoutFactory{timeout}, } server.ServeHTTP(w, req)}serveWatch()에서 WatchServer는 전달된 watcher를 가지고 생성되며Kubernetes의 Watch event는 어떻게 동작하는가 의 마지막쯔음에 보았던ServeHTTP method가 실행되면서 내부 로직을 통해 일련의 인코딩된 이벤트를 클라이언트에게 제공하게 된다.ConclusionKubernetes API server는 go-restful design pattern을 따르며 특정 리소스의 RESTStorage에 구현된 watcher를 통해 클라이언트에게 watch event에 대한 응답을 제공한다.생략을 나름대로 최대한 했음에도 불구하고 굉장히 정교하고 복잡한 핵심 코어인지라 API server 코드 분석이 매우 길어졌다.부족한 부분들이 아쉽기도 한데 이쯤 정리하는 선에서 일단은 만족하기로 했다.이 포스팅과 관련해 추가적인 수정 사항이나 보충할 내용이 생긴다면 그 때 업데이트할 예정이다.이번 분석을 통해 API server에 요청된 watch event가 어떠한 방식으로 Watch Server에 전달이 되는지 알게 되었다.수많은 클라이언트가 API server와 watch event를 위해 connection을 맺고 있다면 어느 정도 부하가 생길 수도 있다고 다들 이야기를 하고 있으며 공감도 된다.더 효율적인 접근을 위해 Kubernetes에서는 Informer를 제공해주고 있다고 하는데다음으로는 Informer란 어떤 것인지, 그리고 어떠한 아키텍처를 통해 위와 같은 문제를 해결했는지 정리해보자.끝. https://github.com/spf13/cobra &#8617; https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/ &#8617; " }, { "title": "Kubernetes의 Watch event는 어떻게 동작하는가", "url": "/posts/what-is-a-kubernetes-watch-event/", "categories": "kubernetes", "tags": "kubernetes, watch, event", "date": "2021-12-26 16:00:00 +0900", "snippet": "Kubernetes는 pods, deployments, services와 같은 resource들을 모니터링하고 관련 event를 추적할 수 있는 Watch 개념을 가지고 있다.대부분 이미 Kubernetes의 Watch 기능을 사용해봤을 것이다.나는 Deployment 등을 배포하고 Pod의 배포 상태를 계속 보고 싶을 때 Kubectl에 -w 옵션을 추가해 확인하곤 했다.또한 Controller를 구현할 때에도 Watch() Method를 사용하면 결과적으로 channel을 통해 event를 받아올 수 있어 변경 감지에 따른 동작을 정의만 해주면 됐다.Kubernetes에서는 이러한 Watch 기능을 사용하면 API server로부터 데이터를 지속적으로 전달받는다는걸 알겠는데, 정확히 어떠한 방식으로 동작되는지 궁금해졌으므로 차근히 확인하면서 여기에 정리해놓고자 한다.혹 글 내용에 대한 수정이 필요하다면 계속해서 업데이트할 예정이다.Prerequisites kubectl minikube and minikube startWatch pods via kubectl최근 감명 깊게 읽은 책인 Programming Kubernetes에서는 Watch event를 아래와 같이 설명하고 있다. Watch events are sent through streaming HTTP connections between the API server and controllers to drive informers.API server는 클라이언트인 Controller와 streaming HTTP connection을 통해 데이터를 주고 받는 형태라는 말인데,이는 또 다른 클라이언트인 Kubectl과도 같은 방식으로 데이터를 주고 받을거라 이해할 수 있을 듯 하다.빠른 확인을 위해 먼저 Kubectl의 Watch 기능을 사용해보도록 하자.익히 알고 있는 바와 같이 한 줄의 Kubectl command로 cluster 상에 있는 (default namespace의) Pod들을 감시할 수 있게 된다.❯ kubectl get pods --watch새로운 shell을 열어 nginx pod 하나를 배포한다.❯ kubectl run nginx --image=nginxpod/nginx created이제 다시 watch를 걸어뒀던 shell로 돌아가면 nginx pod의 상태(status)가 변하는 과정을 관찰할 수 있다.NAME READY STATUS RESTARTS AGEnginx 0/1 Pending 0 0snginx 0/1 Pending 0 0snginx 0/1 ContainerCreating 0 0snginx 1/1 Running 0 14s어떻게 받아오는 것인지 궁금하기에 조금 더 깊게 들여다 봐야겠다. 로그 수준1을 최대로 높여서 watch command를 걸어둔 상태로 nginx-2 pod를 추가 배포하면 아래와 같은 로그를 만나게 된다.❯ kubectl get pods --watch -v 9...GET https://127.0.0.1:57226/api/v1/namespaces/default/pods?limit=500...Response Body: {\"kind\":\"Table\",\"apiVersion\":\"meta.k8s.io/v1\",\"metadata\":{\"resourceVersion\":\"818\"}, ......NAME READY STATUS RESTARTS AGEnginx 1/1 Running 0 4m43s...GET https://127.0.0.1:57226/api/v1/namespaces/default/pods?resourceVersion=818&amp;watch=true...# kubectl run nginx-2 --image=nginxnginx-2 0/1 Pending 0 0snginx-2 0/1 Pending 0 0snginx-2 0/1 ContainerCreating 0 0snginx-2 1/1 Running 0 5s로그 중 주의 깊게 봐야될 것 같은 부분을 추려봤다. 결국 Kubectl의 watch command는 이렇게 동작하는걸로 보인다. Kubectl은 Kuberntes API server로 (Default Namespace의) Pod의 List를 요청한다. (여기서는 max 500으로 설정됨) Pod List에 대한 응답을 받고 다시 GET 요청을 한다. 이 때, 응답의 Boby에 있었던 resourceVersion과 함께 watch도 쿼리 파라미터로 같이 보낸다.Kubectl이 보여주는 로그를 통해 HTTP GET 요청에 ?watch 쿼리 파라미터를 추가해 보내게 되면Kubernetes는 이를 get 동작이 아닌 watch 동작으로 받아들이게 된다는 걸 어림잡아 알게 됐다.이는 Reflector가 구현해둔 ListAndWatch Method의 동작과 정확히 일치하는 흐름이다.왜 2번의 GET 요청을 하도록 구현되었을까? 그리고 resourceVersion은 무엇일까?List and WatchKubernetes에서는 효율적인 변경 추적을 위해, 모든 object에 존재하는 resourceVersion field를 사용한다고 한다.etcd와 같은 persistence layer에 영속화되는 순간에 대한 상태를 식별할 수 있는 일종의 지문으로,상태가 변경될 때마다 resourceVersion도 같이 변경된다.   Pod List nginx Pod nginx-2 Pod kubectl run nginx … 1920 628 - kubectl run nginx-2 … 2137 628 1939 kubectl edit nginx … 6861 6855 1939 : 상태 변경에 따른 resourceVersion 변화Kubectl과 같은 클라이언트들은 object 또는 collection에 대한 초기 요청(get 또는 list)의 응답으로 받은 resourceVersion을 사용하여 감시 요청(watch)을 하게 되면,이후에 발생되는 Create, Update, Delete event와 같은 후속 변경 사항을 구독할 수 있다.이러한 내용들 때문에 2번의 요청이 요구되는 것이다.resourceVersion을 얻기 위해 첫번째 GET 요청을 하며, 해당 요청에 포함된 resourceVersion과 함께 두번째 GET 요청을 하면서 resource에 대한 정확한 구독 시점이 결정되는 것이다.watch 요청 시 전달되는 resourceVersion에 따라 변경 감지의 시작점이 달라지게 되는데Semantics for watch 에서 보다 자세한 내용을 확인할 수 있다. resourceVersion unset resourceVersion=”0” resourceVersion=”{value other than 0}” Get State and Start at Most Recent Get State and Start at Any Start at Exact 이제는 watch event의 동작에 대해서 어느정도 알긴 하겠다. 여기에 추가로, 어떤 방식으로 Kubernetes가 event를 주고 클라이언트가 받을 수 있게 되는지 구현에 대한 정리가 되면 더 명확해질 것으로 보인다.Client-side Implementation클라이언트의 구현을 따라가보자. Kubectl의 watch 구현에서,watch 요청이 오면 최종적으로 request.go에서 생성하는 watch.go의 watch.Interface에서 channel을 꺼내 event가 도착할 때마다 출력한다.커스텀한 Controller 또는 Webhook을 구현할 경우 resource에 대한 변경 감지가 필요한 상황(e.g., Pod 생성 요청을 하고 생성이 완료될 때까지 대기)이면 clientSet의 client를 통해 원하는 resource에 대해 Watch verb를 요청해 원하는 로직을 구현할 수도 있는데2,이 때 얻게 되는 watch.Interface 역시 같은 방식으로 만들어지는 객체이다.watch, err := client.CoreV1().Pods(namespace).Watch(context.TODO(), options)// ...for event := range watch.ResultChan() { pod, ok := event.Object.(*corev1.Pod) // ... switch event.Type { case watch.Added, watch.Modified, watch.Deleted, watch.Bookmark: // ... case watch.Error: // ... }}간단하게는 이러한 방식으로 client 객체를 통해 변경 감지가 필요한 resource의 watch.Interface를 받을 수 있다.watch.ResultChan()으로 event를 전달받을 수 있으며 Type에 따라 필요한 로직을 작성하면 된다.클라이언트 Watcher를 위한 코드는 내부적으로 이런 형태로 구현돼 있다.func (r *Request) Watch(ctx context.Context) (watch.Interface, error) { // ... var retryAfter *RetryAfter url := r.URL().String() for { req, err := r.newHTTPRequest(ctx) if err != nil { return nil, err } // ... resp, err := client.Do(req) // ... if err == nil &amp;&amp; resp.StatusCode == http.StatusOK { return r.newStreamWatcher(resp) } // ... }}watch.Interface의 prototype들을 구현한 구현체 중 하나인 StreamWatcher를 반환하는 Watch(context.Context) Method다.Golang을 공부하며 그동안 예제로 보아왔던 HTTP streaming 클라이언트측 코드 구현과 매우 흡사한걸 확인할 수 있다.streaming을 위한 http.request 객체를 만들고 요청을 보낸 후 응답을 받아 데이터를 지속적으로 수신받을 Decoder를 생성한다.StreamWatcher 내부에 Decoder가 존재하며 아래와 같이 구성된다.func NewStreamWatcher(d Decoder, r Reporter) *StreamWatcher { sw := &amp;StreamWatcher{ source: d, reporter: r, result: make(chan Event), done: make(chan struct{}), } go sw.receive() return sw}Goroutine으로 실행되는 sw.receive()에서 Decoder로부터 Type과 Object를 얻고 result channel로 전송한다.이러한 result channel은 ResultChan() Method를 통해 가져올 수 있으므로, 변경 감지가 필요한 클라이언트는 이를 사용해 channel로부터 Event 를 수신할 수 있게 되는 것이다.Server-side Implementation그렇다면 서버측은 어떻게 구현되어 있을까? 코드를 샅샅히 뒤져보면 WatchServer 구조체가 존재하며 ServeHTTP Method로 watch 응답을 제공한다는 것을 확인할 수 있다.func (s *WatchServer) ServeHTTP(w http.ResponseWriter, req *http.Request) { // ... if wsstream.IsWebSocketRequest(req) { w.Header().Set(\"Content-Type\", s.MediaType) websocket.Handler(s.HandleWS).ServeHTTP(w, req) return } // ... e := streaming.NewEncoder(framer, s.Encoder) // ... w.Header().Set(\"Content-Type\", s.MediaType) w.Header().Set(\"Transfer-Encoding\", \"chunked\") w.WriteHeader(http.StatusOK) flusher.Flush() // ... ch := s.Watching.ResultChan() done := req.Context().Done() for { select { // ... case event, ok := &lt;-ch: // ... if err := e.Encode(outEvent); err != nil { utilruntime.HandleError(fmt.Errorf(\"unable to encode watch object %T: %v (%#v)\", outEvent, err, e)) return } // ... } }}우선 요청에서 Connection과 Upgrade 헤더를 봐서 WebSocket 연결 요청인지 확인한다.맞다면 WebSocket connection을 통해, 아니라면 응답의 Transfer-Encoding 헤더를 chunked로 설정하여 streaming HTTP connection을 통해서 일련의 인코딩된 event를 클라이언트에게 제공한다.코드를 보면 WatchServer 또한 특정 channel로부터 event를 수신해서 최종적으로 클라이언트에게 송신하는 중간 전달자임을 확인할 수 있다.ch := s.Watching.ResultChan()음.. Watching 객체도 watch.Interface로 WatchServer가 생성될 때 외부에서 주입받아 사용이 되는데 이건 또 어디에서 오는걸까?이 부분은 다음에 Kubernetes의 Event에 대해 면밀히 정리를 해보면서 추가로 확인해보도록 하자.Watch event flow개략적인 Watch event의 흐름은 그림 1과 같다.그림 1. Watch event flowclient-go의 clientSet을 통해 Watch() Method를 호출해도 그림 상의 Request.Watch에 도달하는 것은 동일하다.ConclusionKubernetes에서의 Watch event는 어떤 방식으로 구현돼 있는지 어떻게 동작하는지 어느정도 정리해보았다.예상했던 바와 같이 클라이언트와 API server는 Go-based HTTP streaming via HTTP &amp; websocket으로 resource에 대한 add/update/delete 타입의 event를 전달하고 받고 있었다.예를 들어 Pod가 생성되거나 변경되거나 삭제가 되면 일련의 event가 발생되어 전달을 받고 해당 event에 대한 부가적인 처리를 할 수 있다는 아주 기본적이면서 당연한 말이긴 하다.내부적으로 event를 어떤 방식으로 처리하게 했는지에 대해 알면 Kubernetes와 더 가까워질 수 있을 것이다. 다음 순으로 API Server에서 Watch 요청이 어떻게 핸들링되는지, Watch Server가 생성되기까지의 과정을 확인해보자.끝. kubectl은 -v 또는 –v 플래그를 통해 로그 수준을 지정할 수 있도록 지원하고 있다. kubectl-output-verbosity-and-debugging 에서 자세히 확인할 수 있다. &#8617; Watch보다는 Informer 사용이 권장된다. 이유는 추후에 알아보도록 하자. &#8617; " } ]
