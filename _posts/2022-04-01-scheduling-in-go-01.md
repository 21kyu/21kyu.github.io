---
title: Scheduling In Go I - OS Scheduler
author: wq
name: Wongyu Lee
link: https://github.com/kyu21
date: 2022-04-01 23:00:00 +0900
categories: [go]
tags: [go, scheduler, os]
render_with_liquid: false
---

> [Scheduling In Go : Part I - OS Scheduler](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html)
를 옮긴 글

## Prelude

Go의 스케줄러 내부가 돌아가는 메커니즘(mechanics)과 의미론(semantics)에 대한 이해를 제공할 3부작 시리즈의 첫번째 게시물이다.
첫번째 게시물은 운영체제 스케줄러에 중점을 둔다.

**3부작**:
1. [Scheduling In Go : Part I - OS Scheduler](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html)
2. [Scheduling In Go : Part II - Go Scheduler](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html)
3. [Scheduling In Go : Part III - Concurrency](https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html)

## Introduction

Go 스케줄러에 적용된 설계와 동작은 멀티스레드 기반 Go 프로그램이 더육 효율적면서 좋은 성능을 발휘할 수 있게 한다.
이는 운영체제(OS) 스케줄러에 대한 Go 스케줄러의 mechanical sympathy[^1] 덕분이며,
멀티스레드 애플리케이션을 바르게 설계하기 위해서는 운영체제와 Go 스케줄러가 작동하는 방식에 대한 범용적이고 핵심적인 이해를 갖는 것이 중요하다.

앞으로의 게시글에서는 스케줄러에 대한 높은 수준의 메커니즘과 의미론에 초점을 맞추고자 한다.
더 나은 엔지니어링 결정을 하기 위해 이러한 것들의 작동 방식에 대한 시각화가 가능하도록 충분한 설명을 제공할 것이다.
멀티스레드 애플리케이션 개발에 있어서 엔지니어가 선택해야하는 엔지니어링 결정에는 많은 것들이 있지만,
당연하게도 메커니즘과 의미론은 이러한 결정에 필요한 기본 지식의 중요한 부분을 형성해 줄 것이다.

## OS Scheduler

운영체제 스케줄러는 복잡한 소프트웨어 조각이다.
스케줄러는 그들이 실행하는 하드웨어의 레이아웃(layout)과 설정(setup)을 고려해야하며
고려해야할 사항에는 멀티프로세서와 코어, [CPU 캐시 그리고 NUMA](https://frankdenneman.nl/2016/07/06/introduction-2016-numa-deep-dive-series/)
가 포함되지만 딱히 이에 국한되진 않는다.
이런 지식이 없는 상태에서의 스케줄러 동작에 대한 이해는 효율적일 수 없을 것이다.
다행스러운 점이라면 앞서 말한 토픽들에 대해 깊이 들어가지 않고도 운영체제 스케줄러가 작동하는 방식에 대한 훌륭한 Mental model[^2]을 깨닳을 수 있다.

프로그램은 순차적으로 실행되어야하는 일련의 기계 명령어이며 이를 위해 운영체제는 스레드라는 개념를 사용한다.
할당된 명령어 집합에 대한 책임을 지고 순차적으로 실행하는 것은 스레드가 해야할 일이다.
스레드는 더이상 실행할 명령어가 없을 때까지 실행은 계속되며, 이러한 특성때문에 스레드를 "실행 경로"라고 부르기도 한다.

실행되는 모든 프로그램은 프로세스를 생성하며 각 프로세스에는 초기 스레드가 제공되고, 각 스레드는 더 많은 스레드를 생성할 수 있다.

이러한 스레드들은 서로 독립적으로 실행되며 스케줄링 결정은 프로세스 수준이 아닌 스레드 수준에서 이루어진다.
스레드들은 동시(동일 코어에서 빠르게 순차적으로 실행)에 또는 병렬(같은 시간에 다른 코어에서 실행)로 실행될 수 있다.
스레드는 자신의 명령어를 안전하고 지역적이며 독립적으로 실행할 수 있도록 자체 상태를 유지한다.

운영체제 스케줄러는 실행되어야할 스레드가 있는 경우 코어가 유휴 상태가 아닌지 확인하며
또한 실행할 수 있는 모든 스레드가 동시에 실행되고 있다는 착각을 만들어야 한다.
이 착각 속에서 스케줄러는 우선 순위가 낮은 스레드보다 높은 우선 순위의 스레드를 실행해야 한다.
하지만 우선 순위가 낮은 스레드의 실행 시간이 부족하면 안되기 때문에 스케줄러는 빠르고 현명한 결정을 통해 스케줄링 지연을 가능한 한 최소화해야 한다.

이것을 가능케 하기 위해 매우 많은 알고리즘이 사용되고 있지만, 운이 좋게도 이해를 도와줄 수십년의 작업과 경험이 존재해왔다.
이 모든 것들을 더 잘 이해하기 위해 중요한 몇가지 개념을 설명하고 정의하는 것이 좋겠다.

## Executing Instructions

명령어 포인터 (IP)라고도 하는 프로그램 카운터[^3] (PC)는 스레드가 실행할 다음 명령어를 추적할 수 있도록 한다.
대부분의 프로세서에서 PC는 현재 명령어가 아닌 다음 명령어를 가리킨다는 것을 명심하자.

![instruction-pointer](/images/instruction-pointer.jpeg)
_그림 1_

[https://www.slideshare.net/JohnCutajar/assembly-language-8086-intermediate](https://www.slideshare.net/JohnCutajar/assembly-language-8086-intermediate)

Go 프로그램에서 스택 추적을 본 적이 있다면, 각 라인의 끝에 있는 작은 16진수 숫자를 봤을 것이다.
아래에서 `+0x39` 와 `+0x72` 를 확인해보자.

```shell
goroutine 1 [running]:
   main.example(0xc000042748, 0x2, 0x4, 0x106abae, 0x5, 0xa)
       stack_trace/example1/example1.go:13 +0x39
   main.main()
       stack_trace/example1/example1.go:8 +0x72
```
{: .nolineno}

해당 숫자들은 각 함수 상단으로부터의 PC 값 오프셋을 나타낸다.
`+0x39` PC 오프셋은 프로그램이 패닉에 빠지지 않았다면 스레드가 `example` 함수 내부에서 실행했을 다음 명령어를 나타내고
`+0x72` PC 오프셋은 제어가 `main` 함수로 되돌아간 경우의 내부의 다음 명령어이다.
더 중요한 것은 그 포인터 이전에 어떤 명령어가 실행되고 있었는지 알려준다는 것이다.

위의 스택 추적을 만들어낸 프로그램은 아래와 생겼다.

```go
// https://github.com/ardanlabs/gotraining/blob/master/topics/go/profiling/stack_trace/example1/example1.go

07 func main() {
08     example(make([]string, 2, 4), "hello", 10)
09 }

12 func example(slice []string, str string, i int) {
13    panic("Want stack trace")
14 }
```
{: .nolineno}

16진수 `+0x39` 는 함수의 시작 명령어보다 57 (10진수) 바이트 아래에 있는 `example` 함수 내부의 명령어를 위한 PC 오프셋이다.
아래에서처럼 바이너리로부터 `example` 함수의 `objdump`를 볼 수 있다.
아래 나열된 12번째 명령어의 위 코드 행은 패닉에 대한 호출이다.

```shell
$ go tool objdump -S -s "main.example" ./example1
TEXT main.example(SB) stack_trace/example1/example1.go
func example(slice []string, str string, i int) {
  0x104dfa0		65488b0c2530000000	MOVQ GS:0x30, CX
  0x104dfa9		483b6110		CMPQ 0x10(CX), SP
  0x104dfad		762c			JBE 0x104dfdb
  0x104dfaf		4883ec18		SUBQ $0x18, SP
  0x104dfb3		48896c2410		MOVQ BP, 0x10(SP)
  0x104dfb8		488d6c2410		LEAQ 0x10(SP), BP
	panic("Want stack trace")
  0x104dfbd		488d059ca20000	LEAQ runtime.types+41504(SB), AX
  0x104dfc4		48890424		MOVQ AX, 0(SP)
  0x104dfc8		488d05a1870200	LEAQ main.statictmp_0(SB), AX
  0x104dfcf		4889442408		MOVQ AX, 0x8(SP)
  0x104dfd4		e8c735fdff		CALL runtime.gopanic(SB)
  0x104dfd9		0f0b			UD2              <--- LOOK HERE PC(+0x39)
```
{: .nolineno}

앞서 말했듯 PC는 현재 명령어가 아니라 다음 명령어이다.
우리는 위의 예제를 통해 Go 프로그램의 스레드가 순차적으로 실행을 담당하는 amd64 기반 명령어의 좋은 예를 보았다.

## Thread States

또 다른 중요한 개념은 스케줄러가 스레드와 함께 수행할 역할을 지시하는 스레드 상태이다.
스레드는 3가지 상태 중 하나가 될 수 있다.

Waiting
: 스레드가 중지됐으며 작업을 계속하기 위해 무언가를 기다리고 있음을 의미한다.
하드웨어(disk, network), 운영체제(system call) 또는 동기화 이벤트(atomic, mutex)를 기다리는 것과 같은 이유 때문일 수 있다.
이러한 유형의 지연[^4]은 성능 저하의 근본적인 원인이 된다.

Runnable
: 스레드가 할당된 기계 명령어를 실행할 수 있도록 코어에 배치되기를 원한다는 것을 의미한다.
작업 시간을 원하는 스레드가 많으면 많을수록 스레드는 시간을 확보하기 위해 더 오래 기다려야 한다.
또한 더 많은 스레드가 시간을 두고 경쟁함에 따라 각 스레드가 얻는 개별적인 작업 시간이 단축된다.
이 유형의 스케줄링 지연 또한 성능 저하의 원인이 될 수 있다.

Executing
: 스레드가 코어에 배치되어 기계 명령어를 실행하고 있음을 의미한다.
애플리케이션과 연관된 작업이 완료된다.

## Types Of Work

스레드가 할 수 있는 작업엔 두 가지의 유형이 있다.

CPU-Bound
: 스레드가 Waiting 상태에 놓일 수 있는 상황을 만들지 않는 작업니다.
끊임없이 계산을 하는 작업이며 예를 들어 Pi를 N번째 자리까지 계산하는 스레드는 CPU 바운드 유형이다.

IO-Bound
: 스레드가 Waiting 상태에 진입하도록 만드는 작업이다.
네트워크를 통해 리소스에 대한 접근을 요청하거나 운영체제에 시스템 호출을 하는 작업이다.
데이터베이스에 접근해야하는 스레드도 IO 바운드 유형이다.
스레드가 이 범주의 일부로 대기하도록 하는 동기화 이벤트(atomic, mutex)를 포함한다.

## Context Switching

Linux, Mac 또는 Windows에는 선점형 스케줄러가 존재한다.
이는 중요한 것들을 의미하는데, 첫번째로 스케줄러는 주어진 시간에 어떤 스레드가 실행되도록 선택되는지에 관해서 예측할 수 없음을 의미한다.
네트워크에서의 데이터 수신과 같은 이벤트와 함께하는 스레드 우선 순위는 스케줄러가 언제 무엇을 할 지 결정하는 것을 불가능하게 만든다.

두번째로, 항상 동일하게 발생될 것이라고 보장할 수 없는 운 좋게 경험했던 일부 인지된 동작을 기반으로 코드를 작성하면 안된다는 것을 의미한다.
같은 동작이 동일한 방식으로 1000번 발생하는 것을 보았다면 이것은 보장된 동작이라고 생각할 수 있다.
애플리케이션에서 결정성이 필요한 경우에는 스레드의 동기화(synchronization) 및 조정, 조율(orchestration)을 잘 제어해야만 한다.

하나의 코어에서 스레드를 교환하는 물리적 동작을 컨텍스트 스위치라고 한다.
컨텍스트 스위치는 스케줄러가 코어에 배치된 Executing 스레드를 내리고 그 자리에 Runnable 스레드를 배치할 때 발생된다.
실행 큐(run queue)에서 선택된 스레드는 Executing 상태로 변경된다.
코어에서 내려온 스레드는 다시 Runnable 상태(여전히 실행할 수 있는 경우) 혹은 Waiting 상태(IO 바운드 유형의 요청으로 인해 교체된 경우)가 된다.

컨텍스트 스위치는 코어에서 스레드를 배치하고 내리는데 시간이 걸리기 때문에 비용이 많이 드는 것으로 간주된다.
컨텍스트 스위치가 발생하는 동안의 지연 시간은 다양한 요인에 따라 달라지지만 _~1,000, ~1,500 나노초가 소요_[^5]된다고 볼 수 있다.
하드웨어가 각 코어 당, 1 나노초에 평균적으로 12개의 명령어를 실행할 수 있어야 한다는 점을 고려해보면,
컨텍스트 스위치에는 ~12k에서 ~18k개의 명령어에 해당하는 지연 시간이 발생할 수 있는 것이다.
본질적으로 프로그램은 컨텍스트 스위치를 하는 동안 많은 수의 명령어를 실행하는 기회를 상실하게 된다.

IO 바운드 작업에 초점을 맞춘 프로그램에서의 컨텍스트 스위치는 이점이 있다.
코어를 점유 중인 스레드가 Waiting 상태가 될 때, Runnable 상태의 다른 스레드가 그 자리를 차지하게 된다.
이를 통해 코어가 항상 작업을 수행할 수 있게 되는데 이것은 스케줄링의 가장 중요한 측면 중 하나로, 스케줄러는 수행할 작업(Runnable 상태의 스레드)이 있는 경우 코어가 유휴 상태가 되는 것을 허용해선 안된다.

## Less Is More

프로세서가 단지 하나의 코어만을 가졌던 초기에는 스케줄링이 그닥 복잡하지 않았다.
단일 코어가 있는 단일 프로세서이기 때문에 주어진 시간에 하나의 스레드만을 실행할 수 있었다.
스케줄러 기간[^6]을 정의하고 해당 기간 내에 모든 Runnable 상태의 스레드를 실행하는 것을 시도하는 것이 아이디어였고,
정의된 스케줄러 기간을 실행되어야 하는 스레드의 수로 나누면 되기에 이것은 전혀 문제가 없었다.

예를 들어 스케줄러 기간이 1,000ms(1초)이고 10개의 스레드가 존재한다면, 각 스레드는 각각 100ms의 실행 시간을 가진다.
만약 100개의 스레드가 있다면, 각 스레드는 각각 10ms의 실행 시간을 얻게 될 것이다.
그러나 100개의 스레드가 있다면? 각 스레드에 1ms의 작은 시간 조각을 제공하는 것은 컨텍스트 스위칭에서 소비되는 시간은 애플리케이션 작업이 소비할 시간의 양과 관련이 있기 때문에 제대로 작동할 수 없다.

주어진 시간 조각이 얼마나 작을 수 있는지에 대한 제한을 설정하는 것이 필요하다.
마지막 시나리오에서, 최소 시간 조각 제한이 10ms인 상태에서 1,000개의 스레드가 있다면 스케줄러 기간은 10,000ms(10초)로 늘려야 한다.
10,000개의 스레드가 있는 경우엔 100,000ms(100초)의 스케줄러 기간을 보게 된다.
10,000개의 스레드가 10ms의 최소 시간 조각으로 각 스레드가 전체 시간 조각을 사용하는 경우,
이 간단한 예제에서 모든 스레드가 한 번씩만 실행되는데 100초가 걸린다.

이것은 세상을 보는 아주 단순한 관점이라는 것을 알아두자.
스케줄링에 대한 결정을 내릴 때에 스케줄러가 고려하고 처리해야할 많은 사항들이 있다.
애플리케이션에서는 자신이 사용하는 스레드 수를 제어할 수 있다.
고려해야 할 스레드가 더 많고 IO 바운드 작업이 발생하면 더 많은 혼돈과 비결정적 동작이 발생한다.
스케줄링을 하고 실행하는데 더 많은 시간을 필요로하게 된다.

이것이 게임의 규칙이 "Less is More"인 이유이다.
Runnable 상태의 스레드가 적다는건 스케줄링에 대한 오버헤드가 적고 시간이 지남에 따라 각 스레드엔 더 많은 시간이 할당된다는 것을 의미한다.
Runnable 상태의 스레드가 많을수록 시간이 지남에 따라 각 스레드가 얻는 시간도 줄어든다.
즉, 시간이 지남에 따라 한 스레드가 수행할 수 있는 작업도 줄어들게 된다는 것이다.

## Find The Balance

보유하고 있는 코어의 수와 애플리케이션에 대한 최상의 처리량을 얻는데 필요한 스레드의 수 간에 균형을 찾아야 한다.
이러한 균형을 관리하는 것과 관련해 스레드 풀은 좋은 답변이 된다.
Go에서는 이것이 더 이상 필요하지 않다는 것은 다음 게시글에서 보여줄건데,
개인적으로 이를 통해 Go에서 멀티스레드 애플리케이션 개발이 쉬워졌다고 생각한다.

나는 Go로 코딩하기 전에 NT에서 C와 C#으로 코드를 작성했다.
해당 운영체제에서 멀티스레드 소프트웨어를 만들 때 IOCP(IO Completion Ports) 스레드 풀을 사용해야만 했고,
엔지니어는 주어진 코어 수에 대한 처리량을 최대화하기 위해 필요한 스레드 풀의 수와 주어진 풀에 대한 최대 스레드 수를 파악해야 했다.

데이터베이스와 통신하는 웹 서비스를 작성할 때 코어당 3개의 스레드라는 마법같은 숫자는 항상 NT에서 최고의 처리량을 제공하는 것처럼 보였다.
즉, 코아당 3개의 스레드는 컨텍스트 스위치의 대기 시간 비용을 최소화하면서 코어의 실행 시간을 최대화해주었다.
IOCP 스레드 풀을 생성할 때 호스트 시스템에서 식별한 모든 코어에 대해 최소 1개의 스레드와 최대 3개의 스레드로 시작해야 하는 것으로 알고 있었다.

코어당 2개의 스레드를 사용하면 작업을 완료할 수 있는 유휴 시간이 있었기 때문에 모든 작업을 완료하는데 시간이 더 오래 걸렸다.
코어당 4개의 스레드를 사용한 경우 컨텍스트 스위치에서 더 많은 대기 시간을 필요로 했기 때문에 더 오랜 시간이 걸렸다.
어떠한 이유로든 코어당 3개의 스레드 사용은 항상 NT에서 마법의 숫자처럼 느껴진 것이다.

당신의 서비스가 다양한 종류의 작업을 수행하는 경우에는 어떻게 할 것인가?
이는 서로 다르며 일관성이 없는 지연 시간을 생성할 수 있으며, 또한 처리해야 하는 다양한 시스템 수준의 이벤트를 생성할 수도 있다.
서로 다른 모든 워크로드에 대해 항상 최상으로 작동하는 마법의 숫자를 찾는 것은 불가능에 가까울 수 있다.
스레드 풀을 사용하여 서비스 성능을 조정하는 경우 바르게 일관된 구성을 찾는 것이 매우 복잡해질 수 있다.

## Cache Lines

주 메모리의 데이터에 접근하는 것은 프로세서와 코어가 해당 데이터를 필요로 하는 하드웨어 스레드에 보다 가깝게 유지하기 위해 별도의 로컬 캐시를 갖기 때문에
지연 시간 비용이 매우 높다(~100 to ~300 clock cycles).
캐시의 데이터에 접근하는 것은 액세스되는 캐시에 따라 훨씬 저렴한 비용(~3 to ~40 clock cycles)을 갖는다.
오늘날 성능의 한 측면은 이러한 데이터 액세스 지연 시간을 줄이기 위해 데이터를 프록세서에 얼마나 효율적으로 가져올 수 있는지에 관한 것이다.
상태를 변경하는 멀티스레드 애플리케이션을 작성하려면 캐싱 시스템의 매커니즘을 충분히 고려해야 한다.

![Core i7-9xx Cache Hierarchy](/images/core-i7-9xx-cache-hierarchy.png)
_그림 2_

데이터는 캐시 라인[^7]을 통해 프로세서와 주 메모리 간 교환이 이루어진다.
캐시 라인은 주 메모리와 캐싱 시스템 간에 교환되는 64 바이트 크기의 메모리 청크이다.
각 코어에는 필요한 캐시 라인의 자체 복사본이 제공되며, 이는 하드웨어가 value semantics[^8]를 사용함을 의미한다.
멀티스레드 애플리케이션에서 메모리에 대한 변경 사항은 성능에 악영향을 끼칠 수 있는 직격탄이다.

병렬로 실행되는 여러 스레드가 동일한 데이터 또는 서로 가까운 데이터에 접근하려 할 때 동일한 캐시 라인의 데이터에 도달하게 된다.
모든 코어에서 실행되는 모든 스레드는 동일한 캐시 라인의 자체 복사본을 얻는다.

![False Sharing](/images/false-sharing.png)
_그림 3_

주어진 코어의 한 스레드가 캐시 라인의 복사본을 변경하게 되면 하드웨어의 마법을 통해 동일한 캐시 라인의 다른 모든 복사본이 `dirty`로 표시되어야 한다.
스레드가 dirty 캐시 라인에 대한 읽기 또는 쓰기 접근을 시도하면 캐시 라인의 새 복사본을 얻기 위해 주 메모리 접근이 필요하게 된다.

2개의 코어를 가진 프로세서에서는 이것이 큰 문제가 아닐 수 있지만,
32개의 스레드를 병렬로 실행하는 32 코어 프로세서는 모두 동일한 캐시 라인에서 동일한 데이터에 액세스하고 데이터를 변경하게 될 것이다.
각각 16개의 코어가 있는 2개의 물리적 프로세서로 돌아가는 시스템은 어떨까?
프로세서 간 통신에 지연 시간이 발생되기 때문에 이는 더 나빠질 것이다.
애플리케이션은 프로세서와 주 메모리 간의 반복되는 캐시 라인 적재로 인해 스래싱 될 것이고 성능은 끔찍할 것이며 대부분은 그 이유조차 이해하지 못할 것이다.

이를 캐시 일관성 문제[^9]라고 하며 잘못된 공유와 같은 문제도 발생된다.
공유 상태를 변경하는 멀티스레드 애플리케이션을 작성할 때에는 캐싱 시스템도 충분히 고려해야만 한다.

> wq: 음.. 여기서부터 헷갈리기 시작했다. 캐시 라인에 대한 이해가 부족한 상태에서 보자니 쉽지 않았다. 추가로 정리해놓고자 한다.
{: .prompt-info }

캐시 라인은 아래와 같은 흐름으로 동작한다:
* 캐시 라인이란 CPU가 주 메모리로부터 데이터를 가져올 때 바이트 단위로 가져오지 않고 캐시 라인을 가득 채울만큼의 데이터를 가져오는 것을 말한다.
* 캐시 라인은 CPU에 따라 32, 64, 128 바이트의 크기로 구성되며 캐시 메모리에 정렬돼 저장된다.

1. 일반적인 캐시 라인 동작:
   1. CPU에서 1000번째 메모리를 읽으려고 한다.
   2. 주 메모리에 있는 데이터를 캐시 라인의 크기(여기서는 64 바이트로 가정)만큼 가져오므로 1000번에서 1064번 메모리의 데이터를 캐시 메모리에 채우게 된다.
   3. 이후 1000번에서 1064번 메모리에 접근 시 캐시 메모리에서 접근이 가능해진다.
2. 멀티 프로세서 환경에서의 캐시 라인:
   1. CPU A가 1000번째 메모리에 접근한다. 이 때 캐시 라인의 크기만큼 CPU A의 캐시 메모리에 적재된다. (1000번 ~ 1064번)
   2. CPU B도 1000번째 메모리에 접근한다. 마찬가지로 캐시 라인의 크기만큼 CPU B의 캐시 메모리에 적대된다.
   3. CPU A가 1000번째 메모리의 데이터를 변경한다.
   4. 3.의 작업으로 인해 다른 CPU에 있던 동일한 캐시 라인을 무효화시키게 되므로 CPU B에 적재되어 있던 1000번 ~ 1064번 캐시 라인이 무효화된다.
   5. 이후 CPU B는 1000번째 메모리의 데이터에 접근하고자 한다면 다시 캐시 라인을 적재해야 한다.

여기에서 캐시 라인을 무효화 또는 동기화하는 작업이 바로 위에서 언급된 `dirty`이다. 이러한 동작때문에 `False Sharing`이 발생된다.

한 애플리케이션에서 사용되는 두 개의 변수 n1, n2가 있고
애플리케이션 내부에선 2개의 스레드 t1, t2를 통해 각각 n1과 n2를 다루는 어떠한 연산을 진행한다고 가정해보자.
(n1과 n2는 주 메모리에 물리적으로 가까이에 순차적으로 있을 것이다.)

이러한 상황에서 t1의 코어 1에 배치되고 t2는 코어 2에 배치된다고 한다면,
코어 1의 캐시 라인은 n1부터 64 바이트를 읽어서 적재하게 되고 코어 2의 캐시 라인은 n2부터 64 바이트를 읽어서 적재하게 될 것이다.
특히 코어 1의 캐시 라인은 n1부터 가져왔지만 64 바이트를 통째로 읽어서 적재했으므로 n2 데이터도 같이 있을 확률이 높다.

연산이 시작됐을 때, 코어 2는 별다른 문제없이 연산하게 된다.
하지만 코어 1은 약간의 문제가 생길 수 있다.
CPU는 단지 계산만 처리하는 기계이며 캐시 일관성(cache coherence) 매커니즘으로 돌아가기 때문에 캐시 라인에 들어있던 두 변수 모두를 살펴봐야만 한다.
따라서 코어 1은 코어 2에 의해 n2의 값이 변경되면 연산을 멈추고 n2의 값을 다시 받아와서 캐시 라인에 적재하게 된다.
이런 작업이 계속 반복된다면 성능 저하를 일으킬 수 밖에 없다.

이를 해결하는 방법은 패딩(padding)을 사용해 데이터를 캐시 라인의 크기인 64 바이트로 채워주는 것이다.

이제 가려운 부분이 어느정도 해소가 되었다. 다음으로 넘어가보자.

## Scheduling Decision Scenario

내가 당신에게 알려준 높은 수준의 정보를 기반으로 운영체제 스케줄러를 작성하도록 요청했다고 상상해보라.
스케줄러를 만들 때 고려해야할 당장 떠오르는 시나리오가 있는가?
그것은 스케줄러가 스케줄링 결정을 내릴 때 고려해야하는 많은 흥미로운 것들 중 하나라는 것을 기억하자.

애플리케이션을 시작하면 메인 스레드가 생성되고 코어 1에서 실행된다고 가정해보자.
스레드가 명령을 실행하기 시작하면 데이터가 필요하기 때문에 캐시 라인이 검색된다.
이후 스레드가 일부 동시 처리를 위해 새로운 스레드를 생성하기로 결정한다. 이 때,

새로운 스레드가 생성되고 사용될 준비가 되면 스케줄러는 다음을 수행해야 한다:

1. 코어 1의 메인 스레드를 컨텍스트 스위치할 것인가? 새로운 스레드가 이미 캐시된 동일한 데이터를 필요로할 가능성이 매우 높기 때문에 이렇게 하면 성능에 도움이 될 수 있다. 하지만 메인 스레드는 작업할 시간을 얻지 못하게 된다.
2. 메인 스레드의 작업 시간이 완료될 때까지 새로운 스레드가 코어 1에 배치되기를 기다리게 할 것인가? 새로운 스레드는 실행되고 있지 않지만, 시작되면 데이터를 가져오는 작업에 대한 지연 시간이 제거될 것이다.
3. 새로운 스레드가 다른 코어에 배치되기를 기다리게 할 것인가? 즉, 선택한 코어의 캐시 라인이 날아가고 검색 및 복제되는 지연 시간이 발생될 것이다. 그러나 스레드가 더 빨리 시작되고 메인 스레드는 작업 시간을 충분히 가질 수 있게 된다.

즐겁지 아니한가?
이것은 운영체제 스케줄러가 스케줄링 결정을 내릴 때 고려해야하는 아주 흥미로운 질문이다.
운 좋게도 나는 스케줄러는 만드는 사람이 아니다.
내가 말할 수 있는 것은 유휴 코어가 있으면 사용된다는 것 뿐, 우리는 스레드가 실행될 수 있을 때 실행되기를 원한다.

## Conclusion

이 게시물의 첫 번째 부분은 멀티스레드 애플리케이션을 만들 때의 스레드 및 운영체제 스케줄러와 관련해 고려해야 할 사항들에 대한 통찰력을 제공한다.
이는 Go 스케줄러도 고려하는 사항이다.
다음 게시물에서는 Go 스케줄러의 의미와 그것들이 이러한 정보들과 어떻게 연관되는지 설명할 것이다.
그런 다음, 마지막으로 몇 가지 프로그램을 실행해 이 모든 것이 실제로 작동하는지 확인해 볼 것이다.

---

[^1]: [Mechanical Sympathy](https://wa.aws.amazon.com/wellarchitected/2020-07-02T19-33-23/wat.concept.mechanical-sympathy.en.html) 란 간단히 말해서 도구나 시스템이 가장 잘 작동하는 방식을 이해하고 사용하는 상태를 말한다.
[^2]: [Mental model](https://en.wikipedia.org/wiki/Mental_model) 은 실제 세상에서 그것이 어떻게 작동하는지에 관해 어떤 누군가가 사고한 과정에 대한 설명이다.
[^3]: [Program counter](https://ko.wikipedia.org/wiki/프로그램_카운터https://ko.wikipedia.org/wiki/프로그램_카운터)
[^4]: [Latency](https://ko.wikipedia.org/wiki/레이턴시)
[^5]: [Measuring context switching and memory overheads for Linux threads](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/)
[^6]: [Improving scheduler latency](https://lwn.net/Articles/404993/)
[^7]: [code::dive conference 2014 - Scott Meyers: Cpu Caches and Why You Care](https://www.youtube.com/watch?v=WDIkqP4JbkE)
[^8]: [Design Philosophy On Data And Semantics](https://www.ardanlabs.com/blog/2017/06/design-philosophy-on-data-and-semantics.html)
[^9]: [Youtube](https://www.youtube.com/watch?v=WDIkqP4JbkE), 캐시 일관성이란 공유 메모리 시스템에서 각 클라이언트 혹은 프로세서가 가진 로컬 캐시 간의 일관성을 의미한다.
